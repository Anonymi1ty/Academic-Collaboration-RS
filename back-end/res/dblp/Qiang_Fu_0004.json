{"id": "17/1352-4", "name": "Qiang Fu 0004", "Article": {"conf/si3d/JinFD20": {"title": "Contour-based 3D Modeling through Joint Embedding of Shapes and Contours.", "url": "https://doi.org/10.1145/3384382.3384518", "year": "2020", "author": {"Aobo Jin": "246/5482", "Qiang Fu 0004": "17/1352-4", "Zhigang Deng": "23/6641"}, "abstract": "\n\t\tIn this paper, we propose a novel space that jointly embeds both 2D occluding contours and 3D shapes via a variational autoencoder (VAE) and a volumetric autoencoder. Given a dataset of 3D shapes, we extract their occluding contours via projections from random views and use the occluding contours to train the VAE. Then, the obtained continuous embedding space, where each point is a latent vector that represents an occluding contour, can be used to measure the similarity between occluding contours. After that, the volumetric autoencoder is trained to first map 3D shapes onto the embedding space through a supervised learning process and then decode the merged latent vectors of three occluding contours (from three different views) of a 3D shape to its 3D voxel representation. We conduct various experiments and comparisons to demonstrate the usefulness and effectiveness of our method for sketch-based 3D modeling and shape manipulation applications.\n\t"}, "journals/tvcg/XiongFFZLD21": {"title": "Motion Planning for Convertible Indoor Scene Layout Design.", "url": "https://doi.org/10.1109/TVCG.2020.3005680", "year": "2021", "author": {"Guoming Xiong": "61/6845", "Qiang Fu 0004": "17/1352-4", "Hongbo Fu": "19/5752", "Bin Zhou": "66/3973", "Guoliang Luo": "10/10334", "Zhigang Deng": "23/6641"}, "abstract": " Abstract:We present a system for designing indoor scenes with convertible furniture layouts. Such layouts are useful for scenarios where an indoor scene has multiple purposes and requires layout conversion, such as merging multiple small furniture objects into a larger one or changing the locus of the furniture. We aim at planning the motion for the convertible layouts of a scene with the most efficient conversion process. To achieve this, our system first establishes object-level correspondences between the layout of a given source and that of a reference to compute a target layout, where the objects are re-arranged in the source layout with respect to the reference layout. After that, our system initializes the movement paths of objects between the source and target layouts based on various mechanical constraints. A joint space-time optimization is then performed to program a control stream of object translations, rotations, and stops, under which the movements of all objects are efficient and the potential object collisions are avoided. We demonstrate the effectiveness of our system through various design examples of multi-purpose, indoor scenes with convertible layouts."}, "journals/cgf/FuYFL20": {"title": "Interactive Design and Preview of Colored Snapshots of Indoor Scenes.", "url": "https://doi.org/10.1111/cgf.14166", "year": "2020", "author": {"Qiang Fu 0004": "17/1352-4", "Hai Yan": "30/1594", "Hongbo Fu": "19/5752", "Xueming Li": "67/2097"}, "abstract": ""}, "journals/cvgip/FuFYZCL20": {"title": "Human-centric metrics for indoor scene assessment and synthesis.", "url": "https://doi.org/10.1016/j.gmod.2020.101073", "year": "2020", "author": {"Qiang Fu 0004": "17/1352-4", "Hongbo Fu": "19/5752", "Hai Yan": "30/1594", "Bin Zhou": "66/3973", "Xiaowu Chen": "52/2710", "Xueming Li": "67/2097"}, "abstract": "In recent years, many approaches have been proposed to analyze the affordance of 3D objects and to facilitate the synthesis of aesthetic and realistic indoor scenes. However, how to assess the quality of such synthesized 3D scenes is still a challenging problem. To address this, we present a novel approach through so-called Human-Centric Metrics (HCMs) for quantitatively evaluating the layout quality of certain objects, and thus to facilitate indoor scene synthesis. Our HCMs consider both the human-object factors to assess the functional accessibility of indoor objects, and the human-environment factors to assess the subjective comfort in the scene. Given a 3D scene with arranged furniture objects, our method automatically places human agents and then use HCMs to assess both the object arrangement and indoor environment based on the position/direction of a certain human agent. The conducted user study shows that the assessment capability of HCMs well conforms to the interior design knowledge. We also use the HCMs based assessment results to synthesize 3D indoor scenes by suggesting indoor objects and their layout given an empty room. A series of experimental results and comparisons are presented to validate the usability and effectiveness of our HCMs for virtual scene assessment and synthesis."}, "journals/tog/FuCWWZF17": {"title": "Adaptive synthesis of indoor scenes via activity-associated object relation graphs.", "url": "https://doi.org/10.1145/3130800.3130805", "year": "2017", "author": {"Qiang Fu 0004": "17/1352-4", "Xiaowu Chen": "52/2710", "Xiaotian Wang": "30/8606", "Sijia Wen": "02/2608", "Bin Zhou": "66/3973", "Hongbo Fu": "19/5752"}, "abstract": "We present a system for adaptive synthesis of indoor scenes given an empty room and only a few object categories. Automatically suggesting indoor objects and proper layouts to convert an empty room to a 3D scene is challenging, since it requires interior design knowledge to balance the factors like space, path distance, illumination and object relations, in order to insure the functional plausibility of the synthesized scenes. We exploit a database of 2D floor plans to extract object relations and provide layout examples for scene synthesis. With the labeled human positions and directions in each plan, we detect the activity relations and compute the coexistence frequency of object pairs to construct activity-associated object relation graphs. Given the input room and user-specified object categories, our system first leverages the object relation graphs and the database floor plans to suggest more potential object categories beyond the specified ones to make resulting scenes functionally complete, and then uses the similar plan references to create the layout of synthesized scenes. We show various synthesis results to demonstrate the practicability of our system, and validate its usability via a user study. We also compare our system with the state-of-the-art furniture layout and activity-centric scene representation methods, in terms of functional plausibility and user friendliness."}, "journals/tvcg/FuCSF17": {"title": "Pose-Inspired Shape Synthesis and Functional Hybrid.", "url": "https://doi.org/10.1109/TVCG.2017.2739159", "year": "2017", "author": {"Qiang Fu 0004": "17/1352-4", "Xiaowu Chen": "52/2710", "Xiaoyu Su": "144/8973", "Hongbo Fu": "19/5752"}, "abstract": " Abstract:We introduce a shape synthesis approach especially for functional hybrid creation that can be potentially used by a human operator under a certain pose. Shape synthesis by reusing parts in existing models has been an active research topic in recent years. However, how to combine models across different categories to design multi-function objects remains challenging, since there is no natural correspondence between models across different categories. We tackle this problem by introducing a human pose to describe object affordance which establishes a bridge between cross-class objects for composite design. Specifically, our approach first identifies groups of candidate shapes which provide affordances desired by an input human pose, and then recombines them as well-connected composite models. Users may control the design process by manipulating the input pose, or optionally specifying one or more desired categories. We also extend our approach to be used by a single operator with multiple poses or by multiple human operators. We show that our approach enables easy creation of nontrivial, interesting synthesized models."}, "journals/cg/SuCFF16": {"title": "Cross-class 3D object synthesis guided by reference examples.", "url": "https://doi.org/10.1016/j.cag.2015.06.009", "year": "2016", "author": {"Xiaoyu Su": "144/8973", "Xiaowu Chen": "52/2710", "Qiang Fu 0004": "17/1352-4", "Hongbo Fu": "19/5752"}, "abstract": "Re-combining parts of existing 3D object models is an interesting and efficient technique to create novel shape collections. However, due to the lack of direct partsâ€™ correspondence across different shape families, such data-driven modeling approaches in literature are mostly limited to the synthesis of in-class shapes only. To address the problem, this paper proposes a novel approach to create 3D shapes via re-combination of cross-category object parts from an existing database of different model families. In our approach, a reference shape containing multi-functional constituent parts is pre-specified by users, and its design style is then reused to guide the creation process. To this end, the functional substructures are first extracted for the reference shape. After that, we explore a series of category pairs which are potential replacements for the functional substructures of the reference shape to make interesting variations. We demonstrate our ideas using various examples, and present a user study to evaluate the usability and effectiveness of our technique."}, "journals/cgf/FuCSLF16": {"title": "Structure-adaptive Shape Editing for Man-made Objects.", "url": "https://doi.org/10.1111/cgf.12808", "year": "2016", "author": {"Qiang Fu 0004": "17/1352-4", "Xiaowu Chen": "52/2710", "Xiaoyu Su": "144/8973", "Jia Li 0003": "23/6950-3", "Hongbo Fu": "19/5752"}, "abstract": ""}, "journals/cvgip/FuCSF16": {"title": "Natural lines inspired 3D shape re-design.", "url": "https://doi.org/10.1016/j.gmod.2016.01.002", "year": "2016", "author": {"Qiang Fu 0004": "17/1352-4", "Xiaowu Chen": "52/2710", "Xiaoyu Su": "144/8973", "Hongbo Fu": "19/5752"}, "abstract": "We introduce an approach for re-designing 3D shapes inspired by natural lines such as the contours and skeletons extracted from the natural objects in images. Designing an artistically creative and visually pleasing model is not easy for novice users. In this paper, we propose to convert such a design task to a computational procedure. Given a 3D object, we first compare its editable lines with various lines extracted from the image database to explore the candidate reference lines. Then a parametric deformation method is employed to reshape the 3D object guided by the reference lines. We show that our approach enables users to quickly create nontrivial and interesting re-designed 3D objects. We also conduct a user study to validate the usability and effectiveness of our approach."}, "journals/jcst/LiCZLGF15": {"title": "Monocular Video Guided Garment Simulation.", "url": "https://doi.org/10.1007/s11390-015-1543-0", "year": "2015", "author": {"Faming Li": "142/9175", "Xiaowu Chen": "52/2710", "Bin Zhou": "66/3973", "Fei-Xiang Lu": "162/1638", "Kan Guo": "139/0440", "Qiang Fu 0004": "17/1352-4"}, "abstract": "We present a prototype to generate a garment-shape sequence guided by a monocular video sequence. It is a combination of a physically-based simulation and a boundary-based modification. Given a garment in the video worn on a mannequin, the simulation generates a garment initial shape by exploiting the mannequin shapes estimated from the video. The modification then deforms the simulated 3D shape into such a shape that matches the garment 2D boundary extracted from the video. According to the matching correspondences between the vertices on the shape and the points on the boundary, the modification is implemented by attracting the matched vertices and their neighboring vertices. For best-matching correspondences and efficient performance, three criteria are introduced to select the candidate vertices for matching. Since modifying each garment shape independently may cause inter-frame oscillations, changes by the modification are also propagated from one frame to the next frame. As a result, the generated garment 3D shape sequence is stable and similar to the garment video sequence. We demonstrate the effectiveness of our prototype with a number of examples."}, "journals/cgf/ZhouCFGT13": {"title": "Garment Modeling from a Single Image.", "url": "https://doi.org/10.1111/cgf.12215", "year": "2013", "author": {"Bin Zhou": "66/3973", "Xiaowu Chen": "52/2710", "Qiang Fu 0004": "17/1352-4", "Kan Guo": "139/0440", "Ping Tan": "61/6118"}, "abstract": ""}}}