{"id": "95/4440", "name": "Meina Song", "Article": {"conf/ccis/WangOS21": {"title": "PowerDet: Efficient and Lightweight Object Detection for Electric Power Open Scenes.", "url": "https://doi.org/10.1109/CCIS53392.2021.9754678", "year": "2021", "author": {"Shigeng Wang": "318/8450", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": " Abstract:In recent years, with the expansion of the electric network, maintenance cost of electric power transmission and transformer substation equipment has become increasingly greater. Moreover, it requires a lot of manpower as well. At present, there are certain schemes which leverage artificial intelligence techniques to detect equipment flaws or errors automatically. Nevertheless, there are problems with the schemes in open electric power scenes, e.g., only able to detect single category, low detection accuracy of multi-scale objects, and difficulty in deploying models on mobile devices. To address the challenges mentioned above, we propose an object detection model, named PowerDet. It is able to detect 9 different types of power facilities efficiently with low cost. To verify the effectiveness of PowerDet, we collect an open scene facility entity dataset and conduct a series of experiments. Experimental results demonstrate that PowerDet achieves 86.8% AP50 on the dataset, which outperforms the state-of-the-art. The lightweight version of PowerDet, i.e., PowerDet-Lite, can achieve real-time inference on mainstream mobile devices."}, "conf/naacl/XuESSLWY21": {"title": "RTFE: A Recursive Temporal Fact Embedding Framework for Temporal Knowledge Graph Completion.", "url": "https://doi.org/10.18653/v1/2021.naacl-main.451", "year": "2021", "author": {"Youri Xu": "275/8967", "Haihong E": "43/10222", "Meina Song": "95/4440", "Wenyu Song": "265/4346", "Xiaodong Lv": "213/8586", "Haotian Wang 0004": "63/11345-4", "Jinrui Yang": "272/1122"}, "abstract": ""}, "conf/apweb/TanOLSS20": {"title": "Turn-Level Recurrence Self-attention for Joint Dialogue Action Prediction and Response Generation.", "url": "https://doi.org/10.1007/978-3-030-60290-1_24", "year": "2020", "author": {"Yanxin Tan": "276/3512", "Zhonghong Ou": "58/6143", "Kemeng Liu": "237/8139", "Yanan Shi": "120/5466", "Meina Song": "95/4440"}, "abstract": "In task-oriented dialogue systems, semantically controlled natural language generation is the procedure to generate responses based on current context information. Seq2seq models are widely used to generate dialogue responses and achieve favorable performance. Nevertheless, how to effectively obtain the dialogue’s key information from history remains to be a critical problem. To overcome this problem, we propose a Turn-level Recurrence Self-Attention (TRSA) encoder, which effectively obtains progressive structural relationship in turn-level from conversation history. Moreover, we propose a novel model to predict dialogue actions and generate dialogue responses jointly, which is different from the separate training model used in previous studies. Experiments demonstrate that our model alleviates the problem of inaccurate attention in dialogue history and improves the degree of dialogue completion significantly. In the large-scale MultiWOZ dataset, we improve the performance by 3.9% of inform rate and 3.4% of success rate, which is significantly higher than the state-of-the-art.KeywordsSelf-attentionDialogue systemResponse generation."}, "conf/apweb/LiuOTZS20": {"title": "KGWD: Knowledge Graph Based Wide & Deep Framework for Recommendation.", "url": "https://doi.org/10.1007/978-3-030-60259-8_33", "year": "2020", "author": {"Kemeng Liu": "237/8139", "Zhonghong Ou": "58/6143", "Yanxin Tan": "276/3512", "Kai Zhao": "72/2621", "Meina Song": "95/4440"}, "abstract": "Knowledge Graph (KG) contains rich real-world auxiliary information, which can be leveraged to improve the performance of recommender systems. Nevertheless, existing recommender systems usually sample and aggregate neighbor entities and relations that link to target items to enrich the representations of items or users, whereas ignoring combinatorial features among different neighbor entities and relations. To resolve the problem mentioned above, we propose an end-to-end Knowledge Graph based Wide & Deep (KGWD) framework to leverage combinatorial features effectively. At the wide level, KGWD introduces a novel Triplet Compressed Interaction Network (TriCIN) to generate high-order combinatorial features among different triplets associated with the target item automatically. At the deep level, KGWD discovers users’ potential long-distance preferences by mining multi-hop neighbor information over the KG. We conduct experiments on three real-world datasets, i.e., Yelp2018, Last-FM, and Amazon-book, to evaluate the performance of KGWD. Experimental results demonstrate that KGWD outperforms state-of-the-art schemes significantly. Specifically, in all three datasets, KGWD improves the F1-score by more than 5% over the state-of-the-art.KeywordsRecommender systemsKnowledge graphWide & Deep"}, "conf/asse/EZS20": {"title": "Distant Supervised Relation Extraction Model for Reinforcement Learning Combined with Noise Network.", "url": "https://doi.org/10.1145/3399871.3399893", "year": "2020", "author": {"Haihong E": "43/10222", "Xiaosong Zhou": "85/2628", "Meina Song": "95/4440"}, "abstract": "\n\t\tThe distant supervised relation extraction has received wide attention from scholars in recent years. Existing methods for distant supervised relation extraction are based on bag-level for relation prediction, but they do not correspond to sentences and relation one by one. So in 2018, some scholars have proposed distant supervised relation extraction based on the sentence-level with reinforcement learning methods. Adding adaptive noise to the parameters of the reinforcement learning algorithm can effectively improve the performance of the algorithm. In this paper, the parametric noise is added to the neural network weights to increase the exploration of reinforcement learning. Experiments show that reinforcement learning with noise effectively improves the effect of distant supervised relation extraction based on the sentence-level.\n\t"}, "conf/asse/SongXEH20": {"title": "Algorithm for Automatic Layout of Logo Pictures for Visualization of Ecological Map in Strategic Consulting.", "url": "https://doi.org/10.1145/3399871.3399876", "year": "2020", "author": {"Meina Song": "95/4440", "Xiangyu Xu": "172/1282", "Haihong E": "43/10222", "Yucheng Hu": "59/9331"}, "abstract": "\n\t\tThe mapping of the industrial ecological map is an important work in strategic consulting services, but excessive artificial dependence has caused it to become a pain point for the digital transformation of strategic consulting. This paper proposed a method for the automatic layout of logo pictures to improve the efficiency of graph visualization. This paper improved the classic genetic algorithm, used inverse Polish expressions to represent the layout state, and combined the golden ratio and overall utilization as fitness functions to quickly generate the optimal ecological map. Finally, it was compared with artificial layout and violent layout, which proved the feasibility and superiority of the algorithm.\n\t"}, "conf/bdet/WuHS20": {"title": "An Automatic Artificial Intelligence Training Platform Based on Kubernetes.", "url": "https://doi.org/10.1145/3378904.3378921", "year": "2020", "author": {"Chaoyu Wu": "263/0327", "Haihong E": "43/10222", "Meina Song": "95/4440"}, "abstract": "\n\t\tFor large-scale AI training, the manual allocation of GPU resources is too inefficient, and it faces the problems of task allocation and fault restart. In this paper, a fully automatic machine learning platform is designed, which manages server resources uniformly, and users describe the required resources through configuration files. The platform automatically performs AI task allocation and scheduling based on the cluster load, which solves the problems of low cluster resource utilization and uneven machine load distribution. The platform also provides an automatic release and continuous integration of the model, which greatly simplifies the configuration of the model's operating environment and external release process, enabling researchers to focus more on model adjustments. Finally, it is verified by experiments that the extra time spent on AI task training through this platform is negligible, which confirms the feasibility of the platform.\n\t"}, "conf/chil/ZhangHSEOS20": {"title": "BMM-Net: automatic segmentation of edema in optical coherence tomography based on boundary detection and multi-scale network.", "url": "https://doi.org/10.1145/3368555.3384447", "year": "2020", "author": {"Ruru Zhang": "139/7990", "Jiawen He": "256/7881", "Shenda Shi": "255/8207", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": "\n\t\tRetinal effusions and cysts caused by the leakage of damaged macular vessels and choroid neovascularization are symptoms of many ophthalmic diseases. Optical coherence tomography (OCT), which provides clear 10-layer cross-sectional images of the retina, is widely used to screen various ophthalmic diseases. A large number of researchers have carried out relevant studies on deep learning technology to realize the semantic segmentation of lesion areas, such as effusion on OCT images, and achieved good results. However, in this field, problems of the low contrast of the lesion area and unevenness of lesion size limit the accuracy of the deep learning semantic segmentation model. In this paper, we propose a boundary multi-scale multi-task OCT segmentation network (BMM-Net) for these two challenges to segment the retinal edema area, subretinal fluid, and pigment epithelial detachment in OCT images. We propose a boundary extraction module, a multi-scale information perception module, and a classification module to capture accurate position and semantic information and collaboratively extract meaningful features. We train and verify on the AI Challenger competition dataset. The average Dice coefficient of the three lesion areas is 3.058% higher than the most commonly used model in the field of medical image segmentation and reaches 0.8222.\n\t"}, "conf/hucc/LiuLOZS20": {"title": "An Inclusive Finance Consortium Blockchain Platform for Secure Data Storage and Value Analysis for Small and Medium-Sized Enterprises.", "url": "https://doi.org/10.1007/978-3-030-70626-5_44", "year": "2020", "author": {"Jiaxi Liu": "197/1757", "Peihang Liu": "274/3105", "Zhonghong Ou": "58/6143", "Guangwei Zhang": "78/6847", "Meina Song": "95/4440"}, "abstract": "In the era of big data, people pay more and more attention to user privacy and data security. The market size of Small and Medium-sized Enterprises (SMEs) in China is sizable. Nevertheless, due to problems of data dispersion and lack of data features, it is very difficult to make use of the massive data of SMEs scattered in various institutions effectively, which leads to the inability to reflect the value of data. One of the problems is how to credit for SMEs better. Supported by federated learning for such scenarios, we present an inclusive Finance Consortium Blockchain platform in this paper. On the one hand, the platform combines decentralized identity and Blockchain as the underlying architecture, which guarantees authenticity of the data source and safe storage of user data on the chain. The smart contract mechanism provided by Blockchain can also assist secure storage and incentive mechanism of federated learning models effectively. On the other hand, we have innovatively introduced an asynchronous Federated Learning mode based on transfer learning, which encrypts the well-designed pre-training model and transfers it to each participant to guide training of the participant's local model. In the model reasoning stage, all the participants participate in a joint evaluation according to the local model and push the reasoning results on the Blockchain. The smart contract takes the weighted sum of the reasoning results provided by all the participants as the final result of shared model reasoning.KeywordsFederated learningFederated transfer learningBlockchainDecentralized identity"}, "conf/acl/ENCS19": {"title": "A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling.", "url": "https://doi.org/10.18653/v1/p19-1544", "year": "2019", "author": {"Haihong E": "43/10222", "Peiqing Niu": "244/1979", "Zhongfu Chen": "244/2567", "Meina Song": "95/4440"}, "abstract": ""}, "conf/bdiot/SongXE19": {"title": "Research and Top-level Framework Design on Unified Resource Management of Big Data in Strategic Consulting.", "url": "https://doi.org/10.1145/3361758.3361761", "year": "2019", "author": {"Meina Song": "95/4440", "Xiangyu Xu": "172/1282", "Haihong E": "43/10222"}, "abstract": "\n\t\tThis paper puts forward a set of top-level framework design methodology for unified data resource management aiming at the characteristics of big data, multi-source and heterogeneous, and the difficulty of unified organization and management, and completes the top-level framework of big data for strategic consulting based on this methodology for the scenario of strategic consulting. This paper investigates the unified data resource integration model at home and abroad, and proposed a set of architecture design methodology based on it. The methodology includes three aspects: metadata-driven, hierarchical organization, separation and reorganization. Then the article takes the real data as an example and gives the preliminary results of the model to prove the validity of the model.\n\t"}, "conf/ciis/EZS19": {"title": "Hybrid High-order in Graph Attention Layer.", "url": "https://doi.org/10.1145/3372422.3372442", "year": "2019", "author": {"Haihong E": "43/10222", "Di Zeng": "275/0167", "Meina Song": "95/4440"}, "abstract": "\n\t\tAs a result of approximating the Eigenbasis of the graph Laplacian proposed by GC-layer of Kipf & Welling [5], the convolution operation is efficiently applied from Euclidean domain to graph domain, and the end-to-end deep graph neural network is widely used and developed. However, fixed neighborhood limits the learning ability of the model, and GAT [7] models global node pairs to avoid information loss. In the form, this modeling is equivalent to only considering the first-order proximity relation of the network, which leads to the indirect and lossy transmission of the higher-order information of the network, even if the multi-layer attention mechanism is used to expand the order of the network. In order to avoid the above situation and obtain higher-order information better, this paper tries to establish the concept of higher-order neighborhood mixed learning of graphs. In our work, unlike the implicit propagation of neighborhood information through activation functions in the past, our model called H-GAT explicitly obtain the information of high-order neighborhood of nodes, and use attention mechanism to model different weights between high-step nodes.\n\t"}, "conf/ecai2/SongCNE19": {"title": "Building End-to-End Task-oriented Dialogue Systems Via CNNs and Attention Mechanisms.", "url": "https://doi.org/10.1109/ECAI46879.2019.9041974", "year": "2019", "author": {"Meina Song": "95/4440", "Chongfu Chen": "317/5690", "Peiqing Niu": "244/1979", "Haihong E": "43/10222"}, "abstract": " Abstract:We put forward a general solution towards building task-oriented dialogue systems via convolutional neural networks (CNNs) and Attention Mechanisms. The dominant task-oriented dialogue models follow pipeline design and usually rely on complex recurrent neural networks(RNNs). In that case, its structure is complicated and the amount of parameters exceeds on million. In this paper, we propose a novel end-to-end task-oriented dialogue system with a clear structure, just based on CNNs and attention mechanisms, totally dispensing with recurrent neural networks (RNNs). Our model is based entirely on sequence-to-sequence (seq2seq) architecture and realizes the true meaning of end-to-end. Experimental results indicate that our model outperforms the state-of-the-art approaches on Cam-Rest676 and KVRET datasets in two evaluation indexes, namely, task completion and quality of language generation. Meanwhile, the training speed of our model is increased by 3-10 times and the amount of parameters is just 1/3."}, "conf/hucc/EKLSO19": {"title": "A Real-Time Update Approach for Visualizing Multidimensional Big Data.", "url": "https://doi.org/10.1007/978-3-030-37429-7_10", "year": "2019", "author": {"Haihong E": "43/10222", "Huihui Kong": "247/3690", "Yunfeng Liu": "56/5650", "Meina Song": "95/4440", "Zhonghong Ou": "58/6143"}, "abstract": "\nMultidimensional data in different fields (e.g., science and technology resources, medicine, finance and transportation) have emerged in the big data era. Technology of visualization is critical to analyze multidimensional data which is large-scale. Thus, the highly variability of multidimensional data leads to the necessity of improving data management efficiency by updating data in real time. Nevertheless, traditional real-time communication technology suffers from low efficiency and large bandwidth consumption. Based on WebSocket, this paper proposes a multidimensional data service platform architecture that is scalable, real-time and versatile. First, on the platform, we compare the network load and network latency above Ajax polling and WebSocket. Secondly, for multidimensional data, we further validate the effectiveness of WebSocket in the application scenarios of frequent updating and multi-user concurrent requests. WebSocket-based platform greatly shortens the time for people to understand and analyze massive and complex multidimensional data. The application results show that the design is effective for real-time updating of multidimensional data.\nKeywordsWebSocketMultidimensional dataReal-time updating"}, "conf/hucc/ZhangHSKCLLHOS19": {"title": "Computer-Aided Diagnosis of Ophthalmic Diseases Using OCT Based on Deep Learning: A Review.", "url": "https://doi.org/10.1007/978-3-030-37429-7_63", "year": "2019", "author": {"Ruru Zhang": "139/7990", "Jiawen He": "256/7881", "Shenda Shi": "255/8207", "Xiaoyang Kang": "180/2279", "Wenjun Chai": "256/7872", "Meng Lu": "90/106", "Yu Liu": "97/2274", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": "Deep learning can effectively extract the hidden features of images and has developed rapidly in medical image recognition in recent years. Ophthalmic diseases are one of the critical factors affecting the healthy living. At the same time, optical coherence tomography (OCT) has the characteristics of non-invasive and high-resolution and has become the mainstream imaging technology in the clinical diagnosis of Ophthalmic diseases. Therefore, computer-aided diagnosis of ophthalmic diseases using OCT based on deep learning has caused a wide range of research craze. In this paper, we review the imaging methods and applications of OCT, the OCT public dataset. And we introduce in detail the computer-aided diagnosis system of multiple ophthalmic diseases using OCT in recent years, including age-related macular degeneration, glaucoma, diabetic macular edema and so on, and an overview of the main challenges faced by deep learning in OCT imaging.\nKeywordsDeep learningOCTOphthalmic disease"}, "conf/icit/WuOS19": {"title": "Session-based Recommendation with Context-Aware Attention Network.", "url": "https://doi.org/10.1145/3377170.3377269", "year": "2019", "author": {"Jinsheng Wu": "261/7036", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": "\n\t\tSession-based recommendation aims to generate recommendation results based on user's anonymous session. Previous studies model the session as a sequence and use Recursive Neural Network (RNN) to represent user behavior for recommendations. Although achieved promising result, previous studies ignore the relationship between session's items and external context of session, which fails in revealing the intrinsic relation between them. To tackle the problem mentioned above, we propose a novel method, i.e., Session-based Recommendation with Context-Aware Attention Network, SR-CAAN, which enhances the ability of modeling the user preference by combining sequence prediction with session external context aware method. In the proposed method, we incorporate external knowledge with Knowledge Graph (KG) to obtain the external context of session by using attention mechanism. Each session is presented as a composition of the external context of session and user's long-short term interest is obtained by Recurrent Neural Networks (RNNs). Experiments conducted on real word datasets demonstrate that SR-CAAN outperform the state-of-the-art significantly.\n\t"}, "conf/ictai/SongCNE19": {"title": "FPSeq: Simplifying and Accelerating Task-Oriented Dialogue Systems via Fully Parallel Sequence-to-Sequence Framework.", "url": "https://doi.org/10.1109/ICTAI.2019.00165", "year": "2019", "author": {"Meina Song": "95/4440", "Zhongfu Chen": "244/2567", "Peiqing Niu": "244/1979", "Haihong E": "43/10222"}, "abstract": " Abstract:A mainstream task-oriented dialogue system is stuck in the independence of modules since it follows pipeline design, and it also suffers from sequence dependence and time dependence of recurrent neural network (RNN). Thus, these systems are complicated and usually trained slowly. In this paper, we propose FPSeq, a novel, fully parallel framework to simplify and accelerate task-oriented dialogue systems. Specifically, FPSeq turns pipeline design into a single sequence-to-sequence (seq2seq) model to achieve integration of each module for end-to-end training. In addition, multi-layer convolutional neural networks (CNNs) and attention mechanisms are applied in seq2seq learning to achieve parallel computations for speed improvement. Compared to the existing best model, the training speed of FPSeq is 3-10 times faster while only one-third of the number of parameters. Experimental results on CamRest676 and KVRET datasets indicate that FPSeq achieves the state-of-the-art performance in both task completion and quality of language generation."}, "conf/icvisp/HuS19": {"title": "Crowd R-CNN: An Object Detection Model Utilizing Crowdsourced Labels.", "url": "https://doi.org/10.1145/3387168.3387180", "year": "2019", "author": {"Yucheng Hu": "59/9331", "Meina Song": "95/4440"}, "abstract": "\n\t\tAccuracy of object detection has increased significantly in recent years because of the rapid development of deep learning techniques. Nevertheless, its applications in many fields are still limited, mainly due to the lack of large datasets, especially datasets with accurate annotations. Crowdsourcing provides a promising approach to tackle the problem mentioned above because of their \"divide and conquer\" nature. Nonetheless, existing crowdsourced techniques, e.g., Amazon Mechanical Turk (MTurk), often fail to guarantee the quality of the annotations. In this paper, we propose a novel probabilistic scheme based on crowdsourcing for ground truth inference. As a representative of object detection, we choose Faster R-CNN as the base framework. We name our scheme Crowd R-CNN. We propose an aggregation approach to aggregate annotations from multiple annotators, which allows to convert anchor labels and annotated labels with each other and train the network end-to-end using backpropagation. To improve accuracy, Crowd R-CNN takes into consideration the multi-dimensional measure of the annotatore' ability and updates these parameters during training. Experimental results demonstrate that Crowd R-CNN can deal with noisy crowdsourced data effectively. Crowd R-CNN is able to achieve comparable results to the baseline with ground truth annotations and is the first algorithm to solve the problem of how to train deep object detection model utilizing crowdsourced labels.\n\t"}, "conf/icvisp/HuOXS19": {"title": "A Crowdsourcing Repeated Annotations System for Visual Object Detection.", "url": "https://doi.org/10.1145/3387168.3387242", "year": "2019", "author": {"Yucheng Hu": "59/9331", "Zhonghong Ou": "58/6143", "Xiangyu Xu": "172/1282", "Meina Song": "95/4440"}, "abstract": "\n\t\tAs a fundamental task in compute vision, object detection has been developed rapidly driven by the deep learning. The lack of a large number of images with ground truth annotations has become a chief obstacle to object detection applications in many fields. Eliciting labels from crowds is a potential way to obtain large labeled data. Nonetheless, existing crowdsourced techniques, e.g., Amazon Mechanical Turk (MTurk), often fail to guarantee the quality of the annotations, which have a bad influence on the accuracy of the deep detector. A variety of methods have been developed for ground truth inference and learning from crowds. In this paper, we study strategies to crowd-source repeated labels in support for these methods. The core challenge of building such a system is to reduce the difficulty to annotate multiple objects of interest and improve the data quality as much as possible. We present a system that adopts the turn-based annotation mechanism and consists of three simple sub-tasks: a single object annotation, a quality verification task and a coverage verification task. Experimental results demonstrate that our system is scalable, accurate and can assist the detector of obtaining higher accuracy.\n\t"}, "conf/skg/EZS19": {"title": "KB-Transformer: Incorporating Knowledge into End-to-End Task-Oriented Dialog Systems.", "url": "https://doi.org/10.1109/SKG49510.2019.00016", "year": "2019", "author": {"Haihong E": "43/10222", "Wenjing Zhang": "27/3057", "Meina Song": "95/4440"}, "abstract": " Abstract:Existing end-to-end task-oriented dialogue systems are lack of proper support of knowledge base, and training based on RNN seq2seq models is time-consuming. In this paper, we propose a novel parallel computing framework(KB-Transformer) to incorporate KB which can be trained faster than RNN seq2seq models. A key contribution is that we propose multi-head key-value memory network for the first time, comprehensively encoding semantic information of KB and incorporating KB into task-oriented dialog systems from multiple dimensions and sub-spaces. KB-Transformer tries to combine memory network with transformer, implementing a parallel dialogue framework based entirely on attention mechanism. As a result, we show that KB-Transformer can be trained faster and attain better performance than RNN seq2seq models on two different task-oriented dialog datasets."}, "conf/ssps/EZS19": {"title": "Distant Supervised Relation Extraction Based On Recurrent Convolutional Piecewise Neural Network.", "url": "https://doi.org/10.1145/3364908.3365303", "year": "2019", "author": {"Haihong E": "43/10222", "Xiaosong Zhou": "85/2628", "Meina Song": "95/4440"}, "abstract": "\n\t\tDistant supervised relation extraction (RE) is currently an effective way to solve the problem of extracting relation from large amounts of unlabeled data.The purpose of distant supervised relation extraction is to identify the relation between the two entities marked in a sentence. However, there are two existing problems.The one is that some methods need to draw on entity description of external knowledge base to enrich entity information, but in reality not every time we have entity description of an external knowledge base. The other one is that the effects of distant supervised relation extraction are not very ideal currently.This paper proposes a novel relation extraction model based on recurrent piecewise convolutional neural network structure to solve the problems above. Firstly, based on the recurrent convolutional neural network structure, the embedding of every word in a sentence is added with context information to enrich the characteristics of the words. And then with piecewise max pooling, it captures the information throughout the entire sentence. Secondly, the semantic information of a sentence can indirectly reflect the relation of the entity.This paper employs sentence vectors to add the semantic information to improve the accuracy of the distant supervised relation extraction. The experimental results are based on real-world dataset. Our model makes full use of the information characteristics of the dataset and has great improvement on the real-world dataset.It proves that our model in this paper exceeds various baselines.\n\t"}, "conf/acai2/ZhaoSE18": {"title": "Summarization with Highway Condition Radom Pointer-Generator Network.", "url": "https://doi.org/10.1145/3302425.3302490", "year": "2018", "author": {"Wenjun Zhao": "20/10175", "Meina Song": "95/4440", "Haihong E": "43/10222"}, "abstract": "\n\t\tNowadays, Neural sequence-to-sequence models have become the common approach for abstractive text summarization. In this way, the abstract is closer to the natural language, not just the excerpt and recomposition of the original text. However, these models still have some shortcomings: They can't handle out of vocabulary(OOV) words well and they tend to repeat themselves or become confused. What's more, because of the selfcharacteristics of the recurrent neural network, it begins to degenerate when the depth is low (only two layers), which is not conducive to extracting deeper features to improve the accuracy of the model. In order to solve these problems, we have proposed a Highway Condition Radom Pointer-Generator Network(HCRPGN). We introduce the CRF layer to solve the duplication problem and use highway recurrent cell to optimize the neuron structure and prevent model degradation. We apply our model to the CNN/Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 1 ROUGE points.\n\t"}, "conf/ccis/JiangESZ18": {"title": "Research and Application of Newborn Defects Prediction Based on Spark and PU-learning.", "url": "https://doi.org/10.1109/CCIS.2018.8691252", "year": "2018", "author": {"Yufeng Jiang": "239/3395", "Haihong E": "43/10222", "Meina Song": "95/4440", "Ken Zhang": "55/4197"}, "abstract": " Abstract:PU-learning, whose full name is Positive and unlabeled Learning, is a machine learning method based on positive samples and unlabeled samples. In order to adapt to the demand for algorithmic improvements caused by the increasing data volume, we design and implement a distributed version of PU-learning based on Spark, and apply the algorithm to applications for newly born defective children prediction, which facilitates taking early active prevention measures. At the same time, in order to improve the prediction accuracy, we use the method of information gain to select the appropriate feature subsets, fuse the Bagging and Boosting algorithms to extend the PU-learning framework. Experiments show that the extended PU-learning framework outperforms classic PU-learning in terms of accuracy."}, "conf/hucc/SongLLE17": {"title": "A Distributed Self-adaption Cube Building Model Based on Query Log.", "url": "https://doi.org/10.1007/978-3-319-74521-3_41", "year": "2017", "author": {"Meina Song": "95/4440", "Mingkun Li": "37/4171", "Zhuohuan Li": "213/6753", "Haihong E": "43/10222"}, "abstract": "Among the diverse distributed query and analysis engine, Kylin have gained wide adoption since its various strengths. By using Kylin, users can interact with Hadoop data at sub-second latency. However, it still has some disadvantages. One representative disadvantage is the exponential growth of cuboids along with the growth of dimensions. In this paper, we optimize the cuboid materialization strategy of Kylin by reducing the number of cuboids based on the traditional OLAP optimization method. We optimize the strategy mainly from two aspects. Firstly, we propose Lazy-Building strategy to delay the construction of nonessential cuboid and shorten the time of cuboid initialization. Secondly, we adopt Materialized View Self-adjusting Algorithm to eliminate the cuboids which are not in use for a long period. Experimental results demonstrate the efficacy of the proposed Distributed Self-Adaption Cube Building Model. Specifically, by using our model, cube initialization speed has increased by 28.5% points and 65.8% points space are saved, comparing with the cube building model of Kylin.KeywordsDistributed OLAPDistributed query processing systemKylinQuery logMaterialization strategy"}, "conf/ica3pp/OuLSE17": {"title": "A CNN-Based Supermarket Auto-Counting System.", "url": "https://doi.org/10.1007/978-3-319-65482-9_24", "year": "2017", "author": {"Zhonghong Ou": "58/6143", "Changwei Lin": "86/9627", "Meina Song": "95/4440", "Haihong E": "43/10222"}, "abstract": "Deep learning has made significant breakthrough in the past decade. In certain application domain, its detection accuracy has surpassed human being in the same task, e.g., voice recognition and object detection. Various novel applications has been developed and achieved good performance by leveraging the latest advances in deep learning. In this paper, we propose to utilize deep learning based technique, specifically, Convolutional Neural Network (CNN), to develop an auto-counting system for supermarket scenario. Given a picture, the system can automatically detect the specified categories of goods (e.g., Head & Shoulders bottles) and their respective numbers. To improve detection accuracy of the system, we propose to combine hard example mining and multi-scale feature extraction to the Faster R-CNN framework. Experimental results demonstrate the efficacy of the proposed system. Specifically, our system achieves an mAP of 92.1%, which is better than the state-of-the-art, and the response time is about 250 ms per image, including all steps on a GTX 1080 GPU.KeywordsAuto-counting systemDeep learningConvolutional Neural Network"}, "conf/ica3pp/EHSOW17": {"title": "Research and Implementation of Question Classification Model in Q&A System.", "url": "https://doi.org/10.1007/978-3-319-65482-9_25", "year": "2017", "author": {"Haihong E": "43/10222", "Yingxi Hu": "204/2302", "Meina Song": "95/4440", "Zhonghong Ou": "58/6143", "Xinrui Wang": "166/1957"}, "abstract": "Question classification is the core of the question-and-answer (Q&A) sys-tem. This paper intends to use the method of deep learning to explore the question classification model in Q&A systems, the aim of which is to improve the accuracy of question classification.\n\nThe characteristics of natural language questions, such as the use of short texts and basic grammar, were well considered. Subsequently, we want to fully extract the features of questions by using the following methods: multi-channel inputs, multi-granularity convolution kernels, and direct connection with high-speed channels. By combining the three methods, this paper proposes the multi-channel and Bidirectional long-and short-term memory and multi- granularity convolution neural net-work (MC–BLSTM–MGCNN) model to fully extract the features from interrogative sentences, both in time and spatial domains.To verify the validity of the model, this paper experimented with the TREC [1] classification standard dataset. Results achieved 96.6% accuracy, which is superior to the highest existing industry benchmark (96.1%). In addition, this paper used the complete TREC dataset to innovate further, and results obtained 98% accuracy, which greatly improved the classification.KeywordsQ&A systemQuestion classificationDeep learningConvolution neural networkLong- and short-term memory network"}, "conf/ccbd/LiSOE16": {"title": "Performance Comparison and Analysis of Yarn's Schedulers with Stress Cases.", "url": "https://doi.org/10.1109/CCBD.2016.028", "year": "2016", "author": {"Bo Li": "50/3402", "Meina Song": "95/4440", "Zhonghong Ou": "58/6143", "Haihong E": "43/10222"}, "abstract": " Abstract:Hadoop, as a popular distributed storage and computing platform, has been widely used in many companies. Yarn is the resource management platform in Hadoop and plays an important role in the resource managing, because it can affect the cluster's energy efficiency and the usability for applications. The schedulers are the brain of Yarn, which manage and schedule resources from cluster to applications. In this paper, we conduct experiments to compare and analyze the performance of Yarn's schedulers. We use various scenarios to demonstrate the strengths and weaknesses of each scheduler from the perspective of response speed, cluster's efficiency, scheduler's speciality etc. Experimental results demonstrate that the FIFO Scheduler has a better performance and data locality sense for batch jobs processing than the other schedulers, but the Capacity Scheduler and the FIFO Scheduler have better response speed and cluster's usability than the FIFO Scheduler which has a hunger problem in mixed scenario."}, "conf/dasfaa/ZhengESS16": {"title": "TGTM: Temporal-Geographical Topic Model for Point-of-Interest Recommendation.", "url": "https://doi.org/10.1007/978-3-319-32025-0_22", "year": "2016", "author": {"Cong Zheng": "28/9343", "Haihong E": "43/10222", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": "The wide spread use of location based social networks (LBSNs) and Micro-blogging services generated large volume of users’ check-in data, which consists of user ids, textual contents, posting timestamps, geographic information and so on. Point-of-interest (POI) recommendation is a task to provide personalized recommendations of interesting places to enhance the user experience in LBSNs. In this paper, we propose 2 novel time-location-content aware POI recommendation models which jointly integrate auxiliary temporal, textual and spatial information to improve the performance of POI recommendation. Specifically, we utilize temporal information to partition the original user-POI check-in frequency matrix into sub-matrices so that behavior in similar temporal scenario can be grouped. Then, we take advantage of Latent Dirichlet Allocation (LDA) model and spatial coordinates to infer the POIs. Comprehensive experiments conducted using real-world datasets demonstrate the superiority of our approach.KeywordsRecommendationPoint of interestLocation-based social networksHuman mobility"}, "conf/hucc/ELZSS16": {"title": "A General Rating Recommended Weight-Aware Model for Recommendation System.", "url": "https://doi.org/10.1007/978-3-319-31854-7_8", "year": "2016", "author": {"Haihong E": "43/10222", "Yusheng Li 0005": "00/577-5", "Xuejun Zhao": "78/936", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": "In recommendation system, the ratings represent the users’ preference and play an important role in recommending items to users. However, the ratings of items may be influenced by many factors, such as time (the latest ratings are more able to reflect the user’s current preferences), user familiarity (the more familiar a user to an item, the more reliable of rating he gives). So ratings should have different recommended weights in different circumstances. However, current recommendation algorithms ignore this problem and use the ratings indiscriminately, this affecting the accuracy of the recommendation system. In this paper, we proposed a general rating recommended weight-aware model, which can fuse all kinds of recommended weights naturally for item recommendation. We design a new rating weight-aware probability matrix factorization model, which can assign recommended weight to every rating to obtain precise recommendations. We conduct comprehensive experiments using the real-world datasets. Experimental results show that the rating-aware recommendation model outperforms state-of-the-art latent factor models with a significant margin.\n\nKeywordsRecommendation systemsProbability matrix factorizationTime span rating recommended weight-aware modelUser familiarity recommended weight-aware model"}, "conf/hucc/SongZEZ16": {"title": "Mu-En: Multi-path of Entity Recommendation Based on Path Similarity.", "url": "https://doi.org/10.1007/978-3-319-31854-7_31", "year": "2016", "author": {"Meina Song": "95/4440", "Xuejun Zhao": "78/936", "Haihong E": "43/10222", "Cong Zheng": "28/9343"}, "abstract": "In the process of exploring the path of similarity in entity recommendation, the selection of nodes in the path selection process attracts more and more attention. However, single-node path composed by one attribute is valued as the path in the face of the entity with multiple attributes for current research work, with adopting the path in similarity and advanced algorithm. In this work, we investigate the entity attributes in recommender system based on the link prediction method methods; on the basis of path similarity, we analyze the specific single-node paths, and also design the multi-node path composed of multi attributes. Therefore, this study not only provides more profound recommender results based on path similarity, but also greatly widens the path selection and improves the recommender accuracy.KeywordsEntity recommendationMatrix factorizationLink predictionPath similarityMulti-node path"}, "conf/icnidc/SongLE16": {"title": "A Service Discovery System based on Zookeeper with Priority Load Balance Strategy.", "url": "https://doi.org/10.1109/ICNIDC.2016.7974547", "year": "2016", "author": {"Meina Song": "95/4440", "Guimu Luo": "223/1345", "Haihong E": "43/10222"}, "abstract": " Abstract:The paper present a Dynamic Service Discovery System\n[1]\n with a Priority Load Balance Strategy. The system not only integrates Zookeeper\n[2]\n and tradition web project written with Spring and SpringMVC to achieve the dynamic service discovery function, which feeds the basic needs of the Priority Load Balance Strategy. The experimental test result shows that the new system has lots of advantages over the Traditional Service-Oriented Architecture and the load balance module gets a better performance."}, "conf/mobimedia/SongZEO16": {"title": "A Recommender System Model based on Commodity-Purchase-Cycle Classification.", "url": "http://dl.acm.org/citation.cfm?id=3021395", "year": "2016", "author": {"Meina Song": "95/4440", "Xue Zhou": "10/3434", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143"}, "abstract": "\n\t\tRecommender systems have been widely used in e-commerce platforms, such as Amazon and Taobao. Among the available recommendation algorithms, Item Collaborative Filtering (ItemCF) Algorithm and Content Filtering Algorithm have gained wide adoption because of various strengths. For example, hidden interests can be digged so as to get fresh recommendations, and highly individual recommendations can be made. Despite their strengths and wide adoption, there are still some weaknesses associated with them. One representative weakness is the existence of duplicated, and outdated recommendations due to the lack of purchasing cycles, e.g., weekly or seasonal, of goods. We name such cycles Commodity Purchase Cycle (CPC), and propose a new recommendation algorithm based on CPC in this paper. We leverage CPC attributes to modify the collaborative filtering output rating matrix acquired by the ItemCF Algorithm, and take into consideration both user behaviors and commodity characteristics to make timely recommendations. We utilize a realistic dataset from Taobao to verify the performance of the proposed algorithm. Experimental results demonstrate good performance of CPC algorithm. Specifically, from the perspective of Root Mean Square Error (RMSE), the CPC Algorithm promotes the recommendation accuracy by 15%-20%, compared with the state-of-the-art ItemCF Algorithm.\n\t"}, "conf/ucc/SongZEO16": {"title": "Statistic-based CRM approach via time series segmenting RFM on large scale data.", "url": "https://doi.org/10.1145/2996890.3007873", "year": "2016", "author": {"Meina Song": "95/4440", "Xuejun Zhao": "78/936", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143"}, "abstract": "\n\t\tCRM (Customer relationship management) plays a crucial role in detecting and gathering valuable users from externality and internality, where externality refers to customer relationship and internality is regarded as customer characteristics. However, conventional approaches based on RFM (recency, frequency and monetary) model have encountered with three challenges. First, traditional approaches that derive from survey data rather than objective large-scale data fail to apply the method in general scenario; Second, since there is several trial to experiment on RFM model changing over time, different segmentation of time leads to different results; Last, analysis of multiple characteristics either on externality or internality is sparse and separate, which betray the exploration purpose for CRM and make results unconvincing. To overcome the three limitations, a multiple statistic-based approach to value users via time series segmenting time interval of RFM on large scale data is proposed in the paper. In the aspect of telecom service data, we experiment on segmenting time interval methodologically for RFM model on data set more than millions of users. Besides, the most significant part there is formal mechanism to apply MCA (multiple corresponding analysis) on multiple characteristics for internality correspondingly with RFM for externality, leading to the deep relationships of users and their characteristics. Subsequently, we improve the traditional RFM model overtime from the different clustering steps on large-scale data.\n\t"}, "conf/icws/LiESS15": {"title": "User Familiar Degree Aware Recommender System.", "url": "https://doi.org/10.1109/ICWS.2015.58", "year": "2015", "author": {"Yusheng Li 0005": "00/577-5", "Haihong E": "43/10222", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": " Abstract:In a recommender system, items can be rated across multiple fields by users with varying degrees of familiarity. Hence, the ratings in a recommender system should have different recommended weights. Ratings in fields where in the user has high or low familiarity should be given high or low recommended weights, respectively. However, current recommendation algorithms ignore this problem and use the ratings indiscriminately, thus affecting the accuracy of the recommendation system. In this paper, we provide a focused study of user-familiarity degree-aware recommendation and develop a user-familiarity degree-aware latent factor model for recommendations that considers both user familiarity and item features reflected by the tagging information. We also design a user-familiarity degree-aware probability matrix factorization model, which computes the degree of familiarity of a user with the items he/she has rated. By using the user-familiarity degree, different recommended weights are given to every rating to obtain precise recommendations. The experiment results on real-world datasets show that our algorithm significantly outperforms state-of-the-art latent factor models and effectively improves the accuracy of the recommendation results."}, "conf/hucc/WangXS14": {"title": "A Scalable Network Proximity Estimate Algorithm for the Service Provider Selection Method.", "url": "https://doi.org/10.1007/978-3-319-15554-8_13", "year": "2014", "author": {"Ting Wang": "12/2633", "Ke Xu": "181/2626", "Meina Song": "95/4440"}, "abstract": "With the increasing development of overlay service network which contributes a significant portion of today’s network traffic, the selection of good service providers becomes more and more essential. In the selection, network distance is a very important parameter, and estimating network proximity is part of the network distance estimation. Although there exists a number of network proximity estimation technologies, they either require the distance measurement to all the potential targets, or fail when some landmark nodes are not available at a given instant of time. In this paper, we propose a network proximity technique that uses information obtained from probing a small number of landmarks. We firstly partite all the notes into different clusters based on their level vector such that nodes that fall within the same given cluster are relatively closer than those in the different clusters in terms of network latency. Then, for each cluster, the vector distance between the client and each service provider is combined with their ISP information to determine the K closest ones for the selection of the good service providers to consult. Our network proximity estimation strategy is simple, scalable, distributed with little support from the measurement infrastructures and no direct communications between the client and the service providers, and most importantly, it works well when some landmarks are invalid. Our strategy is tested using simulation. Our results indicate that the performance of network distance estimation in the service provider selection can be significantly improved by our scheme with limited measurements.KeywordsOverlay networkNetwork proximityService provider selectionLevel vector"}, "conf/hucc/WangSCS14": {"title": "Capacity Planning for Telecom Operation Support System Cloud Migration.", "url": "https://doi.org/10.1007/978-3-319-15554-8_35", "year": "2014", "author": {"Jinru Wang": "159/4487", "Meina Song": "95/4440", "Qian Chang": "64/7477", "Qin Shu": "89/6568"}, "abstract": "Currently, telecom operators are relying on cloud computing technologies to build a unified resource management platform. After the operation support system migrates to the cloud platform, the servers’ capacity planning is the key to ensure the performance of the system can meet customer’s requirements. We will do server capacity planning in this paper. This paper comes up with a method for capacity planning according to the features of telecom operation support system. On the one hand, considering that the system has different subsystems for various functions, we research the subsystems of operation support system separately; on the other hand, considering that system architecture is multi-layered, we research the system at web layer, application layer, data layer and storage layer, and do the capacity planning for each layer’s server. In the process of cloud migration, different subsystems and different layer of the system use different cloud computing technologies. We analyze different cloud computing technologies and put forward corresponding capacity planning methods.KeywordsCapacity planningCloud computingTelecom operation support system"}, "conf/icpads/JiangES14": {"title": "Hierarchical prediction based task scheduling in hybrid data center.", "url": "https://doi.org/10.1109/PADSW.2014.7097786", "year": "2014", "author": {"Haiou Jiang": "147/6051", "Haihong E": "43/10222", "Meina Song": "95/4440"}, "abstract": " Abstract:Cloud computing can help data center consolidate batch and gratis tasks with over-provisioned production applications, and fulfill their diverse resource demands and performance objectives with high scalability and flexibility. One challenge in this hybrid data center is that the dramatic fluctuation of batch and gratis workload may impact performance of production applications, cause task failure, decrease efficiency, and waste computing resources. One way to tackle the challenge is to reduce resource allocation to prevent host overload by delay scheduling tasks if resources are predicted in short. In this paper, we propose hierarchical prediction method for hybrid workload. We use last-state based ARMA model to predict stationary process of production workload, and use feedback based online AR model to predict the vibrated workload of batch and gratis tasks. Evaluation shows that the hierarchical prediction based task scheduling can reduce host overload by more than 85 percent, reduce tasks evicted and killed by more than 60 percent, and reduce 40 percent of average task scheduling delay."}, "conf/cbd/XinESST13": {"title": "Collaborative Book Recommendation Based on Readers' Borrowing Records.", "url": "https://doi.org/10.1109/CBD.2013.14", "year": "2013", "author": {"Liu Xin": "57/5236", "Haihong E": "43/10222", "Junde Song": "60/5010", "Meina Song": "95/4440", "Junjie Tong": "27/10222"}, "abstract": " Abstract:Book recommendation is an important part and task for personalized services and educations provided by the academic libraries. Many libraries have the readers' borrowing records without the readers' rating information on books. And the collaborative filtering (CF) algorithms are not proper under this circumstance. To apply the CF algorithms in book recommendation, in this paper, we construct the ratings from the readers' borrowing records to enable the CF algorithms. And to evaluate the traditional CF algorithms, we show that linearly combining (blending) a set of CF algorithms increases the accuracy and outperforms any single CF algorithms. At last, we conduct the experiments based on the real world dataset and the results invalidate the efficiency of the blending methods."}, "conf/hpcc/TongESSL13": {"title": "Web Service QoS Prediction under Sparse Data via Local Link Prediction.", "url": "https://doi.org/10.1109/HPCC.and.EUC.2013.328", "year": "2013", "author": {"Junjie Tong": "27/10222", "Haihong E": "43/10222", "Meina Song": "95/4440", "Junde Song": "60/5010", "Yanfei Li": "84/10447"}, "abstract": " Abstract:Client-side Quality-of-Service (QoS) evaluation of Web services is a critical factor in selecting the optimal Web service from a set of functionally equivalent service candidates. And collaborative filtering (CF) method becomes an important way for automatic QoS evaluation. Traditional CF approaches for this problem predict the QoS values by employing historical QoS information, but their performance may suffer from the sparsity of data such the increase of the failure rates and decrease of the accuracy. In this paper, we investigate the data sparsity problem in QoS value prediction. By constructing the user similarity weighted network, we use the modified local link prediction methods to find implicit neighbors to alleviate the lack of neighbors and low successful rate in predictions caused by the sparse data. We also consider the user location proximity and weak tie affection carefully in link prediction. The experiment results on the public dataset validate that via local link prediction, the accuracy and the successful rate both increase compared to the traditional user-based CF approach."}, "conf/icpca/FuYSZ13": {"title": "Mining Weighted Sequential Patterns in a Sequence Database with Itemset-Interval Measurement.", "url": "https://doi.org/10.1007/978-3-319-09265-2_10", "year": "2013", "author": {"Yu Fu": "09/3263", "Yanhua Yu": "124/5763", "Meina Song": "95/4440", "Xiaosu Zhan": "51/2179"}, "abstract": "Weighted sequential pattern mining algorithms discover weighted sequences with considering the different significance of each item in a sequence database. But current algorithms have not considered the importance of the itemset-intervals information between the two items in a same itemset. Hence, although a large number of sequences had been discovered, most of them are not useful for analysis. In this study, we propose a new algorithm, called ItemSet-interval Weighted Sequences (ISiWS), to solve the problem about efficient discovering useful sequences. In ISiWS, a matrix structure, called Transaction Bit Matrix (TBM), represents a sequence. ISiWS first uses TBMs to represent the sequences in a sequence database. Then, it utilizes projected technology to discover weighted sequences, and an approximate sequence match algorithm is applied to calculate support of sequences based on their itemset-intervals. Experiments show that ISiWS produces a significantly less number of weighted sequences than those of WSpan.Keywordsweighted sequential patterns miningapproximate sequence match algorithmtransaction bit matrixitemset-interval"}, "conf/icpca/JiangESS13": {"title": "A Generic Method of Migrating Enterprise Components Partially to the Cloud.", "url": "https://doi.org/10.1007/978-3-319-09265-2_22", "year": "2013", "author": {"Haiou Jiang": "147/6051", "Haihong E": "43/10222", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": "Hybrid migration of enterprise system is to move some components to the cloud, and leave others on premise based on their security or performance requirements. To make hybrid migration strategy, one challenge is how to choose constraints and use them to help determine which components to migrate, and which cloud to use. Existing methods, however, either limit to calculate the quantifiable constraints to generate several alternatives or just list all constraints without stating how to analyze and use them to filter alternatives. In this paper, we extend existing method to a two-phase process: 1) use quantifiable constraints to generate several alternatives; 2) use AHP (Analytic Hierarchy Process) to automate the best solution selection process based on the hierarchical unquantifiable constraints. Analysis shows that our method takes advantage of the accuracy of the quantifiable parameters as well as analysts’ subjective judgment of the importance of the unquantifiable constraints, so that generates a more precise solution meeting enterprise’s subjective requirements.Keywordshybrid migrationmigration strategyquantifiable and unquantifiable constraintsAHP"}, "conf/icpca/XinESST13": {"title": "Book Recommendation Based on Community Detection.", "url": "https://doi.org/10.1007/978-3-319-09265-2_37", "year": "2013", "author": {"Liu Xin": "57/5236", "Haihong E": "43/10222", "Junde Song": "60/5010", "Meina Song": "95/4440", "Junjie Tong": "27/10222"}, "abstract": "In many recommendation systems, the ‘best bet’ recommendations are shown, but the predicted rating values are not. This is usually referred to as a top-N recommendation task, where the goal of the recommendation system is to find a few specific items which are supposed to be most appealing to the user. While providing academic library services, recommending books for readers is a significant work for constructing personal learning environment. As behaviors in social networks and internet tend to be in groups and the behavior trends are influenced much by the influential entities. In this paper, we firstly propose methods for detecting communities with similar interesting by selecting influential entities. And then propose the recommendation algorithms based on the community detection. At last, by implementation the methods in the real world dataset, our methods perform better than the traditional collaborative algorithms in precision and recall.KeywordsTop-NCommunity DetectionInfluencerecommendation"}, "conf/icpca/TongESS13": {"title": "Multi-term and Range Query in Web Service Discovery.", "url": "https://doi.org/10.1007/978-3-319-09265-2_58", "year": "2013", "author": {"Junjie Tong": "27/10222", "Haihong E": "43/10222", "Junde Song": "60/5010", "Meina Song": "95/4440"}, "abstract": "The increasing popularity of Web service has exemplified the need for scalable and robust discovery mechanisms. Decentralized methods are widely researched for dealing this problem. And Peer-to-Peer (P2P) overlay network is one of the most important methods. But most of the current methods or P2P overlay network focus on single or multi term search without considering the requirements on quality of service (QoS). In this paper, we introduce a lightweight, scalable and robust WSDL discovery mechanism based local term calculations. The mechanism supports term and range query at the same time. That mechanism on one hand decreases the number of index while constructing P2P overlay network. And it supports range query for QoS on the other hand. The experiment on the real dataset shows the efficiency and correctness of that mechanism.KeywordsWeb ServiceWSDLMulti-term SearchRange Query"}, "conf/kdd/GuoYSSF13": {"title": "Soft-CsGDT: soft cost-sensitive Gaussian decision tree for cost-sensitive classification of data streams.", "url": "https://doi.org/10.1145/2501221.2501223", "year": "2013", "author": {"Ning Guo": "89/2184", "Yanhua Yu": "124/5763", "Meina Song": "95/4440", "Junde Song": "60/5010", "Yu Fu": "09/3263"}, "abstract": "\n\t\tNowadays in many real-world scenarios, high speed data streams are usually with non-uniform misclassification costs and thus call for cost-sensitive classification algorithms of data streams. However, only little literature focuses on this issue. On the other hand, the existing algorithms for cost-sensitive classification can achieve excellent performance in the metric of total misclassification costs, but always lead to obvious reduction of accuracy, which restrains the practical application greatly. In this paper, we present an improved folk theorem. Based on the new theorem, the existing accuracy-based classification algorithm can be converted into soft cost-sensitive one immediately, which allows us to take both accuracy and cost into account. Following the idea of this theorem, the soft-CsGDT algorithm is proposed to process the data streams with non-uniform misclassification costs, which is an expansion of GDT. With both synthetic and real-world datasets, the experimental results show that compared with the cost-sensitive algorithm, the accuracy in our soft-CsGDT is significantly improved, while the total misclassification costs are approximately the same.\n\t"}, "conf/icebe/GaoSX12": {"title": "Design and Implement of SOA-based Bridge Monitoring System Data Layer.", "url": "https://doi.org/10.1109/ICEBE.2012.28", "year": "2012", "author": {"Wendi Gao": "127/3914", "Meina Song": "95/4440", "Ke Xu": "181/2626"}, "abstract": " Abstract:General operation of bridge does not have perfect safety monitoring schemes, especially for long span bridge and high-speed railway bridge. Unbalanced bearing force can cause bridge deformation and even serious accidents. In order to provide a comprehensive and intelligent monitoring method, a bridge monitoring system architecture has been presented. This paper analyzes a kind of architecture of monitoring system in order to give a universal approach on bridge health monitoring. Then, it brings a design and implement of system data layer based on spring framework and web service technology by using service-oriented method to solve system heterogeneous issues. This data layer can effectively respond to rapid changes in business and will be maintained and extended easily."}, "conf/icpca/EJTSZ12": {"title": "Measure Method and Metrics for Network Characteristics in Service Systems.", "url": "https://doi.org/10.1007/978-3-642-37015-1_15", "year": "2012", "author": {"Haihong E": "43/10222", "Xiaojia Jin": "126/8100", "Junjie Tong": "27/10222", "Meina Song": "95/4440", "Xianzhong Zhu": "35/8542"}, "abstract": "As the development of Service-oriented architecture and service engineering, they have been generally adopted as the architecture and engineering method of software. More and more service applications and systems are constituted by distributed resources and web services which means more challenges in dynamic, varied and complex network environment. At the same time, the dependence and interactivity between the elements of networked service systems result in faults and difficulties in understanding and upgrading system and making the systems much more weakness. In this paper, according to the dynamic characteristics of the networked service system, we propose a network characteristics measure method and metrics for service system (MSS). Service system is defined by the descriptions of six important parameters at system level, which include service complexity, service cooperation relationship factor, service node factor, service cooperation factor, and service composition factor. Then the corresponding simulation is introduced by using the characteristics measure method and the analysis of the simulation results is also given. At last, a dynamic on-demand service composition algorithm based on MSS is designed and its feasibility and effectiveness are verified.Keywordsservice systemsnetwork characteristic measureservice cooperation relationship"}, "conf/icpca/XuZSS12": {"title": "A Content Aware and Name Based Routing Network Speed Up System.", "url": "https://doi.org/10.1007/978-3-642-37015-1_59", "year": "2012", "author": {"Ke Xu": "181/2626", "Hui Zhang": "181/2846", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": "The enormous increase in Internet traffic usage has been leading to problems such as increased complexity of routing topology, explosion in routing table entries, provider-dependent addressing, which reduce the speed of network service. The emerging new techniques such as CDN, P2P, VPN, etc. speed up the network from different perspectives. A new speed up system called CANR, content aware and name based routing, is proposed in this paper, which integrates benefits of several existing mehanisms. CANR consists of a cluster of proxy peers deployed in different network domains, which can work as collaborative routers, forwarding requests to each other to speed up the cross-domain visits. CANR can automatically aware the changes of network and re-construct name-based routing table based on a new multi objectie k shortest algoritm by itself, finding a set of cheapest and most fast k routing paths, which is different from current static preconfigured systems.Keywordsspeed upcontent awarename-based routingk short path"}, "conf/icpca/YueSHE12": {"title": "Location Context Aware Collective Filtering Algorithm.", "url": "https://doi.org/10.1007/978-3-642-37015-1_69", "year": "2012", "author": {"Wenjun Yue": "126/8099", "Meina Song": "95/4440", "Jing Han 0002": "90/2562-2", "Haihong E": "43/10222"}, "abstract": "To improve the quality of the recommendation of the recommendation system, a distance-interest affective model is proposed to combine user location context on the preferences of user interests. Based on the model and user-based collaborative filtering algorithm, the location context aware collective filtering algorithm is designed. Firstly, measure the location-similarity between users through the user’s location context information. Second, calculate the origin user-similarity from the user-item rating matrix. Then, gain the location-similarity as a weight of final user similarity, calculate the final similarity. Finally, recommendation is supplied by top-N recommendation. The simulation results were compared with the traditional algorithm to prove the precision and recall rate of the proposed algorithm is superior to traditional algorithms.Keywordsrecommender systemcollaborative filteringsimilarity measurelocation context"}, "conf/ACISicis/HanSS11": {"title": "A Novel Solution of Distributed Memory NoSQL Database for Cloud Computing.", "url": "https://doi.org/10.1109/ICIS.2011.61", "year": "2011", "author": {"Jing Han 0002": "90/2562-2", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": " Abstract:The traditional relational database to online storage are becoming increasingly problematic: the low performance do not gracefully meet the needs of mass data, the storage approaches of massive data are still not perfect presents. NoSQL and distributed memory database technologies have the potential to simplify or eliminate many of these challenges. NoSQL database technologies can provide Key-value style of data storage and largely ensure high performance. Distributed memory database technologies provide a means for easily store mass data in cloud in a dynamic and scalable manner. This paper argues for a new architecture called CDSA, which is a distributed memory NoSQL database architecture for Cloud computing to improve the performance of querying data and ensure mass data storage in cloud by using rational strategy. Furthermore, add or deleted any node from the distributed database cluster, the others node can work without stop service. We believe that CDSA can provide durable storage with high throughput and lower access latency."}, "conf/ACISicis/GuanXSS11": {"title": "A Survey of Research on Mobile Cloud Computing.", "url": "https://doi.org/10.1109/ICIS.2011.67", "year": "2011", "author": {"Guan Le": "127/3911", "Ke Xu": "181/2626", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": " Abstract:The rapid development of mobile computing and cloud computing trigger novel computing paradigm-----Mobile Cloud Computing. This paper review current research effort towards Mobile Computing. First, we present several challenges for the design of Mobile Cloud Computing service. Second, a concept model has been proposed to analyze related research work. Third, we survey recent Mobile Cloud Computing architecture, application partition & offloading, and context-aware service."}, "conf/cluster/ChenSSGS11": {"title": "HEaRS: A Hierarchical Energy-Aware Resource Scheduler for Virtualized Data Centers.", "url": "https://doi.org/10.1109/CLUSTER.2011.60", "year": "2011", "author": {"Hui Chen": "12/417", "Meina Song": "95/4440", "Junde Song": "60/5010", "Ada Gavrilovska": "76/3229", "Karsten Schwan": "s/KarstenSchwan"}, "abstract": " Abstract:With the increasing popularity of Internet-based cloud services, energy efficiency in large-scale Internet data centers has become important not only to curtail energy costs and alleviate environmental concern, but also because such systems can quickly reach the limits of power available to them. This paper investigates to what extent and how energy usage improvements through consolidation can benefit from taking into account the environmental influences and effects seen in data center systems. Toward that end, we present experimental results obtained in a fully instrumented, small scale data center and then use these results to propose a hierarchical energy-aware resource scheduler (HEaRS) for cluster workload placement and server provisioning, also considers the physical environment in which data center systems operate. Specifically, at the rack level, HEaRS tries to maintain a 'thermal balance' across the rack to avoid hot spots and reduce cooling costs. At the chassis level, HEaRS utilizes the proportional plus integral controller to achieve a balance in the levels of usage of electrical current between the two power domains in the chassis, which helps the chassis reach its most energy efficient state. Finally, at server level, HEaRS can employ known methods like dynamic voltage and frequency scaling or core idling to reduce power consumption. This results in a hierarchical set of controllers that jointly, implement holistic solutions to energy-aware resource scheduling for an entire rack, and this hierarchical solution can then be further extended to entire data centers. Our initial experiment result show opportunities for gains, with up to 16% in energy usage compared to methods that are not aware of the physical environment and up to 15% improvements in application performance."}, "conf/green/ChenSSGSK11": {"title": "CACM: Current-aware capacity management in consolidated server enclosures.", "url": "https://doi.org/10.1109/IGCC.2011.6008588", "year": "2011", "author": {"Hui Chen": "12/417", "Meina Song": "95/4440", "Junde Song": "60/5010", "Ada Gavrilovska": "76/3229", "Karsten Schwan": "s/KarstenSchwan", "Mukil Kesavan": "43/5343"}, "abstract": " Abstract:Using virtualization to consolidate servers is a routine method for reducing power consumption in data centers. Current practice, however, assumes homogeneous servers that operate in a homogeneous physical environment. Experimental evidence collected in our mid-size, fully instrumented data center challenges those assumptions, by finding that chassis construction can significantly influence cooling power usage. In particular, the multiple power domains in a single chassis can have different levels of power efficiency, and further, power consumption is affected by the differences in electrical current levels across these two domains. This paper describes experiments designed to validate these facts, followed by a proposed current-aware capacity management system (CACM) that controls resource allocation across power domains by periodically migrating virtual machines among servers. The method not only fully accounts for the influence of current difference between the two domains, but also enforces power caps and safety levels for node temperature levels. Comparisons with industry-standard techniques that are not aware of physical constraints show that current-awareness can improve performance as well as power consumption, with about 16% in energy savings. Such savings indicate the utility of adding physical awareness to the ways in which IT systems are managed."}, "conf/iceis/HaoSHS11": {"title": "A Cloud Computing Model based on Hadoop with an Optimization of Its Task Scheduling Algorithms.", "url": "", "year": "2011", "author": {"Yulu Hao": "12/10222", "Meina Song": "95/4440", "Jing Han 0002": "90/2562-2", "Junde Song": "60/5010"}, "abstract": ""}, "conf/iceis/TongSSX11": {"title": "Discipline and Infrastructures of Constructing Service Overlay Network.", "url": "", "year": "2011", "author": {"Junjie Tong": "27/10222", "Meina Song": "95/4440", "Junde Song": "60/5010", "Ke Xu": "181/2626"}, "abstract": ""}, "conf/dbta/QiuSLS10": {"title": "Relay Selection and Power Allocation Scheme for Cellular Network Using Cooperative Diversity.", "url": "https://doi.org/10.1109/DBTA.2010.5658935", "year": "2010", "author": {"Lin Qiu": "82/4490", "Meina Song": "95/4440", "Lianru Liu": "69/8840", "Junde Song": "60/5010"}, "abstract": " Abstract:In this paper,a novel network architecture that incorporating cooperative diversity techniques to increase the cellular network throughput is proposed.We design a relay selection strategy in this network architecture design,where the proxy node will select a relay node based on the channel quality and nodes'residual energy to enhance the users'fairness among the nodes. Moreover,we propose a novel power allocation scheme to minimize the power consumption of the whole network.The implementation of the algorithm is given to show that the proposed relay selection and power allocation scheme can provide significant network performance improvement in terms of network power consumption and quality of service due to the using of cooperative diversity techniques."}, "conf/icica/JiangSLX10": {"title": "An Novel Encryption Protocol for Mobile Data Synchronization Based on SyncML.", "url": "https://doi.org/10.1007/978-3-642-16336-4_1", "year": "2010", "author": {"Chao Jiang": "38/2068", "Meina Song": "95/4440", "Ke Liu": "32/2948", "Ke Xu": "181/2626"}, "abstract": "SyncML provides identity authentication service for the security of the data synchronization protocol at the server layer and database layer,. But the data is transmitted in cleartext XML after the authentication. These data are not encrypted and it is easy to be tapped. In order to enhance its security, this paper provides us a novel encryption data synchronization protocol which uses hierarchical encryption algorithms. Finally, an example is presented to illustrate this protocol and architecture.KeywordsSyncMLpublic-key algorithmRSAsymmetric algorithmAES"}, "conf/service/XuSZ10": {"title": "Home Appliance Mashup System Based on Web Service.", "url": "https://doi.org/10.1109/ICSS.2010.61", "year": "2010", "author": {"Ke Xu": "181/2626", "Meina Song": "95/4440", "Xiaoqi Zhang": "60/7678"}, "abstract": " Abstract:With the development of Network Appliance, more and more mechanisms about network control have been introduced to improve the performance and the user experience. Since the cost of web-based interfaces is considerably low, Web can be used to provide the infrastructure for the design of simple and user-friendly interfaces for household appliances. In this paper, we propose a new system which can share the home appliance abilities to Internet as Web Service. By our system, a lot of Web Based Network Appliance related applications can be developed easily and give end users more friendly, flexible control interfaces. Furthermore, functions of different appliances can be integrated to provide more complex service to user, which is named Home Appliance Mashup in this paper."}, "conf/service/Hai-hongSSLR10": {"title": "The Research of Service Network Based on Complex Network.", "url": "https://doi.org/10.1109/ICSS.2010.41", "year": "2010", "author": {"Haihong E": "43/10222", "Meina Song": "95/4440", "Junde Song": "60/5010", "Yan Li": "87/660", "Zhijun Ren": "60/10775"}, "abstract": " Abstract:At present the service science and engineering research are mainly focus on service discovery, service composition, service reputation and other key technical of the service computing. However the basic theory of service science, in particular, the basic principle of service and the evolution mechanism of service network only have some preliminary of research and exploration. The atomic services as the network nodes and the relationships of services combination as the network edges constitute the service network based services provision environment. This paper researched the basic characteristics of services and service networks, and proposed a new research method to explore the service network's \"small world\", \"scale-free\" characteristics and service network topology, based on the theory of complex network and existing networked software research works. It presents a new research perspective and methods for the service science and engineering research."}, "conf/service/QiuS10": {"title": "QoS Oriented Cross-Layer Design for Supporting Multimedia Services in Cooperative Networks.", "url": "https://doi.org/10.1109/ICSS.2010.19", "year": "2010", "author": {"Lin Qiu": "82/4490", "Meina Song": "95/4440"}, "abstract": " Abstract:Providing Quality of Service (QoS) for multimedia communication is a challenging problem in wireless multi-hop networks using cooperative diversity. In this paper, we present a fully distributed cross-layer design algorithm incorporating delay constraint in order to support real-time multimedia services. We utilize network utility maximization framework in the cross-layer design algorithm modeling. The proposed algorithm joint solve congestion-control problem and routing problem using convex optimization method. Moreover, we design an End-to-end Delay Framework for delay constraint modeling when analyzing the network utility maximization problem such that QoS guarantees for multimedia communication is enhanced. Convergence Analysis indicates that this algorithm can converge, which is the expected outcome for providing QoS in supporting multimedia services."}, "conf/service/ZhangSX10": {"title": "A Mobile P2P Community System.", "url": "https://doi.org/10.1109/ICSS.2010.55", "year": "2010", "author": {"Xiaoqi Zhang": "60/7678", "Meina Song": "95/4440", "Ke Xu": "181/2626"}, "abstract": " Abstract:The distributed architecture of vitual community based on P2P has proved to resolves some problems from central architecture such as single point failure. In this paper, drawing on the idea of SOA, we propose an optimized architecture of distributed mobile P2P community system, in which the virtual communities are divided into separately service components which can be deployed in the overlay networks as resource instead of a central server. And the introduction of the physical network aware technique of P4P can help the client find the most suitable service replica. We also propose a replica consistent control mechanism to facilitate the practice of the system in this paper. At last we develope a prototype system of mobile community."}, "conf/icebe/ZhangSS09": {"title": "A Solution of Electronic Authentication Services Based on PKI for Enabling e-Business.", "url": "https://doi.org/10.1109/ICEBE.2009.67", "year": "2009", "author": {"Xiaoqi Zhang": "60/7678", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": " Abstract:As the basic application of PKI (Public Key Infrastructure) theories and technologies, electronic authentication services (thereinafter referred to as EAS) is defined as to provide authentic identities and identity verification services for participants involved in network-based activities. Due to its complexity of constructing PKI, most application systems including e-business platforms need to integrate EAS provided by a third party into their own business processes. Based on exploration on the requirements of EAS for e-business together with careful study and engineering practice in this area, this paper presents a complete solution of EAS based on PKI for enabling e-business. Architecture of EAS and its functionality components are brought forth and illustrated first. Then we brought forward a cross-domain trust model and method of managing different trust sources to achieve cross-domain trust and configurable trust-policy. To integrate EAS with e-business systems agilely, we put forward an agile integrating solution utilizing technologies such as Web service and remote scripting."}, "conf/gpc/OuSCS08": {"title": "Layered Peer-to-Peer Architecture for Mobile Web Services via Converged Cellular and Ad Hoc Networks.", "url": "https://doi.org/10.1109/GPC.WORKSHOPS.2008.42", "year": "2008", "author": {"Zhonghong Ou": "58/6143", "Meina Song": "95/4440", "Hui Chen": "12/417", "Junde Song": "60/5010"}, "abstract": " Abstract:Mobile communication technology is rapidly developed with the enhanced networking capacities as well as the expanding population of mobile subscribers. Providing Web services via converged mobile cellular and Ad Hoc networks has attracted growing attentions. In this paper, a layered peer-to-peer (P2P) architecture is designed for providing Web services via converged mobile cellular and Ad Hoc networks. To speed up the service discovery, a vertical tunneling model is developed as well as the service being classified into \"hot\", \"warm \" and \"cold\". A plug-and-play middleware architecture is developed enabling mobile Web services communication and adapting the heterogeneity of mobile terminals. The diagram of the message sequences implementing the plug-and-play middleware architecture is designed with the case of weather service provision."}, "conf/vtc/ChiSS08": {"title": "Extended WDB Algorithm for QoS Enhancement in IEEE 802.11e WLAN.", "url": "https://doi.org/10.1109/VETECF.2008.308", "year": "2008", "author": {"Jing Chi": "03/627", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": " Abstract:The paper proposes an extended waiting-time dependent backoff (EWDB) algorithm for IEEE 802.11e WLAN as an extension of our previous WDB method. Concerning the QoS limitations of EDCA, EWDB controls backoff window (BW) according to waiting-time (WT), and staggers BW ranges among prioritized services. The algorithm is based on a flexible mathematic model consisting of deterministic function and random function. Backoff functions are respectively designed for voice, video and data. WT-dependent sub-priority is introduced for voice and video. An overlap-restricted backoff function is designed for data traffic. Simulation results show the superiority of EWDB to EDCA in terms of jitter and delay of voice/video, throughput of data, as well as overall collision rate under different network load."}, "conf/csac/YuSSZ06": {"title": "System Architecture Design for WAP Services Based on MISC Platform.", "url": "", "year": "2006", "author": {"Qun Yu": "64/6517", "Meina Song": "95/4440", "Junde Song": "60/5010", "Xiaosu Zhan": "51/2179"}, "abstract": ""}, "conf/csac/SongZS06": {"title": "Mining Self-similarity in Time Series.", "url": "", "year": "2006", "author": {"Meina Song": "95/4440", "Xiaosu Zhan": "51/2179", "Junde Song": "60/5010"}, "abstract": ""}, "conf/er/DuanTYS04": {"title": "Association Rule Mining Based on the Multiple-Dimensional Item Attributes.", "url": "https://doi.org/10.1007/978-3-540-30466-1_24", "year": "2004", "author": {"Yunfeng Duan": "37/1915", "Shiwei Tang": "t/ShiweiTang", "Dongqing Yang": "65/661", "Meina Song": "95/4440"}, "abstract": "The association rule mining is an important topic in recent data mining research. In this paper, a new association rule mining method based on the multiple-dimensional item attributes is proposed through the Market Basket Analysis. The corresponding average weight support is defined, and the AWMAR algorithm is described in detail. Finally, the performance study and results analysis of the improved algorithm is presented. AWMAR algorithm is effective for mining the association rules with acceptable running time."}, "journals/midm/BiKESTTL22": {"title": "Research on early warning of renal damage in hypertensive patients based on the stacking strategy.", "url": "https://doi.org/10.1186/s12911-022-01889-4", "year": "2022", "author": {"Qiubo Bi": "326/5564", "Ze-min Kuang": "305/5265", "Haihong E": "43/10222", "Meina Song": "95/4440", "Ling Tan": "94/5700", "Xinying Tang": "57/8498", "Xing Liu": "87/3144"}, "abstract": ""}, "journals/cmpb/ZhangEYHZZWSW21": {"title": "MBNM: Multi-branch network based on memory features for long-tailed medical image recognition.", "url": "https://doi.org/10.1016/j.cmpb.2021.106448", "year": "2021", "author": {"Ruru Zhang": "139/7990", "Haihong E": "43/10222", "Lifei Yuan": "307/5604", "Jiawen He": "256/7881", "Hongxing Zhang": "248/7826", "Shengjuan Zhang": "307/6291", "Yanhui Wang": "08/5728", "Meina Song": "95/4440", "Lifei Wang": "74/4143"}, "abstract": "Background and objectivesDeep learning algorithms show revolutionary potential in computer-aided diagnosis. These computer-aided diagnosis techniques often rely on large-scale, balanced standard datasets. However, there are many rare diseases in real clinical scenarios, which makes the medical datasets present a highly imbalanced long-tailed distribution, leading to the poor generalization ability of deep learning models. Currently, most algorithms to solve this problem involve more complex modules and loss functions. But for complicated tasks in the medical domain, usually suffer from issues such as increased inference time and unstable performance. Therefore, it is a great challenge to develop a computer-aided diagnosis algorithm for long-tailed medical data.MethodsWe proposed the Multi-Branch Network based on Memory Features (MBNM) for Long-Tailed Medical Image Recognition. MBNM includes three branches, where each branch focuses on a different learning task: 1) the regular learning branch learns the generalizable feature representations; 2) the tail learning branch gains extra intra-class diversity for the tail classes through the feature memory module and the improved reverse sampler to improve the classification performance of the tail classes; 3) the fusion balance branch integrates various decision-making advantages and introduces an adaptive loss function to re-balance the classification performance of easy and difficult samples.ResultsWe conducted experiments on the multi-disease Ophthalmic OCT datasets with imbalance factors of 98.48 and skin image datasets Skin-7 with imbalance factors of 58.3. The Accuracy, MCR, F1-Score, Precision, and AUC of our model were significantly improved over the strong baselines in the auxiliary diagnosis scenario where the clinical medical data is extremely imbalanced. Furthermore, we demonstrated that MBNM outperforms the state-of-the-art models on the publicly available natural image datasets (CIFAR-10 and CIFAR-100).ConclusionsThe proposed algorithm can solve the problem of imbalanced data distribution with little added cost. In addition, the memory module does not act in the inference phase, thereby saving inference time. And it shows outstanding performance on medical images and natural images with a variety of imbalance factors."}, "journals/iotj/OuHSYH21": {"title": "Redundancy Removing Aggregation Network With Distance Calibration for Video Face Recognition.", "url": "https://doi.org/10.1109/JIOT.2020.3038776", "year": "2021", "author": {"Zhonghong Ou": "58/6143", "Yucheng Hu": "59/9331", "Meina Song": "95/4440", "Zheng Yan 0002": "43/180-2", "Pan Hui 0001": "62/1272-1"}, "abstract": " Abstract:Attention-based techniques have been successfully used for rating image quality, and have been widely employed for set-based face recognition. Nevertheless, for video face recognition, where the base convolutional neural network (CNN) trained on large-scale data already provides discriminative features, fusing features with only predicted quality scores to generate representation are likely to cause duplicate sample dominant problem, and degrade performance correspondingly. To resolve the problem mentioned above, we propose a redundancy removing aggregation network (RRAN) for video face recognition. Compared with other quality-aware aggregation schemes, RRAN can take advantage of similarity information to tackle the noise introduced by redundant video frames. By leveraging metric learning, RRAN introduces a distance calibration scheme to align distance distributions of negative pairs of different video representations, which improves the accuracy under a uniform threshold. A series of experiments is conducted on multiple realistic data sets to evaluate the performance of RRAN, including YouTube Faces, IJB-A, and IJB-C. In comprehensive experiments, we demonstrate that our method can diminish the overall influence of poor quality components with large proportion in the video and further improve the overall recognition performance with individual difference. Specifically, RRAN achieves a 96.84% accuracy on YouTube Face, outperforming all existing aggregation schemes."}, "journals/corr/abs-2112-12386": {"title": "KFWC: A Knowledge-Driven Deep Learning Model for Fine-grained Classification of Wet-AMD.", "url": "https://arxiv.org/abs/2112.12386", "year": "2021", "author": {"Haihong E": "43/10222", "Jiawen He": "256/7881", "Tianyi Hu": "158/7565", "Lifei Wang": "74/4143", "Lifei Yuan": "307/5604", "Ruru Zhang": "139/7990", "Meina Song": "95/4440"}, "abstract": "\n      Abstract:  Automated diagnosis using deep neural networks can help ophthalmologists\ndetect the blinding eye disease wet Age-related Macular Degeneration (AMD).\nWet-AMD has two similar subtypes, Neovascular AMD and Polypoidal Choroidal\nVessels (PCV). However, due to the difficulty in data collection and the\nsimilarity between images, most studies have only achieved the coarse-grained\nclassification of wet-AMD rather than a finer-grained one of wet-AMD subtypes.\nTo solve this issue, in this paper we propose a Knowledge-driven Fine-grained\nWet-AMD Classification Model (KFWC), to classify fine-grained diseases with\ninsufficient data. With the introduction of a priori knowledge of 10 lesion\nsigns of input images into the KFWC, we aim to accelerate the KFWC by means of\nmulti-label classification pre-training, to locate the decisive image features\nin the fine-grained disease classification task and therefore achieve better\nclassification. Simultaneously, the KFWC can also provide good interpretability\nand effectively alleviate the pressure of data collection and annotation in the\nfield of fine-grained disease classification for wet-AMD. The experiments\ndemonstrate the effectiveness of the KFWC which reaches 99.71% in AU-ROC\nscores, and its considerable improvements over the data-driven w/o Knowledge\nand ophthalmologists, with the rates of 6.69% over the strongest baseline and\n4.14% over ophthalmologists.\n\n    "}, "journals/access/EZS20": {"title": "Table-to-Dialog: Building Dialog Assistants to Chat With People on Behalf of You.", "url": "https://doi.org/10.1109/ACCESS.2020.2998432", "year": "2020", "author": {"Haihong E": "43/10222", "Zecheng Zhan": "241/6016", "Meina Song": "95/4440"}, "abstract": " Abstract:Artificial Intelligence (AI) personal assistant has attracted much attention from both academia and industry. Almost all existing AI personal assistants serve as service terminals to chat with human users for certain tasks. We are instead interested in building AI personal assistants for a different yet important dialog scenario, where they chat with people to fulfill specific tasks on behalf of their human users. As the personal assistants are playing a requester role, instead of a service terminal role, the conversation goal becomes delivering or requesting information according to specific user requests precisely and efficiently. The challenge for the conversation policy is that all user requests must be delivered precisely, while the challenge for the response generation is that it's generally expected for machine generated responses to cover multiple information slots, either requesting or delivering, to make the conversation efficient. In this paper, we present Table-to-Dialogue, a novel approach to address the above challenges when building a requester role AI personal assistant. We employ an encoder-decoder network to learn explicit conversation policy, which generates the corresponding information slots based on the conversation context and the user request table. We further integrate a novel Multi-Slot Constrained Bi-directional Decoder (MS-CBD) into the above encoder-decoder network, to generate machine response according to the multiple slot values and their intermediate representations from the policy decoder. Different from the existing single direction text decoder approaches, MS-CBD leverage the bi-directional context of the response when generating it to enhance the semantic coherence. The experiments shows that our approach significantly outperform the state-of-the-art conversation approaches on automatic and human evaluation metrics."}, "journals/nca/SongZE20": {"title": "KGAnet: a knowledge graph attention network for enhancing natural language inference.", "url": "https://doi.org/10.1007/s00521-020-04851-5", "year": "2020", "author": {"Meina Song": "95/4440", "Wen Zhao": "17/118", "Haihong E": "43/10222"}, "abstract": "Natural language inference (NLI) is the basic task of many applications such as question answering and paraphrase recognition. Existing methods have solved the key issue of how the NLI model can benefit from external knowledge. Inspired by this, we attempt to further explore the following two problems: (1) how to make better use of external knowledge when the total amount of such knowledge is constant and (2) how to bring external knowledge to the NLI model more conveniently in the application scenario. In this paper, we propose a novel joint training framework that consists of a modified graph attention network, called the knowledge graph attention network, and an NLI model. We demonstrate that the proposed method outperforms the existing method which introduces external knowledge, and we improve the performance of multiple NLI models without additional external knowledge."}, "journals/corr/abs-2009-14653": {"title": "RTFE: A Recursive Temporal Fact Embedding Framework for Temporal Knowledge Graph Completion.", "url": "https://arxiv.org/abs/2009.14653", "year": "2020", "author": {"Youri Xu": "275/8967", "Haihong E": "43/10222", "Meina Song": "95/4440"}, "abstract": "\n      Abstract:  Static knowledge graph (SKG) embedding (SKGE) has been studied intensively in\nthe past years. Recently, temporal knowledge graph (TKG) embedding (TKGE) has\nemerged. In this paper, we propose a Recursive Temporal Fact Embedding (RTFE)\nframework to transplant SKGE models to TKGs and to enhance the performance of\nexisting TKGE models for TKG completion. Different from previous work which\nignores the continuity of states of TKG in time evolution, we treat the\nsequence of graphs as a Markov chain, which transitions from the previous state\nto the next state. RTFE takes the SKGE to initialize the embeddings of TKG.\nThen it recursively tracks the state transition of TKG by passing updated\nparameters/features between timestamps. Specifically, at each timestamp, we\napproximate the state transition as the gradient update process. Since RTFE\nlearns each timestamp recursively, it can naturally transit to future\ntimestamps. Experiments on five TKG datasets show the effectiveness of RTFE.\n\n    "}, "journals/access/SongZE19": {"title": "Hierarchical Schema Representation for Text-to-SQL Parsing With Decomposing Decoding.", "url": "https://doi.org/10.1109/ACCESS.2019.2931464", "year": "2019", "author": {"Meina Song": "95/4440", "Zecheng Zhan": "241/6016", "Haihong E": "43/10222"}, "abstract": " Abstract:Most of existing studies on parsing natural language (NL) for constructing structured query language (SQL) do not consider the complex structure of database schema and the gap between NL and SQL query. In this paper, we propose a schema-aware neural network with decomposing architecture, namely HSRNet, which aims to address the complex and cross-domain Text-to-SQL generation task. The HSRNet models the relationship of the database schema with a hierarchical schema graph and employs a graph network to encode the information into sentence representation. Instead of end-to-end generation, the HSRNet decomposes the generation process into three phases. Given an input question and schema, we first choose the column candidates and generate the sketch grammar of the SQL query. Then, a detail completion module fills the details based on the column candidates and the corresponding sketch. We demonstrate the effectiveness of our hierarchical schema representation by incorporating the information into different baselines. We further show that the decomposing architecture significantly improves the performance of our model. Evaluation of Spider benchmark shows that the hierarchical schema representation and decomposing architecture improves our parser result by 14.5% and 4.3% respectively."}, "journals/access/OuLKSS19": {"title": "CNN Compression-Recovery Framework via Rank Allocation Decomposition With Knowledge Transfer.", "url": "https://doi.org/10.1109/ACCESS.2019.2932773", "year": "2019", "author": {"Zhonghong Ou": "58/6143", "Yunfeng Liu": "56/5650", "Huihui Kong": "247/3690", "Meina Song": "95/4440", "Yingxia Shao": "131/2926"}, "abstract": " Abstract:Low-rank decomposition is an effective way to decrease the model size of convolutional neural networks (CNNs). Nevertheless, selecting the layer-specific rank is a difficult task, because the layers are not equally redundant. The previous methods are mainly by manual, require expertise, or do not consider the different sensitivity of each layer. This paper proposes a rank allocation decomposition (RAD) method to decompose network by allocating rank for each layer automatically. The idea is to transform the combinatorial optimization problem of rank into a constrained optimal search problem, which can be solved by a greedy algorithm. To recover accuracy of the decomposed network, a novel knowledge transfer based approach is introduced, named SchoolNet. It aligns outputs and intermediate responses from the original (teacher) network to its compressed (student) network while transferring dark knowledge from a strong (headmaster) network with high accuracy to the student network. The experimental results from several advanced models, including AlexNet, VGG-16, and ResNet-50, demonstrate that our scheme can reduce parameters significantly while maintaining a high accuracy level. Specifically, for the VGG-16 on Birds-200 dataset, we achieve 48x compression rate with even 0.13% top-1 accuracy improvement, which outperforms the state-of-the-art remarkably."}, "journals/access/OuXXSS19": {"title": "FAMN: Feature Aggregation Multipath Network for Small Traffic Sign Detection.", "url": "https://doi.org/10.1109/ACCESS.2019.2959015", "year": "2019", "author": {"Zhonghong Ou": "58/6143", "Fenrui Xiao": "255/7890", "Baiqiao Xiong": "255/8201", "Shenda Shi": "255/8207", "Meina Song": "95/4440"}, "abstract": " Abstract:Traffic sign detection has achieved promising results in recent years. Nevertheless, there are still two problems remain to be overcome. One problem is the detection of small traffic signs, which usually occupy less than 2% of the image area. The other problem is fine-grained classification, with difficulties arising from similar appearances between traffic signs. For example, different speed-limit traffic signs have differences solely from the speed numbers. In this paper, we propose a Feature Aggregation MultiPath Network (FAMN) to tackle the problems simultaneously. First, we propose a Feature Aggregation (FA) structure to aggregate regional features from different feature maps by using element-wise Max, then convolution layers are used to extract rich semantic features. Accordingly, objects of different scales can choose the best features to improve performance of small object detection. Second, we propose a Multipath Network (MN) structure to obtain fine-grained features. The MN structure consists of three paths, extracting instance-level, part-level, and context-level features, respectively. The three types of features are then concatenated to form fine-grained features of the proposals. Experimental results demonstrate the effectiveness of our proposed FAMN. Specifically, FAMN is able to obtain an average F1-measure of 93.1% in TT100K dataset, 2.9% higher than the state-of-the-art."}, "journals/corr/abs-1907-00390": {"title": "A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling.", "url": "http://arxiv.org/abs/1907.00390", "year": "2019", "author": {"Haihong E": "43/10222", "Peiqing Niu": "244/1979", "Zhongfu Chen": "244/2567", "Meina Song": "95/4440"}, "abstract": "\n      Abstract:  A spoken language understanding (SLU) system includes two main tasks, slot\nfilling (SF) and intent detection (ID). The joint model for the two tasks is\nbecoming a tendency in SLU. But the bi-directional interrelated connections\nbetween the intent and slots are not established in the existing joint models.\nIn this paper, we propose a novel bi-directional interrelated model for joint\nintent detection and slot filling. We introduce an SF-ID network to establish\ndirect connections for the two tasks to help them promote each other mutually.\nBesides, we design an entirely new iteration mechanism inside the SF-ID network\nto enhance the bi-directional interrelated connections. The experimental\nresults show that the relative improvement in the sentence-level semantic frame\naccuracy of our model is 3.79% and 5.42% on ATIS and Snips datasets,\nrespectively, compared to the state-of-the-art model.\n\n    "}, "journals/cluster/JiangES18": {"title": "Multi-prediction based scheduling for hybrid workloads in the cloud data center.", "url": "https://doi.org/10.1007/s10586-018-2265-1", "year": "2018", "author": {"Haiou Jiang": "147/6051", "Haihong E": "43/10222", "Meina Song": "95/4440"}, "abstract": "Cloud computing can leverage over-provisioned resources that are wasted in traditional data centers hosting production applications by consolidating tasks with lower QoS and SLA requirements. However, the dramatic fluctuation of workloads with lower QoS and SLA requirements may impact the performance of production applications. Frequent task eviction, killing and rescheduling operations also waste CPU cycles and create overhead. This paper aims to schedule hybrid workloads in the cloud data center to reduce task failures and increase resource utilization. The multi-prediction model, including the ARMA model and the feedback based online AR model, is used to predict the current and the future resource availability. Decision to accept or reject a new task is based on the available resources and task properties. Evaluations show that the scheduler can reduce the host overload and failed tasks by nearly 70%, and increase effective resource utilization by more than 65%. The task delay performance degradation is also acceptable."}, "journals/jss/OuSHYWCH18": {"title": "Is cloud storage ready? Performance comparison of representative IP-based storage systems.", "url": "https://doi.org/10.1016/j.jss.2018.01.015", "year": "2018", "author": {"Zhonghong Ou": "58/6143", "Meina Song": "95/4440", "Zhen-Huan Hwang": "177/5000", "Antti Ylä-Jääski": "63/5415", "Ren Wang 0001": "29/50-1", "Yong Cui 0001": "91/2346-1", "Pan Hui 0001": "62/1272-1"}, "abstract": "Network based storage systems have traditionally been dominated by Network Attached Storage (NAS) and Storage Area Network (SAN). Cloud based storage systems, including object storage, have gained growing popularity among both private and enterprise users in recent years. Certain enterprises have even considered replacing traditional storage systems with cloud-based systems. Nevertheless, there still lacks a systematic comparative study on the performance of the aforementioned systems to assist such a transition. To fill in this gap, in this paper, we conduct a comprehensive study on the three major network storage systems with realistic network conditions and application behaviours. Specifically, we select one representative from each category for comparison, i.e., Network File System (NFS) from NAS, Internet Small Computer System Interface (iSCSI) from SAN, and OpenStack Swift from cloud storage. As the first study of its kind, we mainly focus on the client-side and take performance as the perspective for comparison. We build a testbed and a suite of micro-benchmarks to study the impact of network complexities and access behaviours on performance. In addition, we employ two widely used macro-benchmarks – PostMark and FileBench – to test the three systems under realistic workloads. Through a set of comprehensive experiments and thorough analysis, we make several key observations. (1) iSCSI excels under good network conditions, e.g., in local area networks (LANs); when network complexities like network delay and packet loss exist, its performance degrades significantly, especially for data-intensive operations. (2) For Internet-like environments, NFS performs poorly, while Swift demonstrates much resilience. (3) Overall, Swift is a viable replacement for NFS in all network scenarios, while it is not ready yet to replace iSCSI for performance-critical environments. (4) System configuration on the client side impacts storage performance significantly and deserves adequate attention. Based on our experimental study, we also make several recommendations to practitioners and pinpoint aspects for system designers to improve each storage system further."}, "journals/ieicet/JiangES17": {"title": "Dynamic Scheduling of Workflow for Makespan and Robustness Improvement in the IaaS Cloud.", "url": "https://doi.org/10.1587/transinf.2016EDP7346", "year": "2017", "author": {"Haiou Jiang": "147/6051", "Haihong E": "43/10222", "Meina Song": "95/4440"}, "abstract": ""}, "journals/ijon/RenSES17": {"title": "Context-aware probabilistic matrix factorization modeling for point-of-interest recommendation.", "url": "https://doi.org/10.1016/j.neucom.2017.02.005", "year": "2017", "author": {"Xingyi Ren": "198/2775", "Meina Song": "95/4440", "Haihong E": "43/10222", "Junde Song": "60/5010"}, "abstract": "The rapid development of location-based social networks (LBSNs) has provided an unprecedented opportunity for better location-based services through Point-of-Interest (POI) recommendation. POI recommendation is personalized, location-aware, and context depended. However, extreme sparsity of user-POI matrix creates a severe challenge. In this paper, we propose a context-aware probabilistic matrix factorization method for POI recommendation. Our model is called TGSC-PMF, it exploits textual information, geographical information, social information, categorical information and popularity information, and incorporates these factors effectively. First, we exploit an aggregated Latent Dirichlet Allocation (LDA) model to learn the interest topics of users and infer the interest POIs by mining textual information associated with POIs and generate interest relevance score. Second, we propose a kernel estimation method with an adaptive bandwidth to model the geographical correlations and then generate geographical relevance score. Third, we build social relevance through the power-law distribution of user social relations to generate social relevance score. Then, we model the categorical correlations which combine the category bias of users and the popularity of POIs into categorical relevance score. Further, we integrate the interest, geographical, social and categorical relevance scores into probabilistic matrix factorization model (PMF) for POI recommendation. Finally, we implement experiments on a real LBSN check-in dataset. Experimental results show that TGSC-PMF achieves significantly superior recommendation quality compared to other state-of-the-art POI recommendation techniques."}, "journals/kbs/SongZEO17": {"title": "Statistics-based CRM approach via time series segmenting RFM on large scale data.", "url": "https://doi.org/10.1016/j.knosys.2017.05.027", "year": "2017", "author": {"Meina Song": "95/4440", "Xuejun Zhao": "78/936", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143"}, "abstract": "Conventional customer relationship management (CRM) is typically based on RFM model, whose parameters are the recency, frequency and monetary aspects of target customers. The latest comprehensive analysis has enabled CRM to present parameters with time series. For example, researchers can account for changing trends based on an RFM model for flexible marketing strategies. Such changes might inspire telecommunication service scenarios that user value relies on long-term performance. In this study, we propose a statistic-based approach to value latent users via time series segmenting time interval of RFM in large scale data set. Apart from utilizing in Spark platform, we integrate multiple corresponding analysis (MCA) to regularize clustering results by the RFM model and extend these approaches to multiple levels. A comprehensive set of experiments, revealed interesting observations regarding the co-existence of time interval and RFM model. First, the clustering method along time interval in three dimensions of the RFM model outperforms the method along the three dimensions in each interval. Subsequently, the cooperation of RFM and MCA provides a convenient methodology for exploring CRM in large–scale data. Therefore, the RFM model with time intervals integrated with MCA in CRM are essential."}, "journals/soco/WangSS17": {"title": "A three-stage global optimization method for server selection in content delivery networks.", "url": "https://doi.org/10.1007/s00500-015-1797-z", "year": "2017", "author": {"Ting Wang": "12/2633", "Junde Song": "60/5010", "Meina Song": "95/4440"}, "abstract": "To cope with increasing number of clients and servers, content delivery networks (CDNs) desire a more efficient way to select servers from multiple data centers in different geographic locations. This paper presents a three-stage global optimization method for the server selection (OMSS) in CDNs, which jointly considers the service experience, load balancing, traffic control and overhead. OMSS first proposes a novel scalable network distance proximity algorithm for partitioning the servers and clients into different clusters, then finds a set of candidate servers and extracts the closest k servers. At last, OMSS proposes a global optimization function with taking into account load balancing and traffic control, and introduces a penalty coefficient to leverage the quality of service experience in terms of network delay and the traffic control in terms of inter-domain transit traffic. In order to comprehensively analyze the performance of OMSS, we use typical benchmarks to compare OMSS with traditional approaches on the one hand, and also perform statistical tests to display the improvement of OMSS on the other hand. As presented in the comparison table, OMSS not only achieves improved performance in both service experience and traffic control, but also enjoys less measurement and computation overhead."}, "journals/tmc/SongOCYKSYH17": {"title": "Exploring Vision-Based Techniques for Outdoor Positioning Systems: A Feasibility Study.", "url": "https://doi.org/10.1109/TMC.2017.2696943", "year": "2017", "author": {"Meina Song": "95/4440", "Zhonghong Ou": "58/6143", "Eduardo Castellanos": "208/9976", "Tuomas Ylipiha": "208/9894", "Teemu Kämäräinen": "157/0335", "Matti Siekkinen": "78/3796", "Antti Ylä-Jääski": "63/5415", "Pan Hui 0001": "62/1272-1"}, "abstract": " Abstract:Recent advances from wearables have significantly changed the way how humans communicate with the surrounding environment. To some extent, they have extended and augmented the capability of humans. For example, with a Google Glass, people can take pictures simply by winking eyes twice, which releases human hands from the cumbersome image-taking process. Thus, it enables new application scenarios that were not possible before. In this paper, we investigate utilizing vision-based techniques to provide a wearable positioning system. Specifically, we propose a Human-centric Positioning System (HoPS) that utilizes traffic signposts together with context information for real-time positioning. Towards that direction, we make three primary contributions: (1) we make several important observations that guide our design of HoPS system; for example, we find out that approximately 40 percent of traffic signposts monopolize a cell tower, and there are at most six signposts within the coverage of a single cell tower; (2) we investigate the impact factors of object detection success rate, and find its correlation with image quality, and resolution; and (3) we design and implement HoPS and an advanced version of HoPS based on additional context information from Wi-Fi network, which we name HoPS-WiFi. Experimental results demonstrate the effectiveness of HoPS, especially HoPS-WiFi, which can estimate the relevant location correctly within 1.3 seconds."}, "journals/wpc/ZhouSSS17": {"title": "Anonymous Limited-Use-Proof Entity Authentication Protocol.", "url": "https://doi.org/10.1007/s11277-017-4221-4", "year": "2017", "author": {"Jian Zhou": "97/97", "Liyan Sun": "141/6518", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": "Currently, challenger have differentiable materials to verify identity including certificates, proofs and lifetime and so on in an entity authentication protocol, which could prone to pry into proprietary information or distinguish different legitimate challengers for a semi-honest verifier. However these attempts of existed anonymous entity authentication protocols fail to enforce anonymity for entity authentication if the verifier is semi-honest. To deal with the question, The paper proposes an anonymous limited-use-proof entity authentication protocol, in which only a shared certificate is corresponding to all legitimate members’ identities, the restriction of using proof of identity is embedded in the shared certificate in secret and the number of using proof of identity is counted by method of updating certificate, consequently a legitimate member’s identity would become illegitimate if the number of using its proof is more than the authorized amount. Finally, the security of our proposed protocol is proved theoretically based on discrete logarithm hard problem in four aspects of correctness, confidentiality, anonymous and finiteness. Therefore, in our proposed protocol, a semi-honest verifier can only judge whether or not a challenger is legitimate, but get nothing on the proprietary information of the identities from the poof of challengers."}, "journals/ijon/ZhengESS16": {"title": "CMPTF: Contextual Modeling Probabilistic Tensor Factorization for recommender systems.", "url": "https://doi.org/10.1016/j.neucom.2016.04.016", "year": "2016", "author": {"Cong Zheng": "28/9343", "Haihong E": "43/10222", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": "Contextual information has been proven to be valuable factor for building personalized Recommender Systems. However, most existing solutions based on probabilistic matrix factorization in recommender systems do not provide a straightforward way of integrating information such as ratings, social relationships, item contents and contexts into one model simultaneously. In this paper, we deem the given data as an User-Item-Context-Rating tensor and introduce a high dimensional method of Collaborative Filtering named probabilistic tensor factorization (PTF) which is a generalization of probabilistic matrix factorization. Then, we further extend PTF to a new model named Contextual Modeling Probabilistic Tensor Factorization (CMPTF) which systematically integrates topic modeling, social relationships and contexts in contextual modeling manner to further improve the quality of recommendation. Comprehensive comparative experiments conducted using real-world datasets demonstrate the superiority of our approach."}, "journals/ieicet/LiSE15": {"title": "Recommender System Using Implicit Social Information.", "url": "https://doi.org/10.1587/transinf.2014EDP7174", "year": "2015", "author": {"Yusheng Li 0005": "00/577-5", "Meina Song": "95/4440", "Haihong E": "43/10222"}, "abstract": ""}, "journals/pc/LiSCSMW15": {"title": "Cost-efficient coordinated scheduling for leasing cloud resources on hybrid workloads.", "url": "https://doi.org/10.1016/j.parco.2015.02.003", "year": "2015", "author": {"Jian Li": "33/5448", "Sen Su": "63/2499", "Xiang Cheng 0003": "29/1059-3", "Meina Song": "95/4440", "Liyu Ma": "161/3443", "Jie Wang 0002": "29/5259-2"}, "abstract": "Cloud service providers, leasing resources from cloud vendors under the pay-per-use service model, would want to minimize rental costs while meeting users’ computing needs. They typically serve the following two types of workloads: interactive service requests and batch jobs. Early algorithms were devised to deal with either type of workloads, but not both. In the presence of a mixture of both types of workloads, we observe that these algorithms would often overproduce virtual-machine (VM) instances, resulting in much higher rental costs than necessary. In particular, we show that the VM instances generated by these algorithms for interactive services tend to incur significant resources unused. We present a coordinated scheduling algorithm to solve this problem. First, we use a priority function to handle interactive services, meet stringent service response time, and in the same time collect residual resources needed for batch jobs. Second, we use queueing analysis to adjust resource allocations based on predictions of resource requests for interactive services. Third, we schedule batch jobs according to the dynamics of residual capacity and spot instance pricing. Using traces from real-world interactive services and a library of batch jobs in practical applications, we demonstrate using numerical analysis that our coordinated scheduling is superior to the existing algorithms on cost efficiency designed for either type of workloads."}, "journals/kbs/ZhengLWLS14": {"title": "Incorporating appraisal expression patterns into topic modeling for aspect and sentiment word identification.", "url": "https://doi.org/10.1016/j.knosys.2014.02.003", "year": "2014", "author": {"Xiaolin Zheng": "09/5763", "Zhen Lin": "26/346", "Xiaowei Wang": "27/5665", "Kwei-Jay Lin": "l/KweiJayLin", "Meina Song": "95/4440"}, "abstract": "With the considerable growth of user-generated content, online reviews are becoming extremely valuable sources for mining customers’ opinions on products and services. However, most of the traditional opinion mining methods are coarse-grained and cannot understand natural languages. Thus, aspect-based opinion mining and summarization are of great interest in academic and industrial research. In this paper, we study an approach to extract product and service aspect words, as well as sentiment words, automatically from reviews. An unsupervised dependency analysis-based approach is presented to extract Appraisal Expression Patterns (AEPs) from reviews, which represent the manner in which people express opinions regarding products or services and can be regarded as a condensed representation of the syntactic relationship between aspect and sentiment words. AEPs are high-level, domain-independent types of information, and have excellent domain adaptability. An AEP-based Latent Dirichlet Allocation (AEP-LDA) model is also proposed. This is a sentence-level, probabilistic generative model which assumes that all words in a sentence are drawn from one topic – a generally true assumption, based on our observation. The model also assumes that every review corpus is composed of several mutually corresponding aspect and sentiment topics, as well as a background word topic. The AEP information is incorporated into the AEP-LDA model for mining aspect and sentiment words simultaneously. The experimental results on reviews of restaurants, hotels, MP3 players, and cameras show that the AEP-LDA model outperforms other approaches in identifying aspect and sentiment words."}, "journals/wpc/ZhouSSZS14": {"title": "Autonomic Group Key Management in Deep Space DTN.", "url": "https://doi.org/10.1007/s11277-013-1505-1", "year": "2014", "author": {"Jian Zhou": "97/97", "Meina Song": "95/4440", "Junde Song": "60/5010", "Xian-Wei Zhou": "41/8468", "Liyan Sun": "141/6518"}, "abstract": "In deep space delay tolerant networks rekeying expend vast amounts of energy and delay time as a reliable end-to-end communication is very difficult to be available between members and key management center. In order to deal with the question, this paper puts forwards an autonomic group key management scheme for deep space DTN, in which a logical key tree based on one-encryption-key multi-decryption-key key protocol is presented. Each leaf node with a secret decryption key corresponds to a network member and each non-leaf node corresponds to a public encryption key generated by all leaf node’s decryption keys that belong to the non-leaf node’s sub tree. In the proposed scheme, each legitimate member has the same capability of modifying public encryption key with himself decryption key as key management center, so rekeying can be fulfilled successfully by a local leaving or joining member in lack of key management center support. In the security aspect, forward security and backward security are guaranteed. In the efficiency aspect, our proposed scheme’s rekeying message cost is half of LKH scheme when a new member joins, furthermore in member leaving event a leaving member makes tradeoff between computation cost and message cost except for rekeying message cost is constant and is not related to network scale. Therefore, our proposed scheme is more suitable for deep space DTN than LKH and the localization of rekeying is realized securely."}, "journals/jcp/YuSS12": {"title": "A Novel Hyper-parameters Selection Approach for Support Vector Machines to Predict Time Series.", "url": "http://www.jcomputers.us/index.php?m=content&c=index&a=show&catid=54&id=598", "year": "2012", "author": {"Yanhua Yu": "124/5763", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": ""}, "journals/cluster/XuSS10": {"title": "An improved P2P lookup protocol model.", "url": "https://doi.org/10.1007/s10586-009-0112-0", "year": "2010", "author": {"Ke Xu": "181/2626", "Meina Song": "95/4440", "Junde Song": "60/5010"}, "abstract": "With the development of the peer-to-peer (P2P) technology, a lot of lookup protocols have come out. Although we can benefit from different protocols separately, our research shows that if there exists a proper model, most of the seemingly different protocols can be classified to a same framework. Since technology is a kind of human behavior, we can set up the P2P lookup general model referring to some outcomes of cognitive psychology. In this paper, we firstly study the lookup model in cognitive psychology, then introduce the model into P2P search strategy, at last we give an improved Chord arithmetic based on the binary tree."}, "journals/wicomm/ChiYSSZ10": {"title": "Generic service composition platform for pervasive E-Commerce.", "url": "https://doi.org/10.1002/wcm.749", "year": "2010", "author": {"Jing Chi": "03/627", "Chunyang Yin": "17/119", "Meina Song": "95/4440", "Junde Song": "60/5010", "Xiaosu Zhan": "51/2179"}, "abstract": ""}}}