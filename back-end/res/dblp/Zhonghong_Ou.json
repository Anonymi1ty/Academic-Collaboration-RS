{"id": "58/6143", "name": "Zhonghong Ou", "Article": {"conf/ccis/WangOS21": {"title": "PowerDet: Efficient and Lightweight Object Detection for Electric Power Open Scenes.", "url": "https://doi.org/10.1109/CCIS53392.2021.9754678", "year": "2021", "author": {"Shigeng Wang": "318/8450", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": " Abstract:In recent years, with the expansion of the electric network, maintenance cost of electric power transmission and transformer substation equipment has become increasingly greater. Moreover, it requires a lot of manpower as well. At present, there are certain schemes which leverage artificial intelligence techniques to detect equipment flaws or errors automatically. Nevertheless, there are problems with the schemes in open electric power scenes, e.g., only able to detect single category, low detection accuracy of multi-scale objects, and difficulty in deploying models on mobile devices. To address the challenges mentioned above, we propose an object detection model, named PowerDet. It is able to detect 9 different types of power facilities efficiently with low cost. To verify the effectiveness of PowerDet, we collect an open scene facility entity dataset and conduct a series of experiments. Experimental results demonstrate that PowerDet achieves 86.8% AP50 on the dataset, which outperforms the state-of-the-art. The lightweight version of PowerDet, i.e., PowerDet-Lite, can achieve real-time inference on mainstream mobile devices."}, "conf/apweb/TanOLSS20": {"title": "Turn-Level Recurrence Self-attention for Joint Dialogue Action Prediction and Response Generation.", "url": "https://doi.org/10.1007/978-3-030-60290-1_24", "year": "2020", "author": {"Yanxin Tan": "276/3512", "Zhonghong Ou": "58/6143", "Kemeng Liu": "237/8139", "Yanan Shi": "120/5466", "Meina Song": "95/4440"}, "abstract": "In task-oriented dialogue systems, semantically controlled natural language generation is the procedure to generate responses based on current context information. Seq2seq models are widely used to generate dialogue responses and achieve favorable performance. Nevertheless, how to effectively obtain the dialogue’s key information from history remains to be a critical problem. To overcome this problem, we propose a Turn-level Recurrence Self-Attention (TRSA) encoder, which effectively obtains progressive structural relationship in turn-level from conversation history. Moreover, we propose a novel model to predict dialogue actions and generate dialogue responses jointly, which is different from the separate training model used in previous studies. Experiments demonstrate that our model alleviates the problem of inaccurate attention in dialogue history and improves the degree of dialogue completion significantly. In the large-scale MultiWOZ dataset, we improve the performance by 3.9% of inform rate and 3.4% of success rate, which is significantly higher than the state-of-the-art.KeywordsSelf-attentionDialogue systemResponse generation."}, "conf/apweb/LiuOTZS20": {"title": "KGWD: Knowledge Graph Based Wide & Deep Framework for Recommendation.", "url": "https://doi.org/10.1007/978-3-030-60259-8_33", "year": "2020", "author": {"Kemeng Liu": "237/8139", "Zhonghong Ou": "58/6143", "Yanxin Tan": "276/3512", "Kai Zhao": "72/2621", "Meina Song": "95/4440"}, "abstract": "Knowledge Graph (KG) contains rich real-world auxiliary information, which can be leveraged to improve the performance of recommender systems. Nevertheless, existing recommender systems usually sample and aggregate neighbor entities and relations that link to target items to enrich the representations of items or users, whereas ignoring combinatorial features among different neighbor entities and relations. To resolve the problem mentioned above, we propose an end-to-end Knowledge Graph based Wide & Deep (KGWD) framework to leverage combinatorial features effectively. At the wide level, KGWD introduces a novel Triplet Compressed Interaction Network (TriCIN) to generate high-order combinatorial features among different triplets associated with the target item automatically. At the deep level, KGWD discovers users’ potential long-distance preferences by mining multi-hop neighbor information over the KG. We conduct experiments on three real-world datasets, i.e., Yelp2018, Last-FM, and Amazon-book, to evaluate the performance of KGWD. Experimental results demonstrate that KGWD outperforms state-of-the-art schemes significantly. Specifically, in all three datasets, KGWD improves the F1-score by more than 5% over the state-of-the-art.KeywordsRecommender systemsKnowledge graphWide & Deep"}, "conf/chil/ZhangHSEOS20": {"title": "BMM-Net: automatic segmentation of edema in optical coherence tomography based on boundary detection and multi-scale network.", "url": "https://doi.org/10.1145/3368555.3384447", "year": "2020", "author": {"Ruru Zhang": "139/7990", "Jiawen He": "256/7881", "Shenda Shi": "255/8207", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": "\n\t\tRetinal effusions and cysts caused by the leakage of damaged macular vessels and choroid neovascularization are symptoms of many ophthalmic diseases. Optical coherence tomography (OCT), which provides clear 10-layer cross-sectional images of the retina, is widely used to screen various ophthalmic diseases. A large number of researchers have carried out relevant studies on deep learning technology to realize the semantic segmentation of lesion areas, such as effusion on OCT images, and achieved good results. However, in this field, problems of the low contrast of the lesion area and unevenness of lesion size limit the accuracy of the deep learning semantic segmentation model. In this paper, we propose a boundary multi-scale multi-task OCT segmentation network (BMM-Net) for these two challenges to segment the retinal edema area, subretinal fluid, and pigment epithelial detachment in OCT images. We propose a boundary extraction module, a multi-scale information perception module, and a classification module to capture accurate position and semantic information and collaboratively extract meaningful features. We train and verify on the AI Challenger competition dataset. The average Dice coefficient of the three lesion areas is 3.058% higher than the most commonly used model in the field of medical image segmentation and reaches 0.8222.\n\t"}, "conf/hucc/LiuLOZS20": {"title": "An Inclusive Finance Consortium Blockchain Platform for Secure Data Storage and Value Analysis for Small and Medium-Sized Enterprises.", "url": "https://doi.org/10.1007/978-3-030-70626-5_44", "year": "2020", "author": {"Jiaxi Liu": "197/1757", "Peihang Liu": "274/3105", "Zhonghong Ou": "58/6143", "Guangwei Zhang": "78/6847", "Meina Song": "95/4440"}, "abstract": "In the era of big data, people pay more and more attention to user privacy and data security. The market size of Small and Medium-sized Enterprises (SMEs) in China is sizable. Nevertheless, due to problems of data dispersion and lack of data features, it is very difficult to make use of the massive data of SMEs scattered in various institutions effectively, which leads to the inability to reflect the value of data. One of the problems is how to credit for SMEs better. Supported by federated learning for such scenarios, we present an inclusive Finance Consortium Blockchain platform in this paper. On the one hand, the platform combines decentralized identity and Blockchain as the underlying architecture, which guarantees authenticity of the data source and safe storage of user data on the chain. The smart contract mechanism provided by Blockchain can also assist secure storage and incentive mechanism of federated learning models effectively. On the other hand, we have innovatively introduced an asynchronous Federated Learning mode based on transfer learning, which encrypts the well-designed pre-training model and transfers it to each participant to guide training of the participant's local model. In the model reasoning stage, all the participants participate in a joint evaluation according to the local model and push the reasoning results on the Blockchain. The smart contract takes the weighted sum of the reasoning results provided by all the participants as the final result of shared model reasoning.KeywordsFederated learningFederated transfer learningBlockchainDecentralized identity"}, "conf/hucc/EKLSO19": {"title": "A Real-Time Update Approach for Visualizing Multidimensional Big Data.", "url": "https://doi.org/10.1007/978-3-030-37429-7_10", "year": "2019", "author": {"Haihong E": "43/10222", "Huihui Kong": "247/3690", "Yunfeng Liu": "56/5650", "Meina Song": "95/4440", "Zhonghong Ou": "58/6143"}, "abstract": "\nMultidimensional data in different fields (e.g., science and technology resources, medicine, finance and transportation) have emerged in the big data era. Technology of visualization is critical to analyze multidimensional data which is large-scale. Thus, the highly variability of multidimensional data leads to the necessity of improving data management efficiency by updating data in real time. Nevertheless, traditional real-time communication technology suffers from low efficiency and large bandwidth consumption. Based on WebSocket, this paper proposes a multidimensional data service platform architecture that is scalable, real-time and versatile. First, on the platform, we compare the network load and network latency above Ajax polling and WebSocket. Secondly, for multidimensional data, we further validate the effectiveness of WebSocket in the application scenarios of frequent updating and multi-user concurrent requests. WebSocket-based platform greatly shortens the time for people to understand and analyze massive and complex multidimensional data. The application results show that the design is effective for real-time updating of multidimensional data.\nKeywordsWebSocketMultidimensional dataReal-time updating"}, "conf/hucc/ZhangHSKCLLHOS19": {"title": "Computer-Aided Diagnosis of Ophthalmic Diseases Using OCT Based on Deep Learning: A Review.", "url": "https://doi.org/10.1007/978-3-030-37429-7_63", "year": "2019", "author": {"Ruru Zhang": "139/7990", "Jiawen He": "256/7881", "Shenda Shi": "255/8207", "Xiaoyang Kang": "180/2279", "Wenjun Chai": "256/7872", "Meng Lu": "90/106", "Yu Liu": "97/2274", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": "Deep learning can effectively extract the hidden features of images and has developed rapidly in medical image recognition in recent years. Ophthalmic diseases are one of the critical factors affecting the healthy living. At the same time, optical coherence tomography (OCT) has the characteristics of non-invasive and high-resolution and has become the mainstream imaging technology in the clinical diagnosis of Ophthalmic diseases. Therefore, computer-aided diagnosis of ophthalmic diseases using OCT based on deep learning has caused a wide range of research craze. In this paper, we review the imaging methods and applications of OCT, the OCT public dataset. And we introduce in detail the computer-aided diagnosis system of multiple ophthalmic diseases using OCT in recent years, including age-related macular degeneration, glaucoma, diabetic macular edema and so on, and an overview of the main challenges faced by deep learning in OCT imaging.\nKeywordsDeep learningOCTOphthalmic disease"}, "conf/icit/WuOS19": {"title": "Session-based Recommendation with Context-Aware Attention Network.", "url": "https://doi.org/10.1145/3377170.3377269", "year": "2019", "author": {"Jinsheng Wu": "261/7036", "Zhonghong Ou": "58/6143", "Meina Song": "95/4440"}, "abstract": "\n\t\tSession-based recommendation aims to generate recommendation results based on user's anonymous session. Previous studies model the session as a sequence and use Recursive Neural Network (RNN) to represent user behavior for recommendations. Although achieved promising result, previous studies ignore the relationship between session's items and external context of session, which fails in revealing the intrinsic relation between them. To tackle the problem mentioned above, we propose a novel method, i.e., Session-based Recommendation with Context-Aware Attention Network, SR-CAAN, which enhances the ability of modeling the user preference by combining sequence prediction with session external context aware method. In the proposed method, we incorporate external knowledge with Knowledge Graph (KG) to obtain the external context of session by using attention mechanism. Each session is presented as a composition of the external context of session and user's long-short term interest is obtained by Recurrent Neural Networks (RNNs). Experiments conducted on real word datasets demonstrate that SR-CAAN outperform the state-of-the-art significantly.\n\t"}, "conf/icvisp/HuOXS19": {"title": "A Crowdsourcing Repeated Annotations System for Visual Object Detection.", "url": "https://doi.org/10.1145/3387168.3387242", "year": "2019", "author": {"Yucheng Hu": "59/9331", "Zhonghong Ou": "58/6143", "Xiangyu Xu": "172/1282", "Meina Song": "95/4440"}, "abstract": "\n\t\tAs a fundamental task in compute vision, object detection has been developed rapidly driven by the deep learning. The lack of a large number of images with ground truth annotations has become a chief obstacle to object detection applications in many fields. Eliciting labels from crowds is a potential way to obtain large labeled data. Nonetheless, existing crowdsourced techniques, e.g., Amazon Mechanical Turk (MTurk), often fail to guarantee the quality of the annotations, which have a bad influence on the accuracy of the deep detector. A variety of methods have been developed for ground truth inference and learning from crowds. In this paper, we study strategies to crowd-source repeated labels in support for these methods. The core challenge of building such a system is to reduce the difficulty to annotate multiple objects of interest and improve the data quality as much as possible. We present a system that adopts the turn-based annotation mechanism and consists of three simple sub-tasks: a single object annotation, a quality verification task and a coverage verification task. Experimental results demonstrate that our system is scalable, accurate and can assist the detector of obtaining higher accuracy.\n\t"}, "conf/ica3pp/OuLSE17": {"title": "A CNN-Based Supermarket Auto-Counting System.", "url": "https://doi.org/10.1007/978-3-319-65482-9_24", "year": "2017", "author": {"Zhonghong Ou": "58/6143", "Changwei Lin": "86/9627", "Meina Song": "95/4440", "Haihong E": "43/10222"}, "abstract": "Deep learning has made significant breakthrough in the past decade. In certain application domain, its detection accuracy has surpassed human being in the same task, e.g., voice recognition and object detection. Various novel applications has been developed and achieved good performance by leveraging the latest advances in deep learning. In this paper, we propose to utilize deep learning based technique, specifically, Convolutional Neural Network (CNN), to develop an auto-counting system for supermarket scenario. Given a picture, the system can automatically detect the specified categories of goods (e.g., Head & Shoulders bottles) and their respective numbers. To improve detection accuracy of the system, we propose to combine hard example mining and multi-scale feature extraction to the Faster R-CNN framework. Experimental results demonstrate the efficacy of the proposed system. Specifically, our system achieves an mAP of 92.1%, which is better than the state-of-the-art, and the response time is about 250 ms per image, including all steps on a GTX 1080 GPU.KeywordsAuto-counting systemDeep learningConvolutional Neural Network"}, "conf/ica3pp/EHSOW17": {"title": "Research and Implementation of Question Classification Model in Q&A System.", "url": "https://doi.org/10.1007/978-3-319-65482-9_25", "year": "2017", "author": {"Haihong E": "43/10222", "Yingxi Hu": "204/2302", "Meina Song": "95/4440", "Zhonghong Ou": "58/6143", "Xinrui Wang": "166/1957"}, "abstract": "Question classification is the core of the question-and-answer (Q&A) sys-tem. This paper intends to use the method of deep learning to explore the question classification model in Q&A systems, the aim of which is to improve the accuracy of question classification.\n\nThe characteristics of natural language questions, such as the use of short texts and basic grammar, were well considered. Subsequently, we want to fully extract the features of questions by using the following methods: multi-channel inputs, multi-granularity convolution kernels, and direct connection with high-speed channels. By combining the three methods, this paper proposes the multi-channel and Bidirectional long-and short-term memory and multi- granularity convolution neural net-work (MC–BLSTM–MGCNN) model to fully extract the features from interrogative sentences, both in time and spatial domains.To verify the validity of the model, this paper experimented with the TREC [1] classification standard dataset. Results achieved 96.6% accuracy, which is superior to the highest existing industry benchmark (96.1%). In addition, this paper used the complete TREC dataset to innovate further, and results obtained 98% accuracy, which greatly improved the classification.KeywordsQ&A systemQuestion classificationDeep learningConvolution neural networkLong- and short-term memory network"}, "conf/ccbd/LiSOE16": {"title": "Performance Comparison and Analysis of Yarn's Schedulers with Stress Cases.", "url": "https://doi.org/10.1109/CCBD.2016.028", "year": "2016", "author": {"Bo Li": "50/3402", "Meina Song": "95/4440", "Zhonghong Ou": "58/6143", "Haihong E": "43/10222"}, "abstract": " Abstract:Hadoop, as a popular distributed storage and computing platform, has been widely used in many companies. Yarn is the resource management platform in Hadoop and plays an important role in the resource managing, because it can affect the cluster's energy efficiency and the usability for applications. The schedulers are the brain of Yarn, which manage and schedule resources from cluster to applications. In this paper, we conduct experiments to compare and analyze the performance of Yarn's schedulers. We use various scenarios to demonstrate the strengths and weaknesses of each scheduler from the perspective of response speed, cluster's efficiency, scheduler's speciality etc. Experimental results demonstrate that the FIFO Scheduler has a better performance and data locality sense for batch jobs processing than the other schedulers, but the Capacity Scheduler and the FIFO Scheduler have better response speed and cluster's usability than the FIFO Scheduler which has a hunger problem in mixed scenario."}, "conf/globecom/LoogaODY16": {"title": "PowerShark: IEEE 802.15.4 Mote Activity Analysis Using Power Traces and Neural Networks.", "url": "https://doi.org/10.1109/GLOCOM.2016.7842163", "year": "2016", "author": {"Vilen Looga": "115/6370", "Zhonghong Ou": "58/6143", "Yang Deng 0003": "115/6282-3", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Analysing the power usage of an Internet of Things (IoT) device is essential in contexts such as smart building, testbed and forensics. For example, in the smart building case, schemes have been proposed to detect and analyse the activity of electric appliances based on the total power usage. In this work, we intend to take this concept a step further and devise a method to analyse the activity of a single IoT device (mote) based on its power usage. To that end, we develop a neural network (NN) based classifier PowerShark that is capable of classifying mote activity based solely on the power usage of the mote, both in online and offline mode. PowerShark can detect radio activity, hardware, operating system (OS), and the MAC layer used. To verify the accuracy of PowerShark, we use power traces from OpenMote and Zolertia Z1 motes, with ContikiOS configured either with ContikiMAC or X-MAC. Experimental results demonstrate the accuracy of our proposed classifier. Specifically, PowerShark can achieve over 95% accuracy in both training and testing phases."}, "conf/huc/HuiOZS16": {"title": "The 7th international workshop on hot topics in planet-scale measurement (HotPlanet '16).", "url": "https://doi.org/10.1145/2968219.2985840", "year": "2016", "author": {"Pan Hui 0001": "62/1272-1", "Zhonghong Ou": "58/6143", "Yanyong Zhang": "44/2799", "Aaron D. Striegel": "42/6870"}, "abstract": "\n\t\tThe recent advances of mobile devices, online social networks, and the emergence of the Internet of Things have driven the corresponding data collection and analytics to planetary scale. It is, thus, essential to provide a forum to discuss the technical advances, share the lessons, experiences, and challenges associated with real-world large-scale deployment. The 7th International Workshop on Hot Topics in Planet-Scale Measurement (HotPlanet '16) is to provide such a forum for the researchers and practitioners in the fields mentioned above. By bringing together the experts in these fields, and through thoughtful discussions and valuable sharing, HotPlanet '16 aims to advance the work in these fields forward.\n\t"}, "conf/huc/KhanHNON16": {"title": "Energy efficiency of large scale graph processing platforms.", "url": "https://doi.org/10.1145/2968219.2968296", "year": "2016", "author": {"Kashif Nizam Khan": "33/8214", "Mohammad Ashraful Hoque": "119/5055", "Tapio Niemi": "48/1823", "Zhonghong Ou": "58/6143", "Jukka K. Nurminen": "38/1107"}, "abstract": "\n\t\tA number of graph processing platforms have emerged recently as a result of the growing demand on graph data analytics with complex and large-scale graph structured datasets. These platforms have been tailored for iterative graph computations and can offer an order of magnitude performance gain over generic data-flow frameworks like Apache Hadoop and Spark. Nevertheless, the increasing availability of such platforms and their functionality overlap necessitates a comparative study on various aspects of the platforms, including applications, performance and energy efficiency. In this work, we focus on the energy efficiency aspect of some large scale graph processing platforms. Specifically, we select two representatives, e.g., Apache Giraph and Spark GraphX, for the comparative study. We compare and analyze the energy consumption of these two platforms with PageRank, Strongly Connected Component and Single Source Shortest Path algorithms over five different realistic graphs. Our experimental results demonstrate that GraphX outperforms Giraph in terms of energy consumption. Specifically, Giraph consumes 1.71 times more energy than GraphX on average for the mentioned algorithms.\n\t"}, "conf/ipsn/DongXOCY16": {"title": "Indoor Tracking Using Crowdsourced Maps.", "url": "https://doi.org/10.1109/IPSN.2016.7460679", "year": "2016", "author": {"Jiang Dong": "64/2623", "Yu Xiao 0001": "54/5385-1", "Zhonghong Ou": "58/6143", "Yong Cui 0001": "91/2346-1", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Using crowdsourced visual and inertial sensor data for indoor mapping has attracted much attention in recent years. Nevertheless, the opportunities and challenges of indoor tracking using crowdsourced maps have not been fully explored. In this work, we aim at tackling the challenges due to incomplete obstacle information in crowdsourced indoor maps, especially at the initialization stage of crowdsourcing. We propose a novel solution for particle-filtering-based indoor tracking, using the crowdsourced maps derived from image-based 3D point clouds. Our solution enhances particle filtering with density-based collision detection and history-based particle regeneration. Evaluation with real user traces demonstrates that our solution outperforms the state-of-the-art. In particular, it reduces the average distance error of indoor tracking by 47% when using crowdsourced 3D point clouds."}, "conf/mobimedia/SongZEO16": {"title": "A Recommender System Model based on Commodity-Purchase-Cycle Classification.", "url": "http://dl.acm.org/citation.cfm?id=3021395", "year": "2016", "author": {"Meina Song": "95/4440", "Xue Zhou": "10/3434", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143"}, "abstract": "\n\t\tRecommender systems have been widely used in e-commerce platforms, such as Amazon and Taobao. Among the available recommendation algorithms, Item Collaborative Filtering (ItemCF) Algorithm and Content Filtering Algorithm have gained wide adoption because of various strengths. For example, hidden interests can be digged so as to get fresh recommendations, and highly individual recommendations can be made. Despite their strengths and wide adoption, there are still some weaknesses associated with them. One representative weakness is the existence of duplicated, and outdated recommendations due to the lack of purchasing cycles, e.g., weekly or seasonal, of goods. We name such cycles Commodity Purchase Cycle (CPC), and propose a new recommendation algorithm based on CPC in this paper. We leverage CPC attributes to modify the collaborative filtering output rating matrix acquired by the ItemCF Algorithm, and take into consideration both user behaviors and commodity characteristics to make timely recommendations. We utilize a realistic dataset from Taobao to verify the performance of the proposed algorithm. Experimental results demonstrate good performance of CPC algorithm. Specifically, from the perspective of Root Mean Square Error (RMSE), the CPC Algorithm promotes the recommendation accuracy by 15%-20%, compared with the state-of-the-art ItemCF Algorithm.\n\t"}, "conf/mss/HouCOWM16": {"title": "Understanding I/O performance behaviors of cloud storage from a client's perspective.", "url": "https://doi.org/10.1109/MSST.2016.7897089", "year": "2016", "author": {"Binbing Hou": "175/6835", "Feng Chen 0005": "21/3047-5", "Zhonghong Ou": "58/6143", "Ren Wang 0001": "29/50-1", "Michael P. Mesnier": "m/MichaelPMesnier"}, "abstract": " Abstract:Cloud storage has gained increasing popularity in the past few years. In cloud storage, data is stored in the service provider's data centers, and users access data via the network. For such a new storage model, our prior wisdom about conventional storage may not remain valid nor applicable to the emerging cloud storage. In this paper, we present a comprehensive study and attempt to gain insight into the unique characteristics of cloud storage, primarily from the client's perspective. Through extensive experiments and quantitative analysis, we have acquired several interesting, and in some cases unexpected, findings. (1) Parallelizing I/Os and increasing request sizes are keys to improving the performance, but optimal bandwidth may only be achieved with a proper combination of parallelism and request size. (2) Client capabilities, including CPU, memory, and storage, play an unexpectedly important role in determining the achievable performance. (3) A geographically long distance affects client-perceived performance but does not always result in lower bandwidth and longer latency. Based on our experimental studies, we further present a case study on appropriate chunking and parallelization in a cloud storage client. Our studies show that specific attention should be paid to fully exploiting the capabilities of clients and the great potential of cloud storage services."}, "conf/ucc/SongZEO16": {"title": "Statistic-based CRM approach via time series segmenting RFM on large scale data.", "url": "https://doi.org/10.1145/2996890.3007873", "year": "2016", "author": {"Meina Song": "95/4440", "Xuejun Zhao": "78/936", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143"}, "abstract": "\n\t\tCRM (Customer relationship management) plays a crucial role in detecting and gathering valuable users from externality and internality, where externality refers to customer relationship and internality is regarded as customer characteristics. However, conventional approaches based on RFM (recency, frequency and monetary) model have encountered with three challenges. First, traditional approaches that derive from survey data rather than objective large-scale data fail to apply the method in general scenario; Second, since there is several trial to experiment on RFM model changing over time, different segmentation of time leads to different results; Last, analysis of multiple characteristics either on externality or internality is sparse and separate, which betray the exploration purpose for CRM and make results unconvincing. To overcome the three limitations, a multiple statistic-based approach to value users via time series segmenting time interval of RFM on large scale data is proposed in the paper. In the aspect of telecom service data, we experiment on segmenting time interval methodologically for RFM model on data set more than millions of users. Besides, the most significant part there is formal mechanism to apply MCA (multiple corresponding analysis) on multiple characteristics for internality correspondingly with RFM for externality, leading to the deep relationships of users and their characteristics. Subsequently, we improve the traditional RFM model overtime from the different clustering steps on large-scale data.\n\t"}, "conf/ccgrid/KhanNONNEEA15": {"title": "Energy Profiling Using IgProf.", "url": "https://doi.org/10.1109/CCGrid.2015.118", "year": "2015", "author": {"Kashif Nizam Khan": "33/8214", "Filip Nyback": "153/1772", "Zhonghong Ou": "58/6143", "Jukka K. Nurminen": "38/1107", "Tapio Niemi": "48/1823", "Giulio Eulisse": "45/3226", "Peter Elmer": "13/6285", "David Abdurachmanov": "137/8358"}, "abstract": " Abstract:Energy efficiency has become a primary concern for data centers in recent years. Understanding where the energy has been spent within a software is fundamental for energy-efficiency study as a whole. In this paper, we take the first step towards this direction by building an energy profiling module on top of IgProf. IgProf is an application profiler developed at CERN for scientific computing workloads. The energy profiling module is based on sampling and obtains energy measurements from the Running Average Power Limit (RAPL) interface present on the latest Intel processors. The initial profiling results of a single-threaded program demonstrates potential, showing a close correlation between the execution time and the energy spent within a function."}, "conf/ewsn/DengOY15": {"title": "Adaptive Packet Size Control for Bulk Data Transmission in IPv6 over Networks of Resource Constrained Nodes.", "url": "https://doi.org/10.1007/978-3-319-15582-1_23", "year": "2015", "author": {"Yang Deng 0003": "115/6282-3", "Zhonghong Ou": "58/6143", "Antti Ylä-Jääski": "63/5415"}, "abstract": "Conventional transmission in IPv6 over Networks of Resource Constrained Nodes (6lo) favours fixed-size packets and results in low network performance when bulk data transmission is required by applications, for example firmware updating. To tackle this problem, we first investigate performance of bulk data transmission through large packets and make two important observations. Then we propose an adaptive mechanism at IP layer to dynamically adjust packet size in 6lo. We implemented the mechanism on Contiki OS and evaluated it through a series of experiments in Cooja. Experimental results demonstrate that our mechanism outperforms Contiki standard implementation significantly from both reliability and goodput under various network conditions.Keywords6loBulk Data TransmissionPacket Size Control"}, "conf/infocom/DongXOY15": {"title": "Utilizing internet photos for indoor mapping and localization - opportunities and challenges.", "url": "https://doi.org/10.1109/INFCOMW.2015.7179457", "year": "2015", "author": {"Jiang Dong": "64/2623", "Yu Xiao 0001": "54/5385-1", "Zhonghong Ou": "58/6143", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Along with the booming popularity of photo sharing services, an ever-increasing number of photos are shared and made publicly available on the Internet. This brings new opportunities for image-based applications and services. In this paper, we explore the potential of using Internet photo collections for building 3D models of indoor environments and providing indoor mapping and localization using these models. We choose several representative places of interest in order to analyze their Internet photo collections. Photo sets have been collected from two wellknown public attractions to generate 3D models using Structure from Motion (SfM) techniques. We further design several metrics to evaluate the usability of these models for indoor mapping and localization. The results show that Internet photo collections can serve the purpose of indoor mapping and localization in certain types of indoor spaces."}, "conf/iscc/LoogaOXY15": {"title": "The great expectations of smartphone traffic scheduling.", "url": "https://doi.org/10.1109/ISCC.2015.7405616", "year": "2015", "author": {"Vilen Looga": "115/6370", "Zhonghong Ou": "58/6143", "Yu Xiao 0001": "54/5385-1", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Utilizing network traffic scheduling to improve the energy efficiency of smartphones has been studied extensively in the past few years. These studies usually take certain approaches and make some assumptions concerning traffic predictability, regardless of whether these assumptions hold or whether the approaches have been studied before. In this paper, we conduct an analysis of existing work to find common approaches and assumptions among the proposed solutions. We find out the following: 1. A large part of the solutions target a specific (single) application or category of applications, and do not schedule the whole traffic transmitted on the smartphone. 2. A common assumption is that network traffic for smart phones is predictable. The focus of our work is to test these assumptions against real-world data and analyze whether the approaches presented in the literature are feasible. By leveraging two data sets from NetSense, we make several major contributions: 1. We demonstrate clearly, based on a large dataset, that background apps are the largest energy consumers for smart phones. 2. although some traffic traces exhibit long-term trends, in general traffic from a single app or a user is not predictable in the short-term. 3. achieving energy savings is difficult by scheduling traffic only from a specific app, since multi-app scenarios are so prevalent on today's smartphones. We also pinpoint future directions for traffic scheduling schemes."}, "conf/sensys/DongXNOY15": {"title": "iMoon: Using Smartphones for Image-based Indoor Navigation.", "url": "https://doi.org/10.1145/2809695.2809722", "year": "2015", "author": {"Jiang Dong": "64/2623", "Yu Xiao 0001": "54/5385-1", "Marius Noreikis": "154/8197", "Zhonghong Ou": "58/6143", "Antti Ylä-Jääski": "63/5415"}, "abstract": "\n\t\tThe adoption of indoor navigation for smartphones has been relatively slow in the past years, although it would be direly needed in complex indoor areas. The primary barriers for its adoption include the lack of fine-grained and up-to-date indoor maps and the potential deployment and maintenance cost. In this paper we investigate the feasibility of utilizing crowdsourced data for building a smartphone-based indoor navigation system, focusing on the technical challenges caused by the varying quality of crowdsourced data. We developed iMoon, an indoor navigation system based on sensor-enriched 3D models of indoor environment, and evaluated its performance via a field study in a public building covering around 1,100 square meters. iMoon builds 3D models of indoor environment from crowdsourced 2D photos, and compiles a navigation mesh from the generated 3D models. Depending on the input for 3D modelling, indoor pedestrian paths may be partly missing from the output. iMoon solves this issue by integrating into navigation mesh the pedestrian paths recognized from crowdsourced user motion trajectories. With photo-based 3D models, iMoon supports image-based localization that identifies user's position and facing direction with photos, and provides visual navigation instructions that show when and where to turn. To reduce response delay while maintaining the accuracy of localization, iMoon partitions 3D models based on the density of 3D points, and selects partitions for image-based localization using Wi-Fi fingerprints. According to our experimental results, iMoon works properly, and our solution of indoor localization achieves competitive performance compared with traditional approaches: in most cases, a user can be located within an average of 3.85 seconds with a location error of less than 2 meters and a facing direction error of less than 6 degrees.\n\t"}, "conf/sensys/DongXNOY15a": {"title": "Demo: iMoon: Using Smartphones for Image-based Indoor Navigation.", "url": "https://doi.org/10.1145/2809695.2817848", "year": "2015", "author": {"Jiang Dong": "64/2623", "Yu Xiao 0001": "54/5385-1", "Marius Noreikis": "154/8197", "Zhonghong Ou": "58/6143", "Antti Ylä-Jääski": "63/5415"}, "abstract": "\n\t\tThe indoor location market is growing rapidly. However, fine-grained and up-to-date indoor maps are rarely available, and the existing indoor localization and navigation services mostly require extra infrastructures to provide accurate locations. In this demonstration we show iMoon, an indoor navigation system that provides indoor mapping, localization and navigation services using photos and sensor data collected from widely available mobile devices. The demonstration leverages a cohesive suite of computer vision, mobile sensing, and wireless networking techniques.\n\t"}, "conf/ucc/OuHCWY15": {"title": "Is Cloud Storage Ready? A Comprehensive Study of IP-Based Storage Systems.", "url": "http://doi.ieeecomputersociety.org/10.1109/UCC.2015.14", "year": "2015", "author": {"Zhonghong Ou": "58/6143", "Zhen-Huan Hwang": "177/5000", "Feng Chen 0005": "21/3047-5", "Ren Wang 0001": "29/50-1", "Antti Ylä-Jääski": "63/5415"}, "abstract": ""}, "conf/wasa/OuWY15": {"title": "Big-Little-Cell Based \"Handprint\" Positioning System.", "url": "https://doi.org/10.1007/978-3-319-21837-3_41", "year": "2015", "author": {"Zhonghong Ou": "58/6143", "Jun Wu": "20/3894", "Antti Ylä-Jääski": "63/5415"}, "abstract": "Mobile computing has been a hot research field in the past decade. Although the computation capability of mainstream smartphones are several orders of magnitude better than desktops twenty years ago, the capacity of battery does not increase at the same pace. Thus, the gap between battery life and the demand from applications increases. To save energy, certain recent work tries to schedule network traffic according to signal strength variations. To achieve this goal, a platform that is used for collecting signal strength traces is essential. We first design and implement a platform to collect cellular network information, including cell ID and signal strength. We then deploy the platform and collect signal strength information in one area of Finland. After a set of carefully designed experiments, we make several interesting observations: (1) the density of base stations is much higher than expectation; (2) small cells account for a large portion in the overall cells; (3) in the same location a device may connect to different base stations, which is also applicable to different devices. Based on the observations, we design a novel energy-efficient positioning system called “Handprint”, which utilizes fingerprint information from neighbouring devices to assist positioning. Performance evaluation demonstrates that, compared with Google Geolocation API and other existing work, our Handprint system can improve positioning accuracy by more than 20 %.KeywordsHandprintPositioning systemEnergy-efficient"}, "conf/wimob/LoogaODY15": {"title": "Remote inference energy model for Internet of Things devices.", "url": "https://doi.org/10.1109/WiMOB.2015.7348033", "year": "2015", "author": {"Vilen Looga": "115/6370", "Zhonghong Ou": "58/6143", "Yang Deng 0003": "115/6282-3", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Large wireless sensor networks (WSNs) with thousands of motes are expected to be a significant part of the future connected world. As battery life of such motes is still an issue, it is important to provide scalable methods to estimate energy usage without introducing significant overhead. We foresee that in the future significant amount of data will be collected and inferred on the behavior of motes. Such collection and inference of data can be considered as a virtual representation of the physical mote, with a potentially longer life-cycle. The virtual mote is a valuable resource for application development, diagnostics and behavior prediction. In this paper, we focus on the energy consumption aspect of such motes. To that end, we develop a packet-based real-time energy model, which works by analyzing network traffic traces collected at the backend to estimate energy consumption of the mote. Such approach scales well to the number of motes and does not require modification to the mote or its network stack. Experimental results from extensive measurements conducted on two platforms, i.e., OpenMote and Zolertia Z1, demonstrate promising potential. The energy model can achieve an estimation accuracy over 90% for platform power, and over 85% accuracy for radio power consumption, on various scenarios."}, "conf/IEEEcloud/ZhuangLOA13": {"title": "Impact of Instance Seeking Strategies on Resource Allocation in Cloud Data Centers.", "url": "https://doi.org/10.1109/CLOUD.2013.81", "year": "2013", "author": {"Hao Zhuang 0002": "84/10899-2", "Xin Liu 0027": "76/1820-27", "Zhonghong Ou": "58/6143", "Karl Aberer": "a/KarlAberer"}, "abstract": " Abstract:With the prosperity of cloud computing, an increasing number of Small and Medium-sized Enterprises (SMEs) move their business to public clouds such as Amazon EC2. To help tenants deploy services in the cloud, researchers either conduct performance evaluations or design mechanisms and software on seeking virtual machines of better performance. However, few studies have investigated the impact of instance seeking strategies on resource allocation in clouds if every tenant starts to apply the same method to find the better performing virtual machine. In this paper, we propose a cloud and a tenant model in order to simulate the process of tenants' seeking better-performing instances in the cloud. We discuss, implement and evaluate six cloud resource allocation strategies and five instance seeking strategies. We perform the evaluation via simulation based on real data traces. Our results show that instance seeking strategies can cause the exhaustion of better-performing instances and significant request growth in the cloud. Furthermore, we find that tenants could save time and budget through collaborative seeking strategies. Finally, we discuss the implications of our findings from perspectives of both tenants and providers."}, "conf/globecom/DongOYC13": {"title": "Mobile hotspots cooperation towards better energy efficiency.", "url": "https://doi.org/10.1109/GLOCOMW.2013.6825080", "year": "2013", "author": {"Jiang Dong": "64/2623", "Zhonghong Ou": "58/6143", "Antti Ylä-Jääski": "63/5415", "Yong Cui 0001": "91/2346-1"}, "abstract": " Abstract:Power consumption from wireless data communications contributes a significant part for the overall mobile phone platform power. Compared with cellular data transmission, Wi-Fi transmission is more energy-efficient. Nevertheless, there are scenarios where cellular network is the only option to access the Internet for a number of mobile phones because of limited Wi-Fi access. This paper proposes a cooperative approach of using Wi-Fi tethering technique to optimize the overall power consumption. Based on a series of real measurements, we characterize the relationship among signal strength, network bandwidth and power consumption, and point out principles of choosing appropriate mobile hotspot nodes. Then we propose two cooperative algorithms to optimize the overall power consumption, i.e., most suitable hotspot first (MSHF) and most suitable leaf first (MSLF). Simulation results demonstrate that MSHF can acquire 24% power saving and MSLF can achieve up to 29% compared with regular 3G approach."}, "conf/mass/LiuLHOYO13": {"title": "Distributed Resource Discovery in the Machine-to-Machine Applications.", "url": "https://doi.org/10.1109/MASS.2013.46", "year": "2013", "author": {"Meirong Liu": "35/4171", "Teemu Leppänen": "59/9531", "Erkki Harjula": "18/4722", "Zhonghong Ou": "58/6143", "Mika Ylianttila": "34/76", "Timo Ojala": "62/3842"}, "abstract": " Abstract:One challenging problem in Machine-to-Machine (M2M) applications is to efficiently discover the resources provided by a huge number of heterogeneous devices. This paper proposes distributed resource discovery architecture (DRD) for M2M applications. The DRD supports heterogeneous devices in resource description registration and discovery of resource value. It achieves interoperability among heterogeneous devices in disparate networks and enables resource access from the Internet. In the DRD, a resource registration component is designed for storing resource descriptions, a resource discovery component is designed to retrieve resource values on behalf of clients after getting address information by looking up resource descriptions. The DRD utilizes a peer-to-peer overlay to distribute workload and avoid single point of failure. A real-world prototype is implemented and verified with a simple demo. Preliminary evaluation on response time of resource discovery is provided."}, "conf/mobiarch/OuDDNYW13": {"title": "Characterize energy impact of concurrent network-intensive applications on mobile platforms.", "url": "https://doi.org/10.1145/2505906.2505909", "year": "2013", "author": {"Zhonghong Ou": "58/6143", "Shichao Dong": "67/8730", "Jiang Dong": "64/2623", "Jukka K. Nurminen": "38/1107", "Antti Ylä-Jääski": "63/5415", "Ren Wang 0001": "29/50-1"}, "abstract": "\n\t\tThe cellular network bandwidth increases significantly in the past few years, stimulated by many popular network-intensive applications, such as video streaming and cloud storage usages. Meanwhile, more and more users enjoy the multitasking feature of mobile devices and concurrently run a number of applications. Given these two trends and the fact that extended battery life remains to be a critical factor for small form factor devices, e.g. smartphones and tablets, it is imperative to understand the energy impact of multiple applications running concurrently on such platforms. In this paper, we characterize and understand the energy and performance impact of concurrent applications via a comprehensive set of carefully designed experiments. Specifically, we focus on network-intensive applications since most usage models today are driven by always-on communication activities. We make several significant contributions to shed light on understanding the energy behavior of concurrent applications. Firstly, we find out that running multiple network-intensive applications concurrently can significantly improve energy efficiency, up to 2.2X compared to running them separately. Secondly, we observe that power consumption from CPU and System on Chip (SoC) are the primary culprits of power dynamic for network-intensive applications; while communication components, including Network Interface Card (NIC), poses very little power consumption variation with different throughput. Thirdly, we investigate, in detail, the significant impact of signal strength on the energy consumption and throughput performance. Our findings and analysis can be applied to provide helpful guidance for a wide range of research aiming to optimize mobile device energy efficiency, e.g. transmission scheduling and protocol design in cellular networks.\n\t"}, "conf/wimob/LiuLHORYO13": {"title": "Distributed resource directory architecture in Machine-to-Machine communications.", "url": "https://doi.org/10.1109/WiMOB.2013.6673379", "year": "2013", "author": {"Meirong Liu": "35/4171", "Teemu Leppänen": "59/9531", "Erkki Harjula": "18/4722", "Zhonghong Ou": "58/6143", "Archana Ramalingam": "136/0926", "Mika Ylianttila": "34/76", "Timo Ojala": "62/3842"}, "abstract": " Abstract:Machine-to-Machine (M2M) communications emerge to achieve ubiquitous communications among all the networked devices. One challenging problem in M2M applications is to discover the resources provided by the devices efficiently. This challenge arises from two perspectives: (1) a large number of heterogeneous devices co-exist and most of them are constrained devices (e.g., limited processing capability), (2) different communication protocols are utilized to get access to different types of resources provided by the devices (e.g., humidity information provided by a sensor). This paper proposes distributed resource directory architecture for M2M applications, referred to as DRD4M. The DRD4M supports heterogeneous devices using HTTP and CoAP protocols for resource registration and lookup. This enables the interoperability among heterogeneous devices and resource access to constrained devices from disparate network including the Internet. The DRD4M introduces two components: a resource registration component for registering resources and a resource lookup component with caching functionality for handling resource lookup with filtering. A peer-to-peer (P2P) overlay is introduced in DRD4M to connect resource peers to avoid single point of failure. A real-world prototype is implemented and is verified with a demo application. Preliminary performance evaluation in terms of response time of resource lookup is provided."}, "conf/ccgrid/OuPDNYH12": {"title": "Energy- and Cost-Efficiency Analysis of ARM-Based Clusters.", "url": "https://doi.org/10.1109/CCGrid.2012.84", "year": "2012", "author": {"Zhonghong Ou": "58/6143", "Bo Pang": "16/6344", "Yang Deng 0003": "115/6282-3", "Jukka K. Nurminen": "38/1107", "Antti Ylä-Jääski": "63/5415", "Pan Hui 0001": "62/1272-1"}, "abstract": " Abstract:General-purpose computing domain has experienced strategy transfer from scale-up to scale-out in the past decade. In this paper, we take a step further to analyze ARM-processor based cluster against Intel X86 workstation, from both energy-efficiency and cost-efficiency perspectives. Three applications are selected and evaluated to represent diversified applications, including Web server throughput, in-memory database, and video transcoding. Through detailed measurements, we make the observations that the energy-efficiency ratio of the ARM cluster against the Intel workstation varies from 2.6-9.5 in in-memory database, to approximately 1.3 in Web server application, and 1.21 in video transcoding. We also find out that for the Intel processor that adopts dynamic voltage and frequency scaling (DVFS) techniques, the power consumption is not linear with the CPU utilization level. The maximum energy saving achievable from DVFS is 20%. Finally, by utilizing a monthly cost model of data centers, we conclude that ARM cluster based data centers are feasible, and are advantageous in computationally lightweight applications, e.g. in-memory database and network-bounded Web applications. The cost advantage of ARM cluster diminishes progressively for computation-intensive applications, i.e. dynamic Web server application and video transcoding, because the number of ARM processors needed to provide comparable performance increases."}, "conf/ccis/DengOKLY12": {"title": "Anatomy of the connecting architecture of Internet of Things.", "url": "https://doi.org/10.1109/CCIS.2012.6664580", "year": "2012", "author": {"Yang Deng 0003": "115/6282-3", "Zhonghong Ou": "58/6143", "Miika Komu": "89/7882", "Vilen Looga": "115/6370", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Internet of Things (IoT) holds a promise that any consumer device can be connected to the Internet and accessed from any network at any time. Most of the state of the art research focuses on application-specific scenarios but a holistic architectural overview of how to connect different heterogeneous IoT networks to the Internet is still missing. In this paper, we present such an overview and a qualitative comparison of the proposed design models. Specifically, we compare three connectivity models, which we refer to as Link Model, Proxy Model and Full-IP Model, from the viewpoint of performance, scalability, applicability and hardware requirements, etc. Finally, we discuss the on-going trends and future challenges."}, "conf/ccis/LoogaODY12": {"title": "MAMMOTH: A massive-scale emulation platform for Internet of Things.", "url": "https://doi.org/10.1109/CCIS.2012.6664581", "year": "2012", "author": {"Vilen Looga": "115/6370", "Zhonghong Ou": "58/6143", "Yang Deng 0003": "115/6282-3", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Internet of Things (IoT) is increasingly used in a plethora of fields to enable radically new ways for various purposes, ranging from monitoring the environment to enhancing the wellbeing of human life. With the ever-increasing size of such networks, it is fundamental to understand the issues that come with scaling on different networking layers. A cost-efficient approach to examine large-scale networks is to use simulators or emulators to test the infrastructure and its ability to support the desired applications. In this paper, we investigate and compare the currently available simulation/emulation software. We found out that the current solutions are mostly appropriate for small- and medium-scale emulation, however they are not suitable for large-scale testing that reaches millions of node running concurrently. We then propose a large-scale IoT emulator called MAMMotH and present a brief overview of its design. Finally we discuss some of the current issues and future directions, e.g. radio link simulation."}, "conf/hotcloud/OuZNYH12": {"title": "Exploiting Hardware Heterogeneity within the Same Instance Type of Amazon EC2.", "url": "https://www.usenix.org/conference/hotcloud12/workshop-program/presentation/ou", "year": "2012", "author": {"Zhonghong Ou": "58/6143", "Hao Zhuang 0002": "84/10899-2", "Jukka K. Nurminen": "38/1107", "Antti Ylä-Jääski": "63/5415", "Pan Hui 0001": "62/1272-1"}, "abstract": ""}, "conf/nsdr/ZhuangNOP12": {"title": "A Service Adaptation Middleware for Delay Tolerant Network based on HTTP Simple Queue Service.", "url": "https://www.usenix.org/conference/nsdr12/workshop-program/presentation/zhuang", "year": "2012", "author": {"Hao Zhuang": "84/10899", "Hervé Ntareme": "10/4248", "Zhonghong Ou": "58/6143", "Björn Pehrson": "57/537"}, "abstract": ""}, "conf/wcnc/LoogaXOY12": {"title": "Exploiting traffic scheduling mechanisms to reduce transmission cost on mobile devices.", "url": "https://doi.org/10.1109/WCNC.2012.6214070", "year": "2012", "author": {"Vilen Looga": "115/6370", "Yu Xiao 0001": "54/5385-1", "Zhonghong Ou": "58/6143", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Energy consumption of wireless data transmission heavily depends on the shape of the outgoing traffic of the mobile device. In this paper, we propose a traffic scheduler that shapes the packets into consistent bursts based on per-packet performance constraints in order to reduce the overall transmission cost. Our scheduler takes into account the scenarios where multiple network applications run concurrently on the mobile device. We evaluate the traffic scheduler with real-life traffic traces from delay-sensitive applications, e.g. Internet radio and YouTube, and delay-tolerant applications e.g. Web browsing. The results show that depending on scenarios 23% to 72% energy savings can be achieved without noticeable performance degradation. Furthermore, our traffic scheduler is of low time complexity O(n), which makes it suitable to be deployed on proxies or directly on mobile devices."}, "conf/globecom/BhebheO11": {"title": "Impact of packet forwarding during Inter-eNodeB handover via X2 interface.", "url": "https://doi.org/10.1109/GLOCOMW.2011.6162524", "year": "2011", "author": {"Leo Bhebhe": "52/6906", "Zhonghong Ou": "58/6143"}, "abstract": " Abstract:This paper analyses the impact of packet forwarding during Inter-eNodeB handover via X2 interface. Performance issues with regard to providing enough capacity at the X2 interface, handling of packets to forward at the source eNodeB are analyzed. The analysis shows that to provide better application performance, proper dimensioning of the X2 interface is required taking into account the anticipated traffic from cells and mobility patterns of users. It further shows that the high sensitive packets need priority in forwarding them to the target eNodeB."}, "conf/ccnc/OuZHY10": {"title": "Truncated Pyramid Peer-to-Peer Architecture with Vertical Tunneling Model.", "url": "https://doi.org/10.1109/CCNC.2009.4784957", "year": "2009", "author": {"Zhonghong Ou": "58/6143", "Jiehan Zhou": "48/4230", "Erkki Harjula": "18/4722", "Mika Ylianttila": "34/76"}, "abstract": " Abstract:Peer-to-Peer (P2P) technologies have many advantages over traditional client/server technologies, including cost- effectiveness, scalability and robustness, due to their decentralized network structure. However, the performance has traditionally been an issue in P2P systems. Especially the higher lookup latencies, when compared with the traditional client/server systems, have been the bottleneck in many P2P systems. In this paper, we propose a truncated pyramid P2P architecture together with an enhanced model, Vertical Tunneling Model (VTM) for improving the lookup performance. The proposed architecture is built on Peer-to-Peer SIP (P2PSIP) network. VTM builds up vertical tunnels between the upper and lower sub-overlays to speed up the service lookup and decrease the session setup delay. Based on the performance analysis and results, it is shown that VTM has better performance compared with the existing systems in average lookup hops, which is about 1/3 of that of the existing systems, the predominance is more evident as the network scale increases."}, "conf/mobility/OuHKY09": {"title": "Feasibility evaluation of a communication-oriented P2P system in mobile environments.", "url": "https://doi.org/10.1145/1710035.1710078", "year": "2009", "author": {"Zhonghong Ou": "58/6143", "Erkki Harjula": "18/4722", "Otso Kassinen": "35/5308", "Mika Ylianttila": "34/76"}, "abstract": "\n\t\tWe present the feasibility evaluation of a structured communication-oriented Peer-to-Peer (P2P) system being used in mobile environments in this paper. The different levels of churn are modeled by the exponential distribution with varied value of mean online time. Our system utilizes Kademlia with some modifications as the underlying Distributed Hash Table (DHT) algorithm, and Peer-to-Peer Protocol (P2PP), one of the former candidates of Peer-to-Peer Session Initiation Protocol (P2PSIP) working group, as the signaling protocol. A prototype is implemented to evaluate the feasibility of mobile nodes acting as fully fledged peers. The prototype measurements show it is feasible for the mobile nodes to take part in the overlay from the viewpoints of CPU load and network traffic load. Through battery measurements, we draw the conclusion that the UMTS access mode consumes slightly more power than the WLAN access mode in general. Protocol packets with sizes of 200 bytes or less are observed to be the most energy efficient in the UMTS access mode.\n\t"}, "conf/pimrc/OuHY09": {"title": "Effects of different churn models on the performance of structured peer-to-peer networks.", "url": "https://doi.org/10.1109/PIMRC.2009.5450134", "year": "2009", "author": {"Zhonghong Ou": "58/6143", "Erkki Harjula": "18/4722", "Mika Ylianttila": "34/76"}, "abstract": " Abstract:We present the effects of different churn models on the performance of structured peer-to-peer (P2P) networks in this paper. Specifically, Exponential distribution (ED), Pareto distribution (PD), and Weibull distribution (WD) are evaluated to provide a comparative analysis. Kademlia-based Peer-to-Peer Protocol (P2PP) is utilized as the underlying signaling protocol. Through simulations, we conclude that the simulated different churn models do not have a significant effect on the performance of the simulated structured P2P network. Quantitatively, ED and PD result in better performance compared to WD from the viewpoints of lookup success rate, mean network traffic load, and mean number of messages."}, "conf/prdc/LiuMO09": {"title": "A Novel Process Migration Method for MPI Applications.", "url": "https://doi.org/10.1109/PRDC.2009.46", "year": "2009", "author": {"Tiantian Liu": "85/7672", "Zhong Ma": "68/4060", "Zhonghong Ou": "58/6143"}, "abstract": " Abstract:Though a lot of research has been done on fault tolerance for MPI applications, process migration has not gained widespread use because the complexity of the requirement that the knowledge about the location of a migrated process has to be made known to every other process in the MPI application. In this paper, we present a novel and effective process migration method for MPI application. We implement a prototype called LAM/Migration which based on LAM/MPI + BLCR to provide transparent process migration for MPI application and the migration mechanism is built into LAM/MPI. All processes in MPI application including mpirun and MPI processes can be migrated to any different set of spare nodes in cluster under user specified in case of nodes failure in our method. Performance evaluation results showed that the checkpoint overhead is similar to plain LAM/MPI + BLCR, and the migration method is feasible and promising for overcoming nodes failure in large-scale parallel computing. By using LAM/Migration, the high availability and reliability of parallel computation can be achieved."}, "conf/gpc/OuSCS08": {"title": "Layered Peer-to-Peer Architecture for Mobile Web Services via Converged Cellular and Ad Hoc Networks.", "url": "https://doi.org/10.1109/GPC.WORKSHOPS.2008.42", "year": "2008", "author": {"Zhonghong Ou": "58/6143", "Meina Song": "95/4440", "Hui Chen": "12/417", "Junde Song": "60/5010"}, "abstract": " Abstract:Mobile communication technology is rapidly developed with the enhanced networking capacities as well as the expanding population of mobile subscribers. Providing Web services via converged mobile cellular and Ad Hoc networks has attracted growing attentions. In this paper, a layered peer-to-peer (P2P) architecture is designed for providing Web services via converged mobile cellular and Ad Hoc networks. To speed up the service discovery, a vertical tunneling model is developed as well as the service being classified into \"hot\", \"warm \" and \"cold\". A plug-and-play middleware architecture is developed enabling mobile Web services communication and adapting the heterogeneity of mobile terminals. The diagram of the message sequences implementing the plug-and-play middleware architecture is designed with the case of weather service provision."}, "conf/mobility/KoskelaKKOY08": {"title": "Peer-to-peer community management using structured overlay networks.", "url": "https://doi.org/10.1145/1506270.1506283", "year": "2008", "author": {"Timo Koskela": "01/6155", "Otso Kassinen": "35/5308", "Jari Korhonen": "15/6505", "Zhonghong Ou": "58/6143", "Mika Ylianttila": "34/76"}, "abstract": "\n\t\tIn this paper, we present a system for the distributed management of user communities. The system utilizes multiple DHT overlay networks where nodes communicate in a peer-to-peer manner. Our system works on top of a P2PSIP protocol implementation that carries out the DHT signaling. The key idea behind our system is to use one overlay network per community; this results in multiple small overlays that are subsets of the main overlay. We evaluate how the usage of small community-overlays affects the nodes' load, as opposed to doing all activities in the main overlay. We also evaluate how the maintenance of community-overlays affects the nodes' load. Finally, we observe the tradeoff between these two quantities; while multiple small overlays decrease DHT-related network traffic in community activities, the management of multiple overlays also introduces some additional load to the nodes.\n\t"}, "conf/mobility/OuHY08": {"title": "GTPP: general truncated pyramid architecture over P2PSIP networks.", "url": "https://doi.org/10.1145/1506270.1506298", "year": "2008", "author": {"Zhonghong Ou": "58/6143", "Erkki Harjula": "18/4722", "Mika Ylianttila": "34/76"}, "abstract": "\n\t\tThere is recently some research work focusing on the multiple-level hierarchical overlay architecture in peer-to-peer (P2P) SIP networks with some assumptions. But questions such as what performance improvements can be achieved and how many levels should be existed in the architecture have not been proved from the mathematical aspect. In this paper, a general truncated pyramid architecture over P2PSIP networks (GTPP) has been put forward in which the number of peers of each level of sub-overlay is subject to the negative exponential distribution (NED) according to the maximum information entropy theorem. Utilizing the similarity between geometric distribution (GD) and NED, we harness GD to distribute peers into multiple sub-overlays to convert the distribution function into discrete domain. Through mathematical evaluation, we get the conclusion that 2~4 levels of sub-overlays are appropriate for most of the systems which also takes the maintenance cost into consideration. As for the number of peers in each sub-sub-overlay (SSO), the kth root of the total number of peers N, that is to say, n = N1/k, is a proper number taking the load balancing into account, wherein k stands for the total number of levels of GTPP.\n\t"}, "conf/mum/KassinenOYH08": {"title": "Effects of peer-to-peer overlay parameters on mobile battery duration and resource lookup efficiency.", "url": "https://doi.org/10.1145/1543137.1543173", "year": "2008", "author": {"Otso Kassinen": "35/5308", "Zhonghong Ou": "58/6143", "Mika Ylianttila": "34/76", "Erkki Harjula": "18/4722"}, "abstract": "\n\t\tThis paper evaluates the feasibility of mobile nodes as peers in a structured peer-to-peer overlay network. Our performance analysis is based on the Peer-to-Peer Protocol (P2PP), which is a peer protocol candidate for the Peer-to-Peer Session Initiation Protocol (P2PSIP). We use both, live-network measurements and simulations, to evaluate two performance metrics: resource lookup success rate and mobile battery duration. While lookup success rate measures P2PP performance in general, battery duration is crucial for mobile use of P2PP. Restricted battery life limits the feasibility of mobile peers. We reveal the tradeoff between lookup success rate and battery duration. Based on the findings it is possible to find more suitable protocol parameters for mobile peers. The battery duration measurements, made with UDP in UMTS and WLAN access networks, are also applicable in the wireless usage of other application-layer protocols.\n\t"}, "conf/services/ZhouORY08": {"title": "P2P SCCM: Service-Oriented Community Coordinated Multimedia over P2P.", "url": "https://doi.org/10.1109/SERVICES-2.2008.32", "year": "2008", "author": {"Jiehan Zhou": "48/4230", "Zhonghong Ou": "58/6143", "Mika Rautiainen": "85/2702", "Mika Ylianttila": "34/76"}, "abstract": " Abstract:Peer-to-peer service-oriented community coordinated multimedia (SCCM) is envisioned as a novel paradigm in which the user consumes multiple media through requesting multimedia-intensive Web services via diversity display devices, converged networks, and heterogeneous platforms within a virtual, open and collaborative community. In this paper, a generic P2P SCCM scenario is created and examined first. A SCCM model is designed with the adoption of the service orientation approach and principles. A tunneled hierarchical P2P model is designed and its performance is analyzed for improving service lookup and session setup. A preliminary SCCM prototype is developed with the design of content annotation service."}, "conf/prdc/OuYZ05": {"title": "Research on Architecture and Design Principles of COTS Components Based Generic Fault-Tolerant Computer.", "url": "https://doi.org/10.1109/PRDC.2005.53", "year": "2005", "author": {"Zhonghong Ou": "58/6143", "Youguang Yuan": "64/2943", "Xiaoyong Zhao": "30/6275"}, "abstract": " Abstract:A novel fault-tolerant architecture based on COTS components is put forward and implemented in this paper. In order to make observable the internal states of COTS components, and in order to concurrently perform fault-tolerance function and normal function and control the behavior of each COTS component, the authors have devised an intelligent hardware module dedicated to fault-tolerance processing, which can significantly offload application processors. This architecture digs every inherent fault-detection mechanism and adopts layered fault protection mechanism to raise fault-tolerance coverage. This architecture is efficient, flexible, scalable and transparent with respect to fault-tolerance. It is Byzantine fault safe and also supports online repair. The authors also raise some design tradeoffs when designing COTS components based fault-tolerant computer."}, "journals/iotj/OuHSYH21": {"title": "Redundancy Removing Aggregation Network With Distance Calibration for Video Face Recognition.", "url": "https://doi.org/10.1109/JIOT.2020.3038776", "year": "2021", "author": {"Zhonghong Ou": "58/6143", "Yucheng Hu": "59/9331", "Meina Song": "95/4440", "Zheng Yan 0002": "43/180-2", "Pan Hui 0001": "62/1272-1"}, "abstract": " Abstract:Attention-based techniques have been successfully used for rating image quality, and have been widely employed for set-based face recognition. Nevertheless, for video face recognition, where the base convolutional neural network (CNN) trained on large-scale data already provides discriminative features, fusing features with only predicted quality scores to generate representation are likely to cause duplicate sample dominant problem, and degrade performance correspondingly. To resolve the problem mentioned above, we propose a redundancy removing aggregation network (RRAN) for video face recognition. Compared with other quality-aware aggregation schemes, RRAN can take advantage of similarity information to tackle the noise introduced by redundant video frames. By leveraging metric learning, RRAN introduces a distance calibration scheme to align distance distributions of negative pairs of different video representations, which improves the accuracy under a uniform threshold. A series of experiments is conducted on multiple realistic data sets to evaluate the performance of RRAN, including YouTube Faces, IJB-A, and IJB-C. In comprehensive experiments, we demonstrate that our method can diminish the overall influence of poor quality components with large proportion in the video and further improve the overall recognition performance with individual difference. Specifically, RRAN achieves a 96.84% accuracy on YouTube Face, outperforming all existing aggregation schemes."}, "journals/access/OuLKSS19": {"title": "CNN Compression-Recovery Framework via Rank Allocation Decomposition With Knowledge Transfer.", "url": "https://doi.org/10.1109/ACCESS.2019.2932773", "year": "2019", "author": {"Zhonghong Ou": "58/6143", "Yunfeng Liu": "56/5650", "Huihui Kong": "247/3690", "Meina Song": "95/4440", "Yingxia Shao": "131/2926"}, "abstract": " Abstract:Low-rank decomposition is an effective way to decrease the model size of convolutional neural networks (CNNs). Nevertheless, selecting the layer-specific rank is a difficult task, because the layers are not equally redundant. The previous methods are mainly by manual, require expertise, or do not consider the different sensitivity of each layer. This paper proposes a rank allocation decomposition (RAD) method to decompose network by allocating rank for each layer automatically. The idea is to transform the combinatorial optimization problem of rank into a constrained optimal search problem, which can be solved by a greedy algorithm. To recover accuracy of the decomposed network, a novel knowledge transfer based approach is introduced, named SchoolNet. It aligns outputs and intermediate responses from the original (teacher) network to its compressed (student) network while transferring dark knowledge from a strong (headmaster) network with high accuracy to the student network. The experimental results from several advanced models, including AlexNet, VGG-16, and ResNet-50, demonstrate that our scheme can reduce parameters significantly while maintaining a high accuracy level. Specifically, for the VGG-16 on Birds-200 dataset, we achieve 48x compression rate with even 0.13% top-1 accuracy improvement, which outperforms the state-of-the-art remarkably."}, "journals/access/OuXXSS19": {"title": "FAMN: Feature Aggregation Multipath Network for Small Traffic Sign Detection.", "url": "https://doi.org/10.1109/ACCESS.2019.2959015", "year": "2019", "author": {"Zhonghong Ou": "58/6143", "Fenrui Xiao": "255/7890", "Baiqiao Xiong": "255/8201", "Shenda Shi": "255/8207", "Meina Song": "95/4440"}, "abstract": " Abstract:Traffic sign detection has achieved promising results in recent years. Nevertheless, there are still two problems remain to be overcome. One problem is the detection of small traffic signs, which usually occupy less than 2% of the image area. The other problem is fine-grained classification, with difficulties arising from similar appearances between traffic signs. For example, different speed-limit traffic signs have differences solely from the speed numbers. In this paper, we propose a Feature Aggregation MultiPath Network (FAMN) to tackle the problems simultaneously. First, we propose a Feature Aggregation (FA) structure to aggregate regional features from different feature maps by using element-wise Max, then convolution layers are used to extract rich semantic features. Accordingly, objects of different scales can choose the best features to improve performance of small object detection. Second, we propose a Multipath Network (MN) structure to obtain fine-grained features. The MN structure consists of three paths, extracting instance-level, part-level, and context-level features, respectively. The three types of features are then concatenated to form fine-grained features of the proposals. Experimental results demonstrate the effectiveness of our proposed FAMN. Specifically, FAMN is able to obtain an average F1-measure of 93.1% in TT100K dataset, 2.9% higher than the state-of-the-art."}, "journals/jss/OuSHYWCH18": {"title": "Is cloud storage ready? Performance comparison of representative IP-based storage systems.", "url": "https://doi.org/10.1016/j.jss.2018.01.015", "year": "2018", "author": {"Zhonghong Ou": "58/6143", "Meina Song": "95/4440", "Zhen-Huan Hwang": "177/5000", "Antti Ylä-Jääski": "63/5415", "Ren Wang 0001": "29/50-1", "Yong Cui 0001": "91/2346-1", "Pan Hui 0001": "62/1272-1"}, "abstract": "Network based storage systems have traditionally been dominated by Network Attached Storage (NAS) and Storage Area Network (SAN). Cloud based storage systems, including object storage, have gained growing popularity among both private and enterprise users in recent years. Certain enterprises have even considered replacing traditional storage systems with cloud-based systems. Nevertheless, there still lacks a systematic comparative study on the performance of the aforementioned systems to assist such a transition. To fill in this gap, in this paper, we conduct a comprehensive study on the three major network storage systems with realistic network conditions and application behaviours. Specifically, we select one representative from each category for comparison, i.e., Network File System (NFS) from NAS, Internet Small Computer System Interface (iSCSI) from SAN, and OpenStack Swift from cloud storage. As the first study of its kind, we mainly focus on the client-side and take performance as the perspective for comparison. We build a testbed and a suite of micro-benchmarks to study the impact of network complexities and access behaviours on performance. In addition, we employ two widely used macro-benchmarks – PostMark and FileBench – to test the three systems under realistic workloads. Through a set of comprehensive experiments and thorough analysis, we make several key observations. (1) iSCSI excels under good network conditions, e.g., in local area networks (LANs); when network complexities like network delay and packet loss exist, its performance degrades significantly, especially for data-intensive operations. (2) For Internet-like environments, NFS performs poorly, while Swift demonstrates much resilience. (3) Overall, Swift is a viable replacement for NFS in all network scenarios, while it is not ready yet to replace iSCSI for performance-critical environments. (4) System configuration on the client side impacts storage performance significantly and deserves adequate attention. Based on our experimental study, we also make several recommendations to practitioners and pinpoint aspects for system designers to improve each storage system further."}, "journals/tompecs/KhanHNNO18": {"title": "RAPL in Action: Experiences in Using RAPL for Power Measurements.", "url": "https://doi.org/10.1145/3177754", "year": "2018", "author": {"Kashif Nizam Khan": "33/8214", "Mikael Hirki": "116/3003", "Tapio Niemi": "48/1823", "Jukka K. Nurminen": "38/1107", "Zhonghong Ou": "58/6143"}, "abstract": "To improve energy efficiency and comply with the power budgets, it is important to be able to measure the power consumption of cloud computing servers. Intel’s Running Average Power Limit (RAPL) interface is a powerful tool for this purpose. RAPL provides power limiting features and accurate energy readings for CPUs and DRAM, which are easily accessible through different interfaces on large distributed computing systems. Since its introduction, RAPL has been used extensively in power measurement and modeling. However, the advantages and disadvantages of RAPL have not been well investigated yet. To fill this gap, we conduct a series of experiments to disclose the underlying strengths and weaknesses of the RAPL interface by using both customized microbenchmarks and three well-known application level benchmarks: Stream, Stress-ng, and ParFullCMS. Moreover, to make the analysis as realistic as possible, we leverage two production-level power measurement datasets from the Taito, a supercomputing cluster of the Finnish Center of Scientific Computing and also replicate our experiments on Amazon EC2. Our results illustrate different aspects of RAPL and document the findings through comprehensive analysis. Our observations reveal that RAPL readings are highly correlated with plug power, promisingly accurate enough, and have negligible performance overhead. Experimental results suggest RAPL can be a very useful tool to measure and monitor the energy consumption of servers without deploying any complex power meters. We also show that there are still some open issues, such as driver support, non-atomicity of register updates, and unpredictable timings that might weaken the usability of RAPL in certain scenarios. For such scenarios, we pinpoint solutions and workarounds."}, "journals/kbs/SongZEO17": {"title": "Statistics-based CRM approach via time series segmenting RFM on large scale data.", "url": "https://doi.org/10.1016/j.knosys.2017.05.027", "year": "2017", "author": {"Meina Song": "95/4440", "Xuejun Zhao": "78/936", "Haihong E": "43/10222", "Zhonghong Ou": "58/6143"}, "abstract": "Conventional customer relationship management (CRM) is typically based on RFM model, whose parameters are the recency, frequency and monetary aspects of target customers. The latest comprehensive analysis has enabled CRM to present parameters with time series. For example, researchers can account for changing trends based on an RFM model for flexible marketing strategies. Such changes might inspire telecommunication service scenarios that user value relies on long-term performance. In this study, we propose a statistic-based approach to value latent users via time series segmenting time interval of RFM in large scale data set. Apart from utilizing in Spark platform, we integrate multiple corresponding analysis (MCA) to regularize clustering results by the RFM model and extend these approaches to multiple levels. A comprehensive set of experiments, revealed interesting observations regarding the co-existence of time interval and RFM model. First, the clustering method along time interval in three dimensions of the RFM model outperforms the method along the three dimensions in each interval. Subsequently, the cooperation of RFM and MCA provides a convenient methodology for exploring CRM in large–scale data. Therefore, the RFM model with time intervals integrated with MCA in CRM are essential."}, "journals/tmc/SongOCYKSYH17": {"title": "Exploring Vision-Based Techniques for Outdoor Positioning Systems: A Feasibility Study.", "url": "https://doi.org/10.1109/TMC.2017.2696943", "year": "2017", "author": {"Meina Song": "95/4440", "Zhonghong Ou": "58/6143", "Eduardo Castellanos": "208/9976", "Tuomas Ylipiha": "208/9894", "Teemu Kämäräinen": "157/0335", "Matti Siekkinen": "78/3796", "Antti Ylä-Jääski": "63/5415", "Pan Hui 0001": "62/1272-1"}, "abstract": " Abstract:Recent advances from wearables have significantly changed the way how humans communicate with the surrounding environment. To some extent, they have extended and augmented the capability of humans. For example, with a Google Glass, people can take pictures simply by winking eyes twice, which releases human hands from the cumbersome image-taking process. Thus, it enables new application scenarios that were not possible before. In this paper, we investigate utilizing vision-based techniques to provide a wearable positioning system. Specifically, we propose a Human-centric Positioning System (HoPS) that utilizes traffic signposts together with context information for real-time positioning. Towards that direction, we make three primary contributions: (1) we make several important observations that guide our design of HoPS system; for example, we find out that approximately 40 percent of traffic signposts monopolize a cell tower, and there are at most six signposts within the coverage of a single cell tower; (2) we investigate the impact factors of object detection success rate, and find its correlation with image quality, and resolution; and (3) we design and implement HoPS and an advanced version of HoPS based on additional context information from Wi-Fi network, which we name HoPS-WiFi. Experimental results demonstrate the effectiveness of HoPS, especially HoPS-WiFi, which can estimate the relevant location correctly within 1.3 seconds."}, "journals/tos/HouCOWM17": {"title": "Understanding I/O Performance Behaviors of Cloud Storage from a Client's Perspective.", "url": "https://doi.org/10.1145/3078838", "year": "2017", "author": {"Binbing Hou": "175/6835", "Feng Chen 0005": "21/3047-5", "Zhonghong Ou": "58/6143", "Ren Wang 0001": "29/50-1", "Michael P. Mesnier": "m/MichaelPMesnier"}, "abstract": "Cloud storage has gained increasing popularity in the past few years. In cloud storage, data is stored in the service provider’s data centers, and users access data via the network. For such a new storage model, our prior wisdom about conventional storage may not remain valid nor applicable to the emerging cloud storage. In this article, we present a comprehensive study to gain insight into the unique characteristics of cloud storage and optimize user experiences with cloud storage from a client’s perspective. Unlike prior measurement work that mostly aims to characterize cloud storage providers or specific client applications, we focus on analyzing the effects of various client-side factors on the user-experienced performance. Through extensive experiments and quantitative analysis, we have obtained several important findings. For example, we find that (1) a proper combination of parallelism and request size can achieve optimized bandwidths, (2) a client’s capabilities and geographical location play an important role in determining the end-to-end user-perceivable performance, and (3) the interference among mixed cloud storage requests may cause performance degradation. Based on our findings, we showcase a sampling- and inference-based method to determine a proper combination for different optimization goals. We further present a set of case studies on client-side chunking and parallelization for typical cloud-based applications. Our studies show that specific attention should be paid to fully exploiting the capabilities of clients and the great potential of cloud storage services."}, "journals/comsur/LiLOYTCS16": {"title": "Multipath Transmission for the Internet: A Survey.", "url": "https://doi.org/10.1109/COMST.2016.2586112", "year": "2016", "author": {"Ming Li 0035": "l/MingLi35", "Andrey Lukyanenko": "72/1967", "Zhonghong Ou": "58/6143", "Antti Ylä-Jääski": "63/5415", "Sasu Tarkoma": "66/5629", "Matthieu Coudron": "140/1908", "Stefano Secci": "40/6812"}, "abstract": " Abstract:Smart devices equipped with multiple network interfaces are becoming commonplace. Nevertheless, even though multiple interfaces can be used to connect to the Internet, their capabilities have not been fully utilized yet because the default TCP/IP stack supports only a single interface for communication. This situation is now changing due to the emergence of multipath protocols on different network stack layers. For example, many IP level approaches have been proposed utilizing tunneling mechanisms for hiding multipath transmission from the transport protocols. Several working groups under IEEE and IETF are actively standardizing multipath transmission on the link layer and transport layer. Application level approaches enable multipath transmission capability by establishing multiple transport connections and distributing data over them. Given all these efforts, it is beneficial and timely to summarize the state-of-the-art, compare their pros and cons, and discuss about the future directions. To that end, we present a survey on multipath transmission and make several major contributions: 1) we present a complete taxonomy pertaining to multipath transmission, including link, network, transport, application, and cross layers; 2) we survey the state-of-the-art for each layer, investigate the problems that each layer aims to address, and make comprehensive assessment of the solutions; and 3) based on the comparison, we identify open issues and pinpoint future directions for multipath transmission research."}, "journals/ife/KhanOHNN16": {"title": "How much power does your server consume? Estimating wall socket power using RAPL measurements.", "url": "https://doi.org/10.1007/s00450-016-0325-4", "year": "2016", "author": {"Kashif Nizam Khan": "33/8214", "Zhonghong Ou": "58/6143", "Mikael Hirki": "116/3003", "Jukka K. Nurminen": "38/1107", "Tapio Niemi": "48/1823"}, "abstract": "Full system electricity intake from the wall socket is important for understanding and budgeting the power consumption of large scale data centers. Measuring full system power, however, requires extra instrumentation with external physical devices, which is not only cumbersome, but also expensive and time consuming. To tackle this problem, in this paper, we propose to model wall socket power from processor package power obtained from the running average power limit (RAPL) interface, which is available on the latest Intel processors. Our experimental results demonstrate a strong correlation between RAPL package power and wall socket power consumption. Based on the observations, we propose an empirical power model to predict the full system power. We verify the model using multiple synthetic benchmarks (Stress-ng, STREAM), high energy physics benchmark (ParFullCMS), and non-trivial application benchmarks (Parsec). Experimental results show that the prediction model achieves good accuracy, which is maximum 5.6 % error rate."}, "journals/monet/TangYDOCW16": {"title": "Throughput Optimization via Association Control in Wireless LANs.", "url": "https://doi.org/10.1007/s11036-015-0650-z", "year": "2016", "author": {"Heyi Tang": "176/5940", "Liu Yang": "27/3367", "Jiang Dong": "64/2623", "Zhonghong Ou": "58/6143", "Yong Cui 0001": "91/2346-1", "Jianping Wu": "82/4905"}, "abstract": "With the rapid development of the mobile computing, accessing the Internet everywhere is important for mobile device users. Wireless LAN is a stable and reliable technique to provide network access for mobile devices. The Wireless LAN Access Points(APs) have been densely deployed so that a user can access the Internet almost everywhere. However, this fact brings some new challenges. Since the regular AP association strategy is signal-based when a user receive the signals of multiple APs. The APs with strong signal will be too overloaded while the bandwidth resource in other APs is wasted. The throughput of the whole WLAN is not optimized. Moreover, the diverse bandwidth demands among users further exacerbate the situation. In this paper, aiming at optimizing the throughput over the whole WLAN, a joint AP association and bandwidth allocation problem is formulated. The different users’ bandwidth demands are added as new constraints. We comprehensively analyze the solution space and prove the problem NP-hard. Our trace-driven evaluations show that the throughput is improved about 23.1 % compared to the conventional schemes."}, "journals/tmc/OuDDWYHWM15": {"title": "Utilize Signal Traces from Others? A Crowdsourcing Perspective of Energy Saving in Cellular Data Communication.", "url": "https://doi.org/10.1109/TMC.2014.2316517", "year": "2015", "author": {"Zhonghong Ou": "58/6143", "Jiang Dong": "64/2623", "Shichao Dong": "67/8730", "Jun Wu": "20/3894", "Antti Ylä-Jääski": "63/5415", "Pan Hui 0001": "62/1272-1", "Ren Wang 0001": "29/50-1", "Alexander W. Min": "35/5219"}, "abstract": " Abstract:With the tremendous growth in wireless network deployment and increasing use of mobile devices, e.g., smartphones and tablets, improving energy efficiency in such devices, especially with communication driven workloads, is critical to providing a satisfactory user experience. Studies show that signal strength plays an important role on energy consumption of cellular data communications. While energy consumption can be minimized by accurately predicting signal strengths and reacting to it in real-time, the dynamic nature of wireless environments makes signal strengths highly unpredictable. In this paper, after analyzing in detail the signal strength variation and its impact on energy consumption, we propose to use crowdsourcing approach to optimize mobile devices' energy efficiency by utilizing signal strength traces reported/shared by other users/devices in cellular networks. Via a comprehensive measurement study, we observe that signal strength traces collected from different devices are pseudo-identical, and they even exhibit similar threshold-based behaviors in the relationship between signal strength and device power consumption. Based on our observations, we propose a predictive scheduling algorithm that: (i) selects the right set of signal strength traces based on its location, (ii) applies a filter to smooth out signal strengths and hide abrupt changes, (iii) digitizes the signal strength to “good” and “bad” areas, and (iv) schedules transmissions based on power-throughput characteristics to optimize the transmission energy efficiency. To demonstrate the efficacy of the proposed algorithms, we prototype the crowdsourcing-based predicative scheduling algorithm on Android-based smartphones. Our experiment results from real-life driving tests demonstrate that, by leveraging others' signal traces, mobile devices can save energy up to 35 percent compared to the conventional opportunistic scheduling, i.e., schedule transmissions only based on instantaneous channel ..."}, "journals/corr/AbdurachmanovEEKNNNPOK14": {"title": "Techniques and tools for measuring energy efficiency of scientific software applications.", "url": "http://arxiv.org/abs/1410.3440", "year": "2014", "author": {"David Abdurachmanov": "137/8358", "Peter Elmer": "13/6285", "Giulio Eulisse": "45/3226", "Robert Knight": "61/11498", "Tapio Niemi": "48/1823", "Jukka K. Nurminen": "38/1107", "Filip Nyback": "153/1772", "Goncalo Pestana": "153/2131", "Zhonghong Ou": "58/6143", "Kashif Nizam Khan": "33/8214"}, "abstract": "\n      Abstract:  The scale of scientific High Performance Computing (HPC) and High Throughput\nComputing (HTC) has increased significantly in recent years, and is becoming\nsensitive to total energy use and cost. Energy-efficiency has thus become an\nimportant concern in scientific fields such as High Energy Physics (HEP). There\nhas been a growing interest in utilizing alternate architectures, such as low\npower ARM processors, to replace traditional Intel x86 architectures.\nNevertheless, even though such solutions have been successfully used in mobile\napplications with low I/O and memory demands, it is unclear if they are\nsuitable and more energy-efficient in the scientific computing environment.\nFurthermore, there is a lack of tools and experience to derive and compare\npower consumption between the architectures for various workloads, and\neventually to support software optimizations for energy efficiency. To that\nend, we have performed several physical and software-based measurements of\nworkloads from HEP applications running on ARM and Intel architectures, and\ncompare their power consumption and performance. We leverage several profiling\ntools (both in hardware and software) to extract different characteristics of\nthe power use. We report the results of these measurements and the experience\ngained in developing a set of measurement techniques and profiling tools to\naccurately assess the power consumption for scientific workloads.\n\n    "}, "journals/tcc/OuZLNHMY13": {"title": "Is the Same Instance Type Created Equal? Exploiting Heterogeneity of Public Clouds.", "url": "https://doi.org/10.1109/TCC.2013.12", "year": "2013", "author": {"Zhonghong Ou": "58/6143", "Hao Zhuang 0002": "84/10899-2", "Andrey Lukyanenko": "72/1967", "Jukka K. Nurminen": "38/1107", "Pan Hui 0001": "62/1272-1", "Vladimir V. Mazalov": "61/4986", "Antti Ylä-Jääski": "63/5415"}, "abstract": " Abstract:Public cloud platforms might start with homogeneous hardware; nevertheless, because of inevitable hardware upgrades, or adding more capacity, the initial homogeneous platform will gradually evolve into heterogeneous as time passes by. The consequent performance heterogeneity is of concern to cloud users. In this paper, we evaluate performance variations from hardware heterogeneity and scheduling mechanisms of public clouds. Amazon Elastic Compute Cloud (Amazon EC2) and Rackspace Cloud are used as the representatives because of their relatively long record and wide usage among small and medium enterprises (SMEs). A comprehensive set of microbenchmarks and application-level macrobenchmarks have been used to investigate performance variation. Several major contributions have been made. First, we find out that heterogeneous hardware is a commonality among the relatively long-lasting cloud platforms, although the level of heterogeneity varies. Second, we observe that heterogeneous hardware is the primary culprit of performance variation of cloud platforms. Third, we discover that varied CPU acquisition percentages and different virtual machine scheduling mechanisms exacerbate the performance variation problem, especially for network related operations. Finally, based on the observations, we propose cost-saving approaches and analyze Nash equilibrium from cloud user perspective. By using a simple \"trial-and-better\" approach, i.e., keep good-performing instances and discard bad-performing instances, cloud users can achieve up to 30 percent cost saving."}, "journals/jnca/LiuKOZRY11": {"title": "Super-peer-based coordinated service provision.", "url": "https://doi.org/10.1016/j.jnca.2011.01.007", "year": "2011", "author": {"Meirong Liu": "35/4171", "Timo Koskela": "01/6155", "Zhonghong Ou": "58/6143", "Jiehan Zhou": "48/4230", "Jukka Riekki": "49/3557", "Mika Ylianttila": "34/76"}, "abstract": "Leveraging P2P technologies for Web service provision attracts considerable research interests. One of the challenges is how to enable the service providers to adapt themselves in response to dynamic service demand. More specifically, one interesting research issue is coordinating the service groups in order to enable inter-group collaboration and resource sharing. In this paper, we propose a super-peer-based coordinated service provision framework (SCSP), consisting of an S-labor-market model (super-peer-based labor-market model), a recruiting protocol based on a weighting mechanism, and an optimal dispatch algorithm. In the SCSP, the S-labor-market model is designed to build the coordination among service groups by employing the proposed recruiting protocol. The optimal dispatch algorithm is designed to select the optimal service peers within a service group to process service requests. Finally, we perform simulations to evaluate the SCSP with four application scenarios. The experimental results show that our SCSP is efficient in coordinating the service groups, and possess good scalability and robustness."}, "journals/cn/OuHKY10": {"title": "Performance evaluation of a Kademlia-based communication-oriented P2P system under churn.", "url": "https://doi.org/10.1016/j.comnet.2009.09.022", "year": "2010", "author": {"Zhonghong Ou": "58/6143", "Erkki Harjula": "18/4722", "Otso Kassinen": "35/5308", "Mika Ylianttila": "34/76"}, "abstract": "The phenomenon of churn has a significant effect on the performance of Peer-to-Peer (P2P) networks, especially in mobile environments that are characterized by intermittent connections and unguaranteed network bandwidths. A number of proposals have been put forward to deal with this problem; however, we have so far not seen any thorough analysis to guide the optimal design choices and parameter configurations for structured P2P networks. In this article, we present a performance evaluation of a structured communication-oriented P2P system in the presence of churn. The evaluation is conducted using both simulation models and a real-life prototype implementation. In both evaluation environments, we utilize Kademlia with some modifications as the underlying distributed hash table (DHT) algorithm, and Peer-to-Peer Protocol (P2PP) as the signaling protocol. The results from the simulation models created using Nethawk EAST (a telecommunication simulator software) suggest that, in most situations, a lookup parallelism degree of 3 and resource replication degree of 3 are enough for guaranteeing a high resource lookup success ratio. We also notice that, with the parallel lookup mechanism, a good success ratio is achieved even without the KeepAlive traffic that is used for detecting the aliveness of nodes. A prototype system that works in mobile environment is implemented to evaluate the feasibility of mobile nodes acting as full-fledged peers. The measurements made using the prototype show that, from the viewpoints of CPU load and network traffic load, it is feasible for the mobile nodes to take part in the overlay. Through energy consumption measurements, we draw the conclusion that in general the UMTS access mode consumes slightly more power than the WLAN access mode. Protocol packets with sizes of 200 bytes or less are observed to be the most energy efficient in the UMTS access mode."}, "journals/monet/OuHKY10": {"title": "GTPP: General Truncated Pyramid Peer-to-Peer Architecture over Structured DHT Networks.", "url": "https://doi.org/10.1007/s11036-009-0193-2", "year": "2010", "author": {"Zhonghong Ou": "58/6143", "Erkki Harjula": "18/4722", "Timo Koskela": "01/6155", "Mika Ylianttila": "34/76"}, "abstract": "Hierarchical Distributed Hash Table (DHT) architectures have been among the most interesting research topics since the birth of flat DHT architecture. However, most of the previous work has merely focused on the two-tier hierarchy. In this paper, we study and analyze General Truncated Pyramid Peer-to-Peer (GTPP) architecture, the generalized version of Partially Vertical Hierarchical Architecture (PV-HA). The idea is to study whether added tiers of hierarchy can provide added value in performance and functionality. Through mathematical analysis, we demonstrate performance results in comparison to flat architecture, which helps understanding the typical characteristics of hierarchical architectures. Firstly, GTPP has slightly higher expected lookup hop count, although it can be decreased with optimizing the sub-overlay setup. However, GTPP significantly decreases the expected lookup routing latency. Secondly, GTPP has clearer and more reasonable traffic distribution among all the peers from different tiers of sub-overlays, and can work with slightly lower maintenance traffic. Thirdly, our studies indicate that two to three tiers are most suitable in most cases for GTPP, considering all the parameters."}, "journals/ieeemm/ZhouORKY09": {"title": "Digital Television for Mobile Devices.", "url": "https://doi.org/10.1109/MMUL.2009.7", "year": "2009", "author": {"Jiehan Zhou": "48/4230", "Zhonghong Ou": "58/6143", "Mika Rautiainen": "85/2702", "Timo Koskela": "01/6155", "Mika Ylianttila": "34/76"}, "abstract": " Abstract:A survey of mobile television technologies analyzes technical characteristics for each mobile TV solution, discusses specifications and standards, and presents possible future developments."}}}