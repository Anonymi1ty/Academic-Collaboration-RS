@misc{word2vec,
  doi = {10.48550/ARXIV.1411.2738},
  url = {https://arxiv.org/abs/1411.2738},
  author = {Rong, Xin},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {word2vec Parameter Learning Explained},
  publisher = {arXiv},
  year = {2014},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{GloVe,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@techreport{ilprints422,
  number = {1999-66},
  month = {November},
  author = {Lawrence Page and Sergey Brin and Rajeev Motwani and Terry Winograd},
  note = {Previous number = SIDL-WP-1999-0120},
  title = {The PageRank Citation Ranking: Bringing Order to the Web.},
  type = {Technical Report},
  publisher = {Stanford InfoLab},
  year = {1999},
  institution = {Stanford InfoLab},
  url = {http://ilpubs.stanford.edu:8090/422/},
  abstract = {The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said objectively about the relative importance of Web pages. This paper describes PageRank, a mathod for rating Web pages objectively and mechanically, effectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to efficiently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.}
  }

@misc{https://doi.org/10.48550/arxiv.2301.10656,
  doi = {10.48550/ARXIV.2301.10656},
  url = {https://arxiv.org/abs/2301.10656},
  author = {Klubička, Filip and Kelleher, John D.},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences, 68T30},
  title = {Probing Taxonomic and Thematic Embeddings for Taxonomic Information},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{https://doi.org/10.48550/arxiv.2211.08203,
  doi = {10.48550/ARXIV.2211.08203},
  url = {https://arxiv.org/abs/2211.08203},
  author = {Valentini, Francisco and Slezak, Diego Fernandez and Altszyler, Edgar},
  keywords = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {The Dependence on Frequency of Word Embedding Similarity Measures},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Montalv_o_2022,
  title={On the Information Content of Predictions in Word Analogy Tests},
  author={Montalv{\~a}o, Jugurta},
  journal={arXiv preprint arXiv:2210.09972},
  year={2022}
}

@misc{https://doi.org/10.48550/arxiv.2204.04833,
  doi = {10.48550/ARXIV.2204.04833},
  url = {https://arxiv.org/abs/2204.04833},
  author = {Rezaei, Hosein},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Word Embeddings Are Capable of Capturing Rhythmic Similarity of Words},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@ARTICLE{8861084,
  author={Onan, Aytuğ},
  journal={IEEE Access}, 
  title={Two-Stage Topic Extraction Model for Bibliometric Data Analysis Based on Word Embeddings and Clustering}, 
  year={2019},
  volume={7},
  number={},
  pages={145614-145633},
  doi={10.1109/ACCESS.2019.2945911}
}

@ARTICLE{8241844,
  author={Yu, Liang-Chih and Wang, Jin and Lai, K. Robert and Zhang, Xuejie},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Refining Word Embeddings Using Intensity Scores for Sentiment Analysis}, 
  year={2018},
  volume={26},
  number={3},
  pages={671-681},
  doi={10.1109/TASLP.2017.2788182}
}

@ARTICLE{7478417,
  author={Lai, Siwei and Liu, Kang and He, Shizhu and Zhao, Jun},
  journal={IEEE Intelligent Systems}, 
  title={How to Generate a Good Word Embedding}, 
  year={2016},
  volume={31},
  number={6},
  pages={5-14},
  doi={10.1109/MIS.2016.45}
}

@ARTICLE{7389336,
  author={Palangi, Hamid and Deng, Li and Shen, Yelong and Gao, Jianfeng and He, Xiaodong and Chen, Jianshu and Song, Xinying and Ward, Rabab},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval}, 
  year={2016},
  volume={24},
  number={4},
  pages={694-707},
  doi={10.1109/TASLP.2016.2520371}
}

@inproceedings{7259377,
  title={Support vector machines and word2vec for text classification with semantic features},
  author={Lilleberg, Joseph and Zhu, Yun and Zhang, Yanqing},
  booktitle={2015 IEEE 14th International Conference on Cognitive Informatics \& Cognitive Computing (ICCI* CC)},
  pages={136--140},
  year={2015},
  organization={IEEE}
}

@INPROCEEDINGS{8318770,
  author={Bhoir, Snehal and Ghorpade, Tushar and Mane, Vanita},
  booktitle={2017 International Conference on Advances in Computing, Communication and Control (ICAC3)}, 
  title={Comparative analysis of different word embedding models}, 
  year={2017},
  volume={},
  number={},
  pages={1-4},
  doi={10.1109/ICAC3.2017.8318770}
}

@INPROCEEDINGS{8852459,
  author={Rao, Qiang and Yu, Bing and He, Kun and Feng, Bailan},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Regularization and Iterative Initialization of Softmax for Fast Training of Convolutional Neural Networks}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/IJCNN.2019.8852459}
}