# A Novel Scholar Embedding Model for Interdisciplinary Collaboration

**Keywords:**跨领域合作、推荐、评价、词向量、网络




# 1.Introduction


<!-- TODO -->
<!-- 架构图 -->
<!-- 随着人类科学技术的不断发展，学者之间的跨领域合作是越来越需要解决的新的迫切需求，这对跨领域合作的评价提出了更高的要求。为了评估学者之间的跨领域合作程度，评估学者之间的研究领域契合度至关重要。对学者的研究方向进行界定和量化，可以对学者之间的研究领域契合程度进行评价。然而，传统的学者研究方向评价标准只能根据学者所在的学院和实验室或过去的学习和研究经验，对学者的研究领域和研究方向进行概览。

例如，在使用传统的学者研究领域评价标准时，该标准只能展示学者的宏观研究领域(如计算机科学)和微观研究领域(大数据和云计算)。然而，这一评价体系对于“微观研究领域”的精细化程度仍然过低，无法准确评价和界定学者的研究方向。该标准仍存在一些不足，如不同研究机构和高校之间的分类标准不统一，同一微观领域的学者之间的研究领域差距较大。传统的评价体系无法准确识别学者间跨领域合作中存在的误判可能性。

此外，传统的评价体系无法准确评价学者的具体研究方向，也无法量化其研究领域，使得全面评价学者的研究方向和跨领域合作具有挑战性。由于无法量化每篇文献的具体研究领域，导致人力损失大，主观性太强，评价效果差。针对这些局限性，提出了一种**学者嵌入语义分析模型**，通过词向量分析，利用学者发表的文献进行"数据挖掘"。

该模型为每个学者计算一个有意义的词向量空间，将所有学者的研究成果的研究方向抽象出来，经过分析处理后产生其所有研究方向的数学表达式。该模型通过GloVe对所有学者发表的文献摘要进行训练，将该学者发表的所有文献摘要的学习结果进行组合。该方法能够更准确、全面地评估学者具体、全面的研究方向，在词性比数据集上准确率达到75%的最新性能证明了该方法的有效性。此外，所提方法在学者研究领域评价上也优于现有方法。

总之，本文突出了传统学者研究领域评价体系的局限性，并针对这些局限性提出了创新性的解决方案。学者嵌入语义分析模型能够更全面、准确地评估学者的研究方向和跨领域合作，使得不同领域的学者之间的合作更加有效和富有成果。 -->

<!-- 交叉学科的意义 -->

学科交叉点往往就是科学新的生长点、新的科学前沿，这里最有可能产生重大的科学突破，使科学发生革命性的变化。我们需要更多的学者进行跨学科的合作，促进科学的发展。因此，我们需要一种系统性的跨学科合作网络发现与推荐解决方案，即发现、评价学者之间的跨学科合作情况，并根据学者的需求推荐适合领域的合作对象，以促进学者之间的跨学科合作。研究上述问题的前提，是完成交叉学科时代背景下的学者评估。

<!-- 挑战 -->

传统的学者评估是指对学者的学术水平和影响力进行量化或定性的评价，常用指标包括论文发表量、论文被引频次、篇均被引频次、高被引论文数和H指数等。然而上述方法都是基于学者的个人成果进行评估，没有考虑到学者在交叉学科的合作情况，这给交叉学科时代下的学者评估与合作推荐带来了挑战。

值得注意的是，不同的学科和领域可能有不同的学者评价指标和方法，传统的基于学科特性依靠人工制定的方法虽然精准，但需要花费巨大的人力、物力，且具有相当的滞后性。随着交叉学科的快速发展，传统的基于学科特性人工制定的学者评估无法适应交叉学科数量多，更加细分，结构复杂，发展迅速的特点。具体而言，几乎每年都有多个交叉学科诞生，这些学科融合了来自不同学科的特点，而且可能由于某一学科的突破性成果发生结构性的改变。学者评估的制定者由于自身的局限性，难以为缺乏历史，跨度广泛且发展迅速的交叉学科制定精细化的评估方法。以上事实对面向交叉学科的学者评估提出了巨大的挑战：提高评估方法的实时性，通用性(跨学科)和自适应性。

<!-- 我们的工作 -->

To tackle the aforementioned challenges，我们提出了一套面向交叉型学者的评估范式。我们知道，评估前的必要工作是选择适合的方法量化学者分布在各领域的学术成果，因此本文聚焦于学者的量化和表示工作，即将学者嵌入到更低维连续向量空间。具体而言，我们提出了一个创新性的基于全局语义信息和社会影响力的学者嵌入模型，用于得到vectors for author representation。我们的学者嵌入模型的输入由全局语义信息和社会影响力两部分组成。其中，语义输入指学者全部文献的摘要，代表了学者在各个学科全部学术成果。语义输入的引入这使得我们可以跨越学科间的壁垒，从更精细的语义维度上，对来自多个学科的学者进行通用性的评估；社会影响力输入是学者在各个学科内影响力和贡献力综合度量，它反应了学者的专长以及在交叉学科的合作情况。同时，以上两个输入是根据文献摘要，论文发表量、论文被引频次等数据实时计算的，使得我们可以实时追踪学者的研究动态。

<!-- 我们的贡献 -->

The contributions of this paper are summarized as follows:
- To the best of our knowledge, our author embedding model是第一个面向交叉型学者的量化和表示的模型，它同时考虑学者的文献全局语义信息和社会影响力，是面向交叉学科的学者评估的实时性，通用性和自适应性挑战而生的解决方案。
- 跨学科合作网络发现与推荐是复杂的系统工程，而我们的author embedding model解决了其中最基础的学者量化和表示工作，为我们后续的工作，包括交叉型学者评估，跨学科合作网络发现-评估-推荐，和更多创新性的应用奠定了基础。
<!-- TODO -->
- 我们take北京邮电大学(BUPT)的126位学者as a showcase and empirically demonstrate the notable efficacy of our proposed author embedding model on author similarity task. Moreover, 我们的工作对BUPT的交叉学科建设提供了数据支持的见解。


# 2.related work

> 介绍词向量分析、GloVe等等说一说目前研究的状况与目前研究成功在文献领域下的问题
## word2vec

为了将各学者的文献摘要进行量化的分析，需要将单词映射到具有单词特征的向量上，即词嵌入技术，词嵌入是词的矢量表示，可以捕捉其语义和句法意义。而word2vec`[cite?]`将每个词映射到一个固定长度的向量，这些向量能更好地表达不同词之间的相似性和类比关系，它们的训练依赖于它们本身的条件概率，在word2vec中词袋模型假设下，词的顺序是不重要的。word2vec的计算过程就是遍历所有的训练数据，最后就可以得到具有相似的上下文的词具有相似的语义，这些词对应的词向量计算余弦相似度也可以得到较高的值。

word2vec 工具主要包含两个模型：**跳元模型（skip-gram）**和**连续词袋模型（continuous bag of words，简称 CBOW）**，其中和下面要提到的GloVe紧密相关的便是skip-gram。跳元模型假设一个词可以用来在文本序列中生成其周围的单词。在跳元模型中，参数是词表中每个词的中心词向量和上下文词向量，每个词都有两个$d$维向量表示，用于计算条件概率。对于上下文窗口$m$，跳元模型的似然函数是在给定任何中心词的情况下生成所有上下文词的概率，至此还没有结束，因为如果单单只是接一个Softmax激活函数，计算量还是很大的，有多少词就会有多少维的权重矩阵，所以这里就提出层次Softmax(Hierarchical Softmax)，使用Huffman Tree来编码输出层的词典，瞬间把维度降低到了树的深度。但word2vec存在的问题是对每个local context window单独训练，没有利用包含在global co-occurrence矩阵中的统计信息，以及对多义词无法很好的表示和处理，因为使用了唯一的词向量。

## GloVe

GloVe`[cite?]`是word2vec生成词嵌入方法的扩展，它试图改进原始word2vec方法的一些限制。虽然word2vec和GloVe都是通过对大量的文本数据进行训练来生成词嵌入，但GloVe采取了不同的方法来为词之间的关系建模。具体来说，GloVe试图捕捉语料库中单词之间的共现统计，而不是像word2vec那样只捕捉每个单词周围的局部环境。通过这样做，GloVe能够捕捉到词与词之间的全局和局部关系，从而得到更适合捕捉词与词之间语义关系的嵌入。

然而，在GloVe中，被嵌入的对象是单词，而不是文献或者学者，这与我们研究的问题不同。因此我们需要使用GloVe进行一些序列级应用，提出新的嵌入方法，使其能够适用于我们的问题。



# 3. 前言

词嵌入，也称为分布式表示，是自然语言处理(NLP)中广泛使用的技术，使机器能够捕捉单词的含义和上下文。Global Vectors for Word Representation(GloVe)就是这样一种方法，它因能够产生高质量的词嵌入而受到欢迎。

在Pennington等人`\cite`的一篇论文中介绍了GloVe，该论文提出了一种基于语料库中单词的全局共现统计量来训练单词嵌入的新方法。该方法包括使用奇异值分解(SVD)对单词共现计数矩阵进行分解，并学习捕捉单词之间统计关系的单词向量。

GloVe中使用的关键公式是目标函数:

$$
J = \sum_{i,j=1}^{V}f(X_{ij})(w_i^T \tilde{w_j} + b_i + \tilde{b_j} - log(X_{ij}))^2
$$

其中$V$是单词的词汇量，$X_{ij}$是单词$i$和$j$的共现次数，$w_i$和$w_j$是词向量，$b_i$和$b_j$是偏置词，$f(X_{ij})$是一个赋予罕见词对较小权重的权重函数。目标是通过调整词向量和偏差来最小化$J$。词嵌入中另一个重要的公式是余弦相似度:

$$
similarity(w_i, w_j) = cos(θ) = (w_i^T * w_j) / (||w_i|| * ||w_j||)
$$

它通过计算两个词向量$w_i$和$w_j$之间夹角的余弦来度量它们之间的相似度。高余弦相似度值表明单词在语义上相似。总的来说，以GloVe为代表的词嵌入已经成为NLP不可分割的一部分，并实现了许多应用，如机器翻译、情感分析和文本分类。

# 4.Author Embedding Model

> 前面写一些前提，主要写如何将GloVe应用于Author Embedding，具体为比如文章的50维向量的处理过程

当把GloVe应用于本文章的问题时，即构建基于语义和综合影响力的合作网络，相应的原则是利用GloVe的预训练模型，将学者的文献摘要转化为向量，这个过程称为文献嵌入。然后根据各篇文献的综合影响力，对这些文献向量进行加权平均运算得到学者向量，这个过程称为学者嵌入。最后，我们根据学者向量，构建基于语义和综合影响力的跨学科学术合作网络。使用GloVe处理本工作的一个好处是，嵌入可以捕捉到单词之间的语义和句法关系，这对于识别跨学科学者之间有意义的研究联系可能很重要。此外，GloVe嵌入已被证明在各种自然语言处理任务中表现良好，这表明它们可能是一种识别跨学科合作的强大工具。

**文献嵌入：**

我们定义文献的向量$\vec P$:
$$
\vec P = \frac{1}{n}\sum_{i=1}^{n} \vec W_i
$$
其中，$\vec W_i$是文献摘要中第$i$个单词的词向量，$n$是文献摘要中单词的总数。这里我们使用了平均值来表示文献向量，这是因为我们认为文献的主题应该是由摘要中的所有单词共同决定的。

对于词向量$\vec W$，我们将数据库中的文献摘要(数据类型为String)，切分成单词，然后将每个单词，也就是token，映射到GloVe的预训练模型中，得到每个单词的50维的词向量。在本文中，我们使用GloVe的预训练模型(6B tokens, 400K vocab, uncased, 50d vectors)，该模型是在维基百科语料库上训练的。

**学者嵌入：**

首先我们定义一些符号。$x_{ij}$代表学者$i$的文献$j$中的合著者总人数。一般而言，对于一篇文献，学者的排名越前，他对于该文献的贡献度越大。因此，我们可以假设学者的贡献度与他在该文献中的排名成非均匀的正比关系，使用指数函数来表示`（见图？）`。

<img src="https://my-typora-p1.oss-cn-beijing.aliyuncs.com/typoraImgs/202303082319201.png" alt="2bd9afb730a0a9e5ff19f583f43d2ef" style="zoom:67%;" />

基于上述假设，则学者$i$对于文献$j$的贡献度$E_{Rij}$表示如下：
$$
E_{Rij}= \begin{cases} e,& \text{k = 1} \\ e^{\frac{x_{ij}-k}{x_{ij}}}, & \text{others} \end{cases}
$$

其中，$k$表示学者在文献中所有合著者中的排名。

此外，该文献的被引用次数能够反映该文献的影响力，通常情况下，被引用次数越多，该文献的影响力越大。因此，我们定义了学者$i$的文献$j$的影响因子$C_{ij}$：
$$
C_{ij} = \begin{cases} 0,& {{n_{ij}} = 0} \\ 1, & {{n_{ij}} > 0} \end{cases}
$$

其中$n_{ij}$是文献被引用的次数。并且结合文献的影响因子$C_{ij}$，我们可以得到文献$j$的影响力$E_{Cij}$，其定义如下：
$$
E_{Cij} = C_{ij} e^{\frac{n_{ij}}{n_{i_{max}}}}
$$
其中，$n_{ij}$是文献$j$被引用的次数,$n_{i_{max}}$是学者$i$的最高单篇被引用次数。

上述两个步骤分别提出了学者对于文献的贡献度和文献的影响力。接下来，我们基于PageRank思想上改进上式，Pagerank是由Sergey Brin和Lawrence Page等人`[cite?]`提出的在考虑网络单点的影响力的基础上，考虑其他因素的影响力的算法，我们将模型进行了调整:
$$
E_{ij} = \lambda E_{Rij} + (1-\lambda)E_{Cij}
$$

$E_{ij}$代表文献$j$的综合影响力，这里我们考虑两个因素：学者$i$对于文献$j$的贡献度$E_{Rij}$和文献$j$的影响力$E_{Cij}$，其中权重参数$\lambda$决定了$E_{Rij}$和$E_{Cij}$两个因素对$E_{ij}$的影响情况，取值范围为$[0, 1]$。


通过上述步骤我们得到了学者$i$在文献$j$中的影响力$E_{ij}$，接下来将其与GloVe提取的学者$i$的文献$j$的向量$\vec{P_{ij}}$相乘，并进行加权平均运算，得到学者$i$的向量$\vec{A_i}$，其定义如下：
$$
\vec{A_i} = \frac{\sum_{j=1}^{m} E_{ij} \vec{P_{ij}}}{m}
$$

其中，$m$表示学者$i$撰写的文献总数。通过此方法我们可以得到每一个学者的向量表示，我们称上述过程为Author Embedding。



## 4.1模型复杂性

As can be seen from `Eqn. (?)`，作者在某篇文章中的影响力的计算的时间复杂度取决于计算$E_{Rij}$与$E_{Cij}$的时间复杂度。As can be seen from `Eqn. (?)`，$E_{Rij}$取决于作者在此篇文章中的贡献程度（即此文章的作者顺序）。在本模型中$E_{Rij}$的计算可以通过读取相关文章的作者顺序并调用公式`Eqn. (?)`直接得出该作者在此篇文献下的贡献度$E_{Rij}$。

As can be seen from `Eqn. (?)` and `Eqn. (?)`，$E_{Cij}$取决于该篇文章在学术界的影响力（被引次数）。在本模型中$E_{Cij}$的计算可以通过读取相关文章的被引次数并调用公式`Eqn. (?)`和公式`Eqn. (?)`直接得出该文献的影响力$E_{Rij}$。

针对于使用GloVe计算后的学者发表文献的作者排行和被引次数计算作者在某篇文章的影响度这一步骤，本模型的时间复杂度为:$O(1)$，且与文章数正相关：
$$
\mid n \mid \backsim O(1)
$$

假设某作者共发表n篇文章，那么此步骤的总体时间复杂度为$O(n)$。

综上，在本模型下，将获取的学者发表所有文献的作者排行和被引次数等等原始数据转化为作者最终的总文献影响力的时间复杂度为（其中$O(|C|^{0.8})$为GloVe算法的时间复杂度，$n$为作者发表文献总数）:
$$
O(n \cdot |C|^{0.8})
$$

本模型使用了词向量领域下目前表现较好的GloVe作为词向量处理工具，其$O(|C|^{0.8})$的时间复杂度相较于其余词向量处理工具在时间复杂度上表现较好，符合本项目对于时间复杂度的需求。对于将处理后的词向量转化为最终学者总文献影响力这一步骤，本模型将单个文章处理的时间复杂度减低到了$O(1)$，单一作者总文献影响力处理的时间复杂度降低到了$O(n)$，表现良好，模型符合需求。
<!-- $$
E_{ij} = \lambda E_{Rij} + (1-\lambda)E_{Cij} = \lambda e^{\frac{x_{ij}-k}{x_{ij}}}+ (1-\lambda) C_{ij} e^{\frac{n_j}{n_{max}}}
$$ -->





# 5.Experiments

## 5.1模型测试方法

>下面的AB方法只是方法介绍，具体结果在5.3中呈现

为了评估author embedding的效果，we conduct experiments on the author similarity task. Pennington`[cite?]`等人对GloVe进行了word similarity评估，相应的，我们参考他们的工作设计了author similarity task，这是因为我们的embedding是基于GloVe预训练模型的。具体而言，我们邀请北京邮电大学的专家，对我们数据库中126位学者的合作关系进行了评估。合作关系分为5个等级，分别为1, 2, 3, 4, 5，对应author similarity的值为0.2, 0.4, 0.6, 0.8, 1。其中等级1表示完全不合作，等级5表示密切合作，我们将这些评估结果记作$t_{ij}$，其中。通过author embedding，我们学者的向量表示，然后我们计算了学者向量之间的余弦相似度$s_{ij}$：
$$
s_{ij} = \frac{\vec{A_i} \cdot \vec{A_j}}{{\mid \vec{A_i} \mid} \cdot {\mid \vec{A_j} \mid}}
$$
其中，$s_{ij}$表示学者$i$和学者$j$的相似度，$\vec{A_i}$表示学者$i$的向量，$\vec{A_j}$表示学者$j$的向量。

根据上述方法，同理可得学者$i$和其他所有学者的余弦相似度$\vec{s_i}$和评估结果$\vec{t_{i}}$，最后我们将$\vec{s_i}$与$\vec{t_i}$进行比较。

我们选择了余弦相似度作为评估方法，即模型推导出的相似度与人工标注的相似度的余弦相似度作为评估指标，越接近1表明模型越精准，我们将这个指标记作accuracy，即：
$$
Accuracy = \frac{\vec{s_i} \cdot \vec{t_{i}}}{{\mid \vec{s_i} \mid} \cdot {\mid \vec{t_{i}} \mid}}
$$


## 5.2测试结果

我们在`Fig.`中展示了两组数据的相似度情况。我们选择以10个作者为步长，将人工标注的数据集中的每个作者与生成的数据集中的每个作者进行比较，同时可视化的观测两组数据的相似度浮动。可以看到，两组数据的相似度浮动在一个很好的范围内，这表明我们所做的学者嵌入已经准确地反映了学者之间的合作关系。

<!-- TODO -->
<!-- 标题改为accuracy of author similarity task-->
<img src="https://my-typora-p1.oss-cn-beijing.aliyuncs.com/typoraImgs/202303120043420.png" alt="e2c7c62fc588c75c73fd3a7a1339123" style="zoom:67%;" />
通过计算，最终得到accuracy of author similarity task为**90.91%**，这个结果很好地证明了我们方案的可行性。

## 5.3Model Analysis:$\lambda$的选择
In `Fig ?`，我们展示了`Eqn. (?)`中，不同$\lambda$的选择对于整体模型准确度的影响。可以看出，开始时准确度随着$\lambda$的增加而上升。因为当$\lambda$的值越大时，作者的向量受其本身贡献度的影响增大，更加能反应出作者在该论文中的重要性，使得评价更加准确。但是在$\lambda$的值达到一定程度后，准确度就会开始下降。这是因为当$\lambda$的值越大时，作者的向量受文献影响力的影响增大，但是这个影响力是由论文的引用次数决定的，而论文的引用次数受到很多因素的影响，比如论文的发表时间，论文的主题等等，这些因素都会影响论文的引用次数。因此，当$\lambda$的值达到一定程度后，作者的向量就会受到很多不相关的因素的影响，使得评价不准确。因此，我们选择$\lambda$的值为0.56，这个值能够使得模型的准确度达到最大值。

<img src="https://my-typora-p1.oss-cn-beijing.aliyuncs.com/typoraImgs/202303102323182.png" alt="λ_graph" style="zoom:80%;" />

## 5.4Model Analysis:词向量维度的选择

本节介绍了模型分析的结果，重点是在GloVe预训练模型中为词向量选择最合适的维度。为了进行分析，我们使用不同的词向量维度(从50到300)对模型进行评估。我们对比了不同维度下的accuracy of author similarity task。`Table. ? `表明模型的对author similarity task的精度随着词向量的维度增加先提高后下降，并且在100维时取得了最高的精度。我们将这种精度的提高归因于这样一个事实，50维的作者向量不能反应作者的更多特征。因此，我们选择100维作为词向量的维度。

|  50 d  | 100 d  | 200 d  | 300 d  |
| :----: | :----: | :----: | :----: |
| 85.16% | 90.91% | 83.45% | 80.76% |




# 6.Conclusion
<!-- 在这次分析过程中，我们重点关注于如何将作者的特征进行映射，并提出了一种学者嵌入方法，通过对学者发表的文章进行分析，得到了学者的嵌入向量。我们之后对我们提出的模型进行评估，实验结果显示，通过对比人工标注的数据集与生成的数据集，得到其准确性为**90.91**，证明我们的方法取得了非常好的成效。下一步工作我们将使用现阶段得到的学者向量，并且基于此向量发现学者之间的潜在关系，并且以此为基础针对单个学者进行推荐工程。 -->
我们提出了一个的基于全局语义信息和社会影响力的学者嵌入模型，用于得到vectors for author representation。实验中，我们对北京邮电大学的126位学者应用了author embedding model，得到了他们各自的向量表示，并计算了两两之间的作者相似度(余弦相似度)。我们还邀请了该组织的学者评估专家对126位学者的两两合作关系评估，并与我们得到的作者相似度进行了比对。实验表明，计算得到的学者向量在学者相似度任务中取得了90.91%的精度。换言之，作者向量良好地表征了交叉型学者的学术成果和合作情况，我们的author embedding model成功地量化了学者。

我们的author embedding model为未来的跨学科合作网络发现与推荐研究开启了新的大门。它解决了其中最基础的学者量化和表示工作，为我们后续的工作，包括交叉型学者评估，跨学科合作网络发现-评估-推荐，和更多创新性的应用奠定了基础。
